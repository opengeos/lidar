{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to the lidar package","text":"<p>lidar is Python package for delineating the nested hierarchy of surface depressions in digital elevation models (DEMs). It is particularly useful for analyzing high-resolution topographic data, such as DEMs derived from Light Detection and Ranging (LiDAR) data.</p> <ul> <li>GitHub repo: https://github.com/opengeos/lidar</li> <li>Documentation: https://lidar.gishub.org</li> <li>PyPI: https://pypi.org/project/lidar</li> <li>Conda-forge: https://anaconda.org/conda-forge/lidar</li> <li>Open in Colab: https://gishub.org/lidar-colab</li> <li>Free software: MIT license</li> </ul> <p>Citations</p> <ul> <li> <p>Wu, Q., (2021). lidar: A Python package for delineating nested surface depressions from digital elevation data. Journal of Open Source Software, 6(59), 2965, https://doi.org/10.21105/joss.02965</p> </li> <li> <p>Wu, Q., Lane, C.R., Wang, L., Vanderhoof, M.K., Christensen,     J.R., &amp; Liu, H. (2019). Efficient Delineation of Nested Depression     Hierarchy in Digital Elevation Models for Hydrological Analysis     Using Level-Set Method. Journal of the American Water Resources     Association. https://doi.org/10.1111/1752-1688.12689 (PDF)</p> </li> </ul>"},{"location":"#introduction","title":"Introduction","text":"<p>lidar is a Python package for delineating the nested hierarchy of surface depressions in digital elevation models (DEMs). In traditional hydrological modeling, surface depressions in a DEM are commonly treated as artifacts and thus filled and removed to create a depressionless DEM, which can then be used to generate continuous stream networks. In reality, however, surface depressions in DEMs are commonly a combination of spurious and actual terrain features. Fine-resolution DEMs derived from Light Detection and Ranging (LiDAR) data can capture and represent actual surface depressions, especially in glaciated and karst landscapes. During the past decades, various algorithms have been developed to identify and delineate surface depressions, such as depression filling, depression breaching, hybrid breaching-filling, and contour tree method. More recently, a level-set method based on graph theory was proposed to delineate the nested hierarchy of surface depressions. The lidar Python package implements the level-set method and makes it possible for delineating the nested hierarchy of surface depressions as well as elevated terrain features. It also provides an interactive Graphical User Interface (GUI) that allows users to run the program with minimal coding.</p>"},{"location":"#statement-of-need","title":"Statement of Need","text":"<p>The lidar package is intended for scientists and researchers who would like to integrate surface depressions into hydrological modeling. It can also facilitate the identification and delineation of depressional features, such as sinkholes, detention basins, and prairie potholes. The detailed topological and geometric properties of surface depressions can be useful for terrain analysis and hydrological modeling, including the size, volume, mean depth, maximum depth, lowest elevation, spill elevation, perimeter, major axis length, minor axis length, elongatedness.</p>"},{"location":"#state-of-the-field","title":"State of the Field","text":"<p>Currently, there are a few open-source Python packages that can perform depression filling on digital elevation data, such as RichDEM and whitebox, the Python frontend for WhiteboxTools. However, there are no Python packages offering tools for delineating the nested hierarchy of surface depressions and catchments as well as simulating inundation dynamics. The lidar Python package is intended for filling this gap.</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Smoothing DEMs using mean, median, and Gaussian filters.</li> <li>Extracting depressions from DEMs.</li> <li>Filtering out small artifact depressions based on user-specified minimum depression size.</li> <li>Generating refined DEMs with small depressions filled but larger depressions kept intact.</li> <li>Delineating depression nested hierarchy using the level-set method.</li> <li>Delineating mount nested hierarchy using the level-set method.</li> <li>Computing topological and geometric properties of depressions, including size, volume, mean depth, maximum depth, lowest elevation,     spill elevation, perimeter, major axis length, minor axis length, elongatedness, eccentricity, orientation, and area-bbox-ratio.</li> <li>Exporting depression properties as a csv file.</li> </ul>"},{"location":"changelog/","title":"Changelog","text":""},{"location":"changelog/#v070-sep-23-2022","title":"v0.7.0 - Sep 23, 2022","text":"<ul> <li>Added extract sinks by huc and bbox</li> <li>Added huc8 data</li> <li>Added download ned functions</li> <li>Removed pygdal</li> </ul>"},{"location":"changelog/#v060-feb-27-2021","title":"v0.6.0 - Feb 27, 2021","text":"<ul> <li>Improved documentation</li> <li>Added ArcGIS toolbox tutorials</li> <li>Addressed JOSS review comments</li> </ul>"},{"location":"changelog/#v053-feb-10-2021","title":"v0.5.3 - Feb 10, 2021","text":"<ul> <li>Fixed PyPI markdown rendering error</li> </ul>"},{"location":"changelog/#v052-feb-10-2021","title":"v0.5.2 - Feb 10, 2021","text":"<ul> <li>Added new documentation website (https://lidar.gishub.org)</li> <li>Improved JOSS paper</li> <li>Cleaned up source code</li> </ul>"},{"location":"changelog/#v051-dec-12-2020","title":"v0.5.1 - Dec 12, 2020","text":""},{"location":"changelog/#v020-sep-16-2018","title":"v0.2.0 - Sep 16, 2018","text":""},{"location":"changelog/#v016-may-21-2018","title":"v0.1.6 - May 21, 2018","text":""},{"location":"changelog/#015-may-16-2018","title":"0.1.5 - May 16, 2018","text":""},{"location":"changelog/#013-may-15-2018","title":"0.1.3 - May 15, 2018","text":""},{"location":"changelog/#010-may-14-2018","title":"0.1.0 - May 14, 2018","text":""},{"location":"citations/","title":"Citations","text":"<p>The level-set algorithm was proposed by Wu et al. (2019):</p> <ul> <li>Wu, Q., Lane, C.R., Wang, L., Vanderhoof, M.K., Christensen,     J.R., &amp; Liu, H. (2019). Efficient Delineation of Nested Depression     Hierarchy in Digital Elevation Models for Hydrological Analysis     Using Level-Set Method. Journal of the American Water Resources     Association. DOI: 10.1111/1752-1688.12689 (PDF)</li> </ul> <p>Applications of the level-set and contour-tree methods for feature extraction from LiDAR data:</p> <ul> <li>Wu, Q., &amp; Lane, C.R. (2017). Delineating wetland catchments and     modeling hydrologic connectivity using LiDAR data and aerial     imagery. Hydrology and Earth System Sciences. 21: 3579-3595. DOI:     10.5194/hess-21-3579-2017</li> <li>Wu, Q., Deng, C., &amp; Chen, Z. (2016). Automated delineation of     karst sinkholes from LiDAR-derived digital elevation models.     Geomorphology. 266: 1-10. DOI:     10.1016/j.geomorph.2016.05.006</li> <li>Wu, Q., Su, H., Sherman, D.J., Liu, H., Wozencraft, J.M., Yu,     B., &amp; Chen, Z. (2016). A graph-based approach for assessing     storm-induced coastal changes. International Journal of Remote     Sensing. 37:4854-4873. DOI:     10.1080/01431161.2016.1225180</li> <li>Wu, Q., &amp; Lane, C.R. (2016). Delineation and quantification of     wetland depressions in the Prairie Pothole Region of North Dakota.     Wetlands. 36(2):215\u2013227. DOI:     10.1007/s13157-015-0731-6</li> <li>Wu, Q., Liu, H., Wang, S., Yu, B., Beck, R., &amp; Hinkel, K.     (2015). A localized contour tree method for deriving geometric and     topological properties of complex surface depressions based on     high-resolution topographic data. International Journal of     Geographical Information Science. 29(12): 2041-2060. DOI:     10.1080/13658816.2015.1038719</li> <li>Wu, Q., Lane, C.R., &amp; Liu, H. (2014). An effective method for     detecting potential woodland vernal pools using high-resolution     LiDAR data and aerial imagery. Remote Sensing. 6(11):11444-11467.     DOI: 10.3390/rs61111444</li> </ul>"},{"location":"common/","title":"utilities module","text":""},{"location":"common/#lidar.common.add_crs","title":"<code>add_crs(filename, epsg)</code>","text":"<p>Add a CRS to a raster dataset.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>The filename of the raster dataset.</p> required <code>epsg</code> <code>int | str</code> <p>The EPSG code of the CRS.</p> required Source code in <code>lidar/common.py</code> <pre><code>def add_crs(filename, epsg):\n    \"\"\"Add a CRS to a raster dataset.\n\n    Args:\n        filename (str): The filename of the raster dataset.\n        epsg (int | str): The EPSG code of the CRS.\n\n    \"\"\"\n    try:\n        import rasterio\n    except ImportError:\n        raise ImportError(\n            \"rasterio is required for adding a CRS to a raster. Please install it using 'pip install rasterio'.\"\n        )\n\n    if not os.path.exists(filename):\n        raise ValueError(\"filename must exist.\")\n\n    if isinstance(epsg, int):\n        epsg = f\"EPSG:{epsg}\"\n    elif isinstance(epsg, str):\n        epsg = \"EPSG:\" + epsg\n    else:\n        raise ValueError(\"epsg must be an integer or string.\")\n\n    crs = rasterio.crs.CRS({\"init\": epsg})\n    with rasterio.open(filename, mode=\"r+\") as src:\n        src.crs = crs\n</code></pre>"},{"location":"common/#lidar.common.check_file_path","title":"<code>check_file_path(file_path, make_dirs=True)</code>","text":"<p>Gets the absolute file path.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>str</code> <p>The path to the file.</p> required <code>make_dirs</code> <code>bool</code> <p>Whether to create the directory if it does not exist. Defaults to True.</p> <code>True</code> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the directory could not be found.</p> <code>TypeError</code> <p>If the input directory path is not a string.</p> <p>Returns:</p> Name Type Description <code>str</code> <p>The absolute path to the file.</p> Source code in <code>lidar/common.py</code> <pre><code>def check_file_path(file_path, make_dirs=True):\n    \"\"\"Gets the absolute file path.\n\n    Args:\n        file_path (str): The path to the file.\n        make_dirs (bool, optional): Whether to create the directory if it does not exist. Defaults to True.\n\n    Raises:\n        FileNotFoundError: If the directory could not be found.\n        TypeError: If the input directory path is not a string.\n\n    Returns:\n        str: The absolute path to the file.\n    \"\"\"\n    if isinstance(file_path, str):\n        if file_path.startswith(\"~\"):\n            file_path = os.path.expanduser(file_path)\n        else:\n            file_path = os.path.abspath(file_path)\n\n        file_dir = os.path.dirname(file_path)\n        if not os.path.exists(file_dir) and make_dirs:\n            os.makedirs(file_dir)\n\n        return file_path\n\n    else:\n        raise TypeError(\"The provided file path must be a string.\")\n</code></pre>"},{"location":"common/#lidar.common.check_install","title":"<code>check_install(package)</code>","text":"<p>Checks whether a package is installed. If not, it will install the package.</p> <p>Parameters:</p> Name Type Description Default <code>package</code> <code>str</code> <p>The name of the package to check.</p> required Source code in <code>lidar/common.py</code> <pre><code>def check_install(package):\n    \"\"\"Checks whether a package is installed. If not, it will install the package.\n\n    Args:\n        package (str): The name of the package to check.\n    \"\"\"\n    import subprocess\n\n    try:\n        __import__(package)\n        # print('{} is already installed.'.format(package))\n    except ImportError:\n        print(\"{} is not installed. Installing ...\".format(package))\n        try:\n            subprocess.check_call([\"python\", \"-m\", \"pip\", \"install\", package])\n        except Exception as e:\n            print(\"Failed to install {}\".format(package))\n            print(e)\n        print(\"{} has been installed successfully.\".format(package))\n</code></pre>"},{"location":"common/#lidar.common.clip_image","title":"<code>clip_image(image, mask, output)</code>","text":"<p>Clip an image by mask.</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>str</code> <p>Path to the image file in GeoTIFF format.</p> required <code>mask</code> <code>str | list | dict</code> <p>The mask used to extract the image. It can be a path to vector datasets (e.g., GeoJSON, Shapefile), a list of coordinates, or m.user_roi.</p> required <code>output</code> <code>str</code> <p>Path to the output file.</p> required <p>Raises:</p> Type Description <code>ImportError</code> <p>If the fiona or rasterio package is not installed.</p> <code>FileNotFoundError</code> <p>If the image is not found.</p> <code>ValueError</code> <p>If the mask is not a valid GeoJSON or raster file.</p> <code>FileNotFoundError</code> <p>If the mask file is not found.</p> Source code in <code>lidar/common.py</code> <pre><code>def clip_image(image, mask, output):\n    \"\"\"Clip an image by mask.\n\n    Args:\n        image (str): Path to the image file in GeoTIFF format.\n        mask (str | list | dict): The mask used to extract the image. It can be a path to vector datasets (e.g., GeoJSON, Shapefile), a list of coordinates, or m.user_roi.\n        output (str): Path to the output file.\n\n    Raises:\n        ImportError: If the fiona or rasterio package is not installed.\n        FileNotFoundError: If the image is not found.\n        ValueError: If the mask is not a valid GeoJSON or raster file.\n        FileNotFoundError: If the mask file is not found.\n    \"\"\"\n    import json\n\n    try:\n        import fiona\n        import rasterio\n        import rasterio.mask\n    except ImportError as e:\n        raise ImportError(e)\n\n    if not os.path.exists(image):\n        raise FileNotFoundError(f\"{image} does not exist.\")\n\n    if not output.endswith(\".tif\"):\n        raise ValueError(\"Output must be a tif file.\")\n\n    output = check_file_path(output)\n\n    if isinstance(mask, str):\n        if mask.startswith(\"http\"):\n            mask = download_file(mask, output)\n        if not os.path.exists(mask):\n            raise FileNotFoundError(f\"{mask} does not exist.\")\n    elif isinstance(mask, list) or isinstance(mask, dict):\n\n        if isinstance(mask, list):\n            geojson = {\n                \"type\": \"FeatureCollection\",\n                \"features\": [\n                    {\n                        \"type\": \"Feature\",\n                        \"properties\": {},\n                        \"geometry\": {\"type\": \"Polygon\", \"coordinates\": [mask]},\n                    }\n                ],\n            }\n        else:\n            geojson = {\n                \"type\": \"FeatureCollection\",\n                \"features\": [mask],\n            }\n        mask = temp_file_path(\".geojson\")\n        with open(mask, \"w\") as f:\n            json.dump(geojson, f)\n\n    with fiona.open(mask, \"r\") as shapefile:\n        shapes = [feature[\"geometry\"] for feature in shapefile]\n\n    with rasterio.open(image) as src:\n        out_image, out_transform = rasterio.mask.mask(src, shapes, crop=True)\n        out_meta = src.meta\n\n    out_meta.update(\n        {\n            \"driver\": \"GTiff\",\n            \"height\": out_image.shape[1],\n            \"width\": out_image.shape[2],\n            \"transform\": out_transform,\n        }\n    )\n\n    with rasterio.open(output, \"w\", **out_meta) as dest:\n        dest.write(out_image)\n</code></pre>"},{"location":"common/#lidar.common.clone_repo","title":"<code>clone_repo(out_dir='.', unzip=True)</code>","text":"<p>Clones the lidar GitHub repository.</p> <p>Parameters:</p> Name Type Description Default <code>out_dir</code> <code>str</code> <p>Output folder for the repo. Defaults to '.'.</p> <code>'.'</code> <code>unzip</code> <code>bool</code> <p>Whether to unzip the repository. Defaults to True.</p> <code>True</code> Source code in <code>lidar/common.py</code> <pre><code>def clone_repo(out_dir=\".\", unzip=True):\n    \"\"\"Clones the lidar GitHub repository.\n\n    Args:\n        out_dir (str, optional): Output folder for the repo. Defaults to '.'.\n        unzip (bool, optional): Whether to unzip the repository. Defaults to True.\n    \"\"\"\n    url = \"https://github.com/opengeos/lidar/archive/master.zip\"\n    filename = \"lidar-master.zip\"\n    download_from_url(url, out_file_name=filename, out_dir=out_dir, unzip=unzip)\n</code></pre>"},{"location":"common/#lidar.common.convert_lidar","title":"<code>convert_lidar(source, destination=None, point_format_id=None, file_version=None, **kwargs)</code>","text":"<p>Converts a Las from one point format to another Automatically upgrades the file version if source file version     is not compatible with the new point_format_id</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>str | LasBase</code> <p>The source data to be converted.</p> required <code>destination</code> <code>str</code> <p>The destination file path. Defaults to None.</p> <code>None</code> <code>point_format_id</code> <code>int</code> <p>The new point format id (the default is None, which won't change the source format id).</p> <code>None</code> <code>file_version</code> <code>str</code> <p>The new file version. None by default which means that the file_version may be upgraded for compatibility with the new point_format. The file version will not be downgraded.</p> <code>None</code> <p>Returns:</p> Type Description <p>aspy.lasdatas.base.LasBase: The converted LasData object.</p> Source code in <code>lidar/common.py</code> <pre><code>def convert_lidar(\n    source, destination=None, point_format_id=None, file_version=None, **kwargs\n):\n    \"\"\"Converts a Las from one point format to another Automatically upgrades the file version if source file version\n        is not compatible with the new point_format_id\n\n    Args:\n        source (str | laspy.lasdatas.base.LasBase): The source data to be converted.\n        destination (str, optional): The destination file path. Defaults to None.\n        point_format_id (int, optional): The new point format id (the default is None, which won't change the source format id).\n        file_version (str, optional): The new file version. None by default which means that the file_version may be upgraded\n            for compatibility with the new point_format. The file version will not be downgraded.\n\n    Returns:\n        aspy.lasdatas.base.LasBase: The converted LasData object.\n    \"\"\"\n    try:\n        import laspy\n    except ImportError:\n        print(\n            \"The laspy package is required for this function. Use `pip install laspy[lazrs,laszip]` to install it.\"\n        )\n        return\n\n    if isinstance(source, str):\n        source = read_lidar(source)\n\n    las = laspy.convert(\n        source, point_format_id=point_format_id, file_version=file_version\n    )\n\n    if destination is None:\n        return las\n    else:\n        destination = check_file_path(destination)\n        write_lidar(las, destination, **kwargs)\n        return destination\n</code></pre>"},{"location":"common/#lidar.common.csv_points_to_shp","title":"<code>csv_points_to_shp(in_csv, out_shp, latitude='latitude', longitude='longitude')</code>","text":"<p>Converts a csv file containing points (latitude, longitude) into a shapefile.</p> <p>Parameters:</p> Name Type Description Default <code>in_csv</code> <code>str</code> <p>File path or HTTP URL to the input csv file. For example, https://raw.githubusercontent.com/giswqs/data/main/world/world_cities.csv</p> required <code>out_shp</code> <code>str</code> <p>File path to the output shapefile.</p> required <code>latitude</code> <code>str</code> <p>Column name for the latitude column. Defaults to 'latitude'.</p> <code>'latitude'</code> <code>longitude</code> <code>str</code> <p>Column name for the longitude column. Defaults to 'longitude'.</p> <code>'longitude'</code> Source code in <code>lidar/common.py</code> <pre><code>def csv_points_to_shp(in_csv, out_shp, latitude=\"latitude\", longitude=\"longitude\"):\n    \"\"\"Converts a csv file containing points (latitude, longitude) into a shapefile.\n\n    Args:\n        in_csv (str): File path or HTTP URL to the input csv file. For example, https://raw.githubusercontent.com/giswqs/data/main/world/world_cities.csv\n        out_shp (str): File path to the output shapefile.\n        latitude (str, optional): Column name for the latitude column. Defaults to 'latitude'.\n        longitude (str, optional): Column name for the longitude column. Defaults to 'longitude'.\n\n    \"\"\"\n    import whitebox\n\n    if in_csv.startswith(\"http\") and in_csv.endswith(\".csv\"):\n        out_dir = os.path.join(os.path.expanduser(\"~\"), \"Downloads\")\n        out_name = os.path.basename(in_csv)\n\n        if not os.path.exists(out_dir):\n            os.makedirs(out_dir)\n        download_from_url(in_csv, out_dir=out_dir)\n        in_csv = os.path.join(out_dir, out_name)\n\n    wbt = whitebox.WhiteboxTools()\n    in_csv = os.path.abspath(in_csv)\n    out_shp = os.path.abspath(out_shp)\n\n    if not os.path.exists(in_csv):\n        raise Exception(\"The provided csv file does not exist.\")\n\n    with open(in_csv, encoding=\"utf-8\") as csv_file:\n        reader = csv.DictReader(csv_file)\n        fields = reader.fieldnames\n        xfield = fields.index(longitude)\n        yfield = fields.index(latitude)\n\n    wbt.csv_points_to_vector(in_csv, out_shp, xfield=xfield, yfield=yfield, epsg=4326)\n</code></pre>"},{"location":"common/#lidar.common.csv_to_shp","title":"<code>csv_to_shp(in_csv, out_shp, latitude='latitude', longitude='longitude')</code>","text":"<p>Converts a csv file with latlon info to a point shapefile.</p> <p>Parameters:</p> Name Type Description Default <code>in_csv</code> <code>str</code> <p>The input csv file containing longitude and latitude columns.</p> required <code>out_shp</code> <code>str</code> <p>The file path to the output shapefile.</p> required <code>latitude</code> <code>str</code> <p>The column name of the latitude column. Defaults to 'latitude'.</p> <code>'latitude'</code> <code>longitude</code> <code>str</code> <p>The column name of the longitude column. Defaults to 'longitude'.</p> <code>'longitude'</code> Source code in <code>lidar/common.py</code> <pre><code>def csv_to_shp(in_csv, out_shp, latitude=\"latitude\", longitude=\"longitude\"):\n    \"\"\"Converts a csv file with latlon info to a point shapefile.\n\n    Args:\n        in_csv (str): The input csv file containing longitude and latitude columns.\n        out_shp (str): The file path to the output shapefile.\n        latitude (str, optional): The column name of the latitude column. Defaults to 'latitude'.\n        longitude (str, optional): The column name of the longitude column. Defaults to 'longitude'.\n    \"\"\"\n    import csv\n    import shapefile as shp\n\n    if in_csv.startswith(\"http\") and in_csv.endswith(\".csv\"):\n        out_dir = os.path.join(os.path.expanduser(\"~\"), \"Downloads\")\n        out_name = os.path.basename(in_csv)\n\n        if not os.path.exists(out_dir):\n            os.makedirs(out_dir)\n        download_from_url(in_csv, out_dir=out_dir)\n        in_csv = os.path.join(out_dir, out_name)\n\n    out_dir = os.path.dirname(out_shp)\n    if not os.path.exists(out_dir):\n        os.makedirs(out_dir)\n\n    try:\n        points = shp.Writer(out_shp, shapeType=shp.POINT)\n        with open(in_csv, encoding=\"utf-8\") as csvfile:\n            csvreader = csv.DictReader(csvfile)\n            header = csvreader.fieldnames\n            [points.field(field) for field in header]\n            for row in csvreader:\n                points.point((float(row[longitude])), (float(row[latitude])))\n                points.record(*tuple([row[f] for f in header]))\n\n        out_prj = out_shp.replace(\".shp\", \".prj\")\n        with open(out_prj, \"w\") as f:\n            prj_str = 'GEOGCS[\"GCS_WGS_1984\",DATUM[\"D_WGS_1984\",SPHEROID[\"WGS_1984\",6378137,298.257223563]],PRIMEM[\"Greenwich\",0],UNIT[\"Degree\",0.0174532925199433]] '\n            f.write(prj_str)\n\n    except Exception as e:\n        print(e)\n</code></pre>"},{"location":"common/#lidar.common.download_file","title":"<code>download_file(url=None, output=None, quiet=False, proxy=None, speed=None, use_cookies=True, verify=True, id=None, fuzzy=False, resume=False, unzip=True, overwrite=False)</code>","text":"<p>Download a file from URL, including Google Drive shared URL.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>Google Drive URL is also supported. Defaults to None.</p> <code>None</code> <code>output</code> <code>str</code> <p>Output filename. Default is basename of URL.</p> <code>None</code> <code>quiet</code> <code>bool</code> <p>Suppress terminal output. Default is False.</p> <code>False</code> <code>proxy</code> <code>str</code> <p>Proxy. Defaults to None.</p> <code>None</code> <code>speed</code> <code>float</code> <p>Download byte size per second (e.g., 256KB/s = 256 * 1024). Defaults to None.</p> <code>None</code> <code>use_cookies</code> <code>bool</code> <p>Flag to use cookies. Defaults to True.</p> <code>True</code> <code>verify</code> <code>bool | str</code> <p>Either a bool, in which case it controls whether the server's TLS certificate is verified, or a string, in which case it must be a path to a CA bundle to use. Default is True.. Defaults to True.</p> <code>True</code> <code>id</code> <code>str</code> <p>Google Drive's file ID. Defaults to None.</p> <code>None</code> <code>fuzzy</code> <code>bool</code> <p>Fuzzy extraction of Google Drive's file Id. Defaults to False.</p> <code>False</code> <code>resume</code> <code>bool</code> <p>Resume the download from existing tmp file if possible. Defaults to False.</p> <code>False</code> <code>unzip</code> <code>bool</code> <p>Unzip the file. Defaults to True.</p> <code>True</code> <code>overwrite</code> <code>bool</code> <p>Overwrite the file if it already exists. Defaults to False.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>str</code> <p>The output file path.</p> Source code in <code>lidar/common.py</code> <pre><code>def download_file(\n    url=None,\n    output=None,\n    quiet=False,\n    proxy=None,\n    speed=None,\n    use_cookies=True,\n    verify=True,\n    id=None,\n    fuzzy=False,\n    resume=False,\n    unzip=True,\n    overwrite=False,\n):\n    \"\"\"Download a file from URL, including Google Drive shared URL.\n\n    Args:\n        url (str, optional): Google Drive URL is also supported. Defaults to None.\n        output (str, optional): Output filename. Default is basename of URL.\n        quiet (bool, optional): Suppress terminal output. Default is False.\n        proxy (str, optional): Proxy. Defaults to None.\n        speed (float, optional): Download byte size per second (e.g., 256KB/s = 256 * 1024). Defaults to None.\n        use_cookies (bool, optional): Flag to use cookies. Defaults to True.\n        verify (bool | str, optional): Either a bool, in which case it controls whether the server's TLS certificate is verified, or a string, in which case it must be a path to a CA bundle to use. Default is True.. Defaults to True.\n        id (str, optional): Google Drive's file ID. Defaults to None.\n        fuzzy (bool, optional): Fuzzy extraction of Google Drive's file Id. Defaults to False.\n        resume (bool, optional): Resume the download from existing tmp file if possible. Defaults to False.\n        unzip (bool, optional): Unzip the file. Defaults to True.\n        overwrite (bool, optional): Overwrite the file if it already exists. Defaults to False.\n\n    Returns:\n        str: The output file path.\n    \"\"\"\n\n    import gdown\n\n    if output is None:\n        if isinstance(url, str) and url.startswith(\"http\"):\n            output = os.path.basename(url)\n\n    if isinstance(url, str):\n        if os.path.exists(os.path.abspath(output)) and (not overwrite):\n            print(\n                f\"{output} already exists. Skip downloading. Set overwrite=True to overwrite.\"\n            )\n            return os.path.abspath(output)\n        else:\n            url = github_raw_url(url)\n\n    if \"https://drive.google.com/file/d/\" in url:\n        fuzzy = True\n\n    output = gdown.download(\n        url, output, quiet, proxy, speed, use_cookies, verify, id, fuzzy, resume\n    )\n\n    if unzip and output.endswith(\".zip\"):\n\n        with zipfile.ZipFile(output, \"r\") as zip_ref:\n            if not quiet:\n                print(\"Extracting files...\")\n            zip_ref.extractall(os.path.dirname(output))\n\n    return os.path.abspath(output)\n</code></pre>"},{"location":"common/#lidar.common.download_folder","title":"<code>download_folder(url=None, id=None, output=None, quiet=False, proxy=None, speed=None, use_cookies=True, remaining_ok=False)</code>","text":"<p>Downloads the entire folder from URL.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>URL of the Google Drive folder. Must be of the format 'https://drive.google.com/drive/folders/{url}'. Defaults to None.</p> <code>None</code> <code>id</code> <code>str</code> <p>Google Drive's folder ID. Defaults to None.</p> <code>None</code> <code>output</code> <code>str</code> <p>String containing the path of the output folder. Defaults to current working directory.</p> <code>None</code> <code>quiet</code> <code>bool</code> <p>Suppress terminal output. Defaults to False.</p> <code>False</code> <code>proxy</code> <code>str</code> <p>Proxy. Defaults to None.</p> <code>None</code> <code>speed</code> <code>float</code> <p>Download byte size per second (e.g., 256KB/s = 256 * 1024). Defaults to None.</p> <code>None</code> <code>use_cookies</code> <code>bool</code> <p>Flag to use cookies. Defaults to True.</p> <code>True</code> <code>resume</code> <code>bool</code> <p>Resume the download from existing tmp file if possible. Defaults to False.</p> required <p>Returns:</p> Name Type Description <code>list</code> <p>List of files downloaded, or None if failed.</p> Source code in <code>lidar/common.py</code> <pre><code>def download_folder(\n    url=None,\n    id=None,\n    output=None,\n    quiet=False,\n    proxy=None,\n    speed=None,\n    use_cookies=True,\n    remaining_ok=False,\n):\n    \"\"\"Downloads the entire folder from URL.\n\n    Args:\n        url (str, optional): URL of the Google Drive folder. Must be of the format 'https://drive.google.com/drive/folders/{url}'. Defaults to None.\n        id (str, optional): Google Drive's folder ID. Defaults to None.\n        output (str, optional):  String containing the path of the output folder. Defaults to current working directory.\n        quiet (bool, optional): Suppress terminal output. Defaults to False.\n        proxy (str, optional): Proxy. Defaults to None.\n        speed (float, optional): Download byte size per second (e.g., 256KB/s = 256 * 1024). Defaults to None.\n        use_cookies (bool, optional): Flag to use cookies. Defaults to True.\n        resume (bool, optional): Resume the download from existing tmp file if possible. Defaults to False.\n\n    Returns:\n        list: List of files downloaded, or None if failed.\n    \"\"\"\n    import gdown\n\n    files = gdown.download_folder(\n        url, id, output, quiet, proxy, speed, use_cookies, remaining_ok\n    )\n    return files\n</code></pre>"},{"location":"common/#lidar.common.download_from_gdrive","title":"<code>download_from_gdrive(gfile_url, file_name, out_dir='.', unzip=True, verbose=True)</code>","text":"<p>Download a file shared via Google Drive    (e.g., https://drive.google.com/file/d/18SUo_HcDGltuWYZs1s7PpOmOq_FvFn04/view?usp=sharing)</p> <p>Parameters:</p> Name Type Description Default <code>gfile_url</code> <code>str</code> <p>The Google Drive shared file URL</p> required <code>file_name</code> <code>str</code> <p>The output file name to use.</p> required <code>out_dir</code> <code>str</code> <p>The output directory. Defaults to '.'.</p> <code>'.'</code> <code>unzip</code> <code>bool</code> <p>Whether to unzip the output file if it is a zip file. Defaults to True.</p> <code>True</code> <code>verbose</code> <code>bool</code> <p>Whether to display or not the output of the function</p> <code>True</code> Source code in <code>lidar/common.py</code> <pre><code>def download_from_gdrive(gfile_url, file_name, out_dir=\".\", unzip=True, verbose=True):\n    \"\"\"Download a file shared via Google Drive\n       (e.g., https://drive.google.com/file/d/18SUo_HcDGltuWYZs1s7PpOmOq_FvFn04/view?usp=sharing)\n\n    Args:\n        gfile_url (str): The Google Drive shared file URL\n        file_name (str): The output file name to use.\n        out_dir (str, optional): The output directory. Defaults to '.'.\n        unzip (bool, optional): Whether to unzip the output file if it is a zip file. Defaults to True.\n        verbose (bool, optional): Whether to display or not the output of the function\n    \"\"\"\n    try:\n        from google_drive_downloader import GoogleDriveDownloader as gdd\n    except ImportError:\n        print(\"GoogleDriveDownloader package not installed. Installing ...\")\n        subprocess.check_call(\n            [\"python\", \"-m\", \"pip\", \"install\", \"googledrivedownloader\"]\n        )\n        from google_drive_downloader import GoogleDriveDownloader as gdd\n\n    file_id = gfile_url.split(\"/\")[5]\n    if verbose:\n        print(\"Google Drive file id: {}\".format(file_id))\n\n    dest_path = os.path.join(out_dir, file_name)\n    gdd.download_file_from_google_drive(file_id, dest_path, True, unzip)\n\n    return\n</code></pre>"},{"location":"common/#lidar.common.download_from_url","title":"<code>download_from_url(url, out_file_name=None, out_dir='.', unzip=True, verbose=True)</code>","text":"<p>Download a file from a URL (e.g., https://github.com/giswqs/whitebox/raw/master/examples/testdata.zip)</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The HTTP URL to download.</p> required <code>out_file_name</code> <code>str</code> <p>The output file name to use. Defaults to None.</p> <code>None</code> <code>out_dir</code> <code>str</code> <p>The output directory to use. Defaults to '.'.</p> <code>'.'</code> <code>unzip</code> <code>bool</code> <p>Whether to unzip the downloaded file if it is a zip file. Defaults to True.</p> <code>True</code> <code>verbose</code> <code>bool</code> <p>Whether to display or not the output of the function</p> <code>True</code> Source code in <code>lidar/common.py</code> <pre><code>def download_from_url(url, out_file_name=None, out_dir=\".\", unzip=True, verbose=True):\n    \"\"\"Download a file from a URL (e.g., https://github.com/giswqs/whitebox/raw/master/examples/testdata.zip)\n\n    Args:\n        url (str): The HTTP URL to download.\n        out_file_name (str, optional): The output file name to use. Defaults to None.\n        out_dir (str, optional): The output directory to use. Defaults to '.'.\n        unzip (bool, optional): Whether to unzip the downloaded file if it is a zip file. Defaults to True.\n        verbose (bool, optional): Whether to display or not the output of the function\n    \"\"\"\n    in_file_name = os.path.basename(url)\n\n    if out_file_name is None:\n        out_file_name = in_file_name\n    out_file_path = os.path.join(os.path.abspath(out_dir), out_file_name)\n\n    if verbose:\n        print(\"Downloading {} ...\".format(url))\n\n    try:\n        urllib.request.urlretrieve(url, out_file_path)\n    except Exception:\n        raise Exception(\"The URL is invalid. Please double check the URL.\")\n\n    final_path = out_file_path\n\n    if unzip:\n        # if it is a zip file\n        if \".zip\" in out_file_name:\n            if verbose:\n                print(\"Unzipping {} ...\".format(out_file_name))\n            with zipfile.ZipFile(out_file_path, \"r\") as zip_ref:\n                zip_ref.extractall(out_dir)\n            final_path = os.path.join(\n                os.path.abspath(out_dir), out_file_name.replace(\".zip\", \"\")\n            )\n\n        # if it is a tar file\n        if \".tar\" in out_file_name:\n            if verbose:\n                print(\"Unzipping {} ...\".format(out_file_name))\n            with tarfile.open(out_file_path, \"r\") as tar_ref:\n\n                def is_within_directory(directory, target):\n\n                    abs_directory = os.path.abspath(directory)\n                    abs_target = os.path.abspath(target)\n\n                    prefix = os.path.commonprefix([abs_directory, abs_target])\n\n                    return prefix == abs_directory\n\n                def safe_extract(tar, path=\".\", members=None, *, numeric_owner=False):\n\n                    for member in tar.getmembers():\n                        member_path = os.path.join(path, member.name)\n                        if not is_within_directory(path, member_path):\n                            raise Exception(\"Attempted Path Traversal in Tar File\")\n\n                    tar.extractall(path, members, numeric_owner=numeric_owner)\n\n                safe_extract(tar_ref, out_dir)\n            final_path = os.path.join(\n                os.path.abspath(out_dir), out_file_name.replace(\".tart\", \"\")\n            )\n\n    if verbose:\n        print(\"Data downloaded to: {}\".format(final_path))\n\n    return\n</code></pre>"},{"location":"common/#lidar.common.download_ned_by_bbox","title":"<code>download_ned_by_bbox(bbox, datasets=None, out_dir=None, return_url=False, download_args={}, **kwargs)</code>","text":"<p>Download the US National Elevation Datasets (NED) for a bounding box. See https://apps.nationalmap.gov/tnmaccess/#/ for more information.</p> <p>Parameters:</p> Name Type Description Default <code>bbox</code> <code>list</code> <p>The bounding box in the form [xmin, ymin, xmax, ymax].</p> required <code>huc_type</code> <code>str</code> <p>The HUC type, e.g., huc2, huc4, huc8. Defaults to \"huc8\".</p> required <code>datasets</code> <code>str</code> <p>Comma-delimited list of valid dataset tag names. The commonly used datasets include: Digital Elevation Model (DEM) 1 meter National Elevation Dataset (NED) 1/3 arc-second Current National Elevation Dataset (NED) 1/9 arc-second Current National Elevation Dataset (NED) 1 arc-second Current For more information, see https://apps.nationalmap.gov/tnmaccess/#/product Defaults to None, which will be the (NED) 1/3 arc-second</p> <code>None</code> <code>out_dir</code> <code>str</code> <p>The output directory. Defaults to None, which will use the current working directory.</p> <code>None</code> <code>return_url</code> <code>bool</code> <p>If True, the URL will be returned instead of downloading the data. Defaults to False.</p> <code>False</code> <code>download_args</code> <code>dict</code> <p>The download arguments to be passed to the download_file function. Defaults to {}.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>list</code> <p>The list of downloaded files.</p> Source code in <code>lidar/common.py</code> <pre><code>def download_ned_by_bbox(\n    bbox,\n    datasets=None,\n    out_dir=None,\n    return_url=False,\n    download_args={},\n    **kwargs,\n):\n    \"\"\"Download the US National Elevation Datasets (NED) for a bounding box. See https://apps.nationalmap.gov/tnmaccess/#/ for more information.\n\n    Args:\n        bbox (list): The bounding box in the form [xmin, ymin, xmax, ymax].\n        huc_type (str, optional): The HUC type, e.g., huc2, huc4, huc8. Defaults to \"huc8\".\n        datasets (str, optional): Comma-delimited list of valid dataset tag names. The commonly used datasets include:\n            Digital Elevation Model (DEM) 1 meter\n            National Elevation Dataset (NED) 1/3 arc-second Current\n            National Elevation Dataset (NED) 1/9 arc-second Current\n            National Elevation Dataset (NED) 1 arc-second Current\n            For more information, see https://apps.nationalmap.gov/tnmaccess/#/product\n            Defaults to None, which will be the (NED) 1/3 arc-second\n        out_dir (str, optional): The output directory. Defaults to None, which will use the current working directory.\n        return_url (bool, optional): If True, the URL will be returned instead of downloading the data. Defaults to False.\n        download_args (dict, optional): The download arguments to be passed to the download_file function. Defaults to {}.\n\n    Returns:\n        list: The list of downloaded files.\n    \"\"\"\n\n    import requests\n\n    endpoint = \"https://tnmaccess.nationalmap.gov/api/v1/products?\"\n\n    if datasets is None:\n        datasets = \"National Elevation Dataset (NED) 1/3 arc-second Current\"\n\n    if out_dir is None:\n        out_dir = os.getcwd()\n\n    if isinstance(bbox, list):\n        bbox = \",\".join([str(x) for x in bbox])\n\n    kwargs[\"datasets\"] = datasets\n    kwargs[\"bbox\"] = bbox\n\n    result = requests.get(endpoint, params=kwargs).json()\n    if \"errorMessage\" in result:\n        raise ValueError(result[\"errorMessage\"])\n    else:\n        links = [x[\"downloadURL\"] for x in result[\"items\"]]\n        for index, link in enumerate(links):\n            if \"historical\" in link:\n                link = link.replace(\"historical\", \"current\")[:-13] + \".tif\"\n                links[index] = link\n\n    if return_url:\n        return links\n    else:\n        for index, link in enumerate(links):\n\n            r = requests.head(link)\n            if r.status_code == 200:\n                filepath = os.path.join(out_dir, os.path.basename(link))\n                print(\n                    f\"Downloading {index + 1} of {len(links)}: {os.path.basename(link)}\"\n                )\n                download_file(link, filepath, **download_args)\n            else:\n                print(f\"{link} does not exist.\")\n</code></pre>"},{"location":"common/#lidar.common.download_ned_by_huc","title":"<code>download_ned_by_huc(huc_id, huc_type='huc8', datasets=None, out_dir=None, return_url=False, download_args={}, **kwargs)</code>","text":"<p>Download the US National Elevation Datasets (NED) for a Hydrologic Unit region. See https://apps.nationalmap.gov/tnmaccess/#/ for more information.</p> <p>Parameters:</p> Name Type Description Default <code>huc_id</code> <code>str</code> <p>The HUC ID, for example, \"01010002\"</p> required <code>huc_type</code> <code>str</code> <p>The HUC type, e.g., huc2, huc4, huc8. Defaults to \"huc8\".</p> <code>'huc8'</code> <code>datasets</code> <code>str</code> <p>Comma-delimited list of valid dataset tag names. The commonly used datasets include: Digital Elevation Model (DEM) 1 meter National Elevation Dataset (NED) 1/3 arc-second Current National Elevation Dataset (NED) 1/9 arc-second Current National Elevation Dataset (NED) 1 arc-second Current For more information, see https://apps.nationalmap.gov/tnmaccess/#/product Defaults to None, which will be the (NED) 1/3 arc-second</p> <code>None</code> <code>out_dir</code> <code>str</code> <p>The output directory. Defaults to None, which will use the current working directory.</p> <code>None</code> <code>return_url</code> <code>bool</code> <p>If True, the URL will be returned instead of downloading the data. Defaults to False.</p> <code>False</code> <code>download_args</code> <code>dict</code> <p>The download arguments to be passed to the download_file function. Defaults to {}.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>list</code> <p>The list of downloaded files.</p> Source code in <code>lidar/common.py</code> <pre><code>def download_ned_by_huc(\n    huc_id,\n    huc_type=\"huc8\",\n    datasets=None,\n    out_dir=None,\n    return_url=False,\n    download_args={},\n    **kwargs,\n):\n    \"\"\"Download the US National Elevation Datasets (NED) for a Hydrologic Unit region. See https://apps.nationalmap.gov/tnmaccess/#/ for more information.\n\n    Args:\n        huc_id (str): The HUC ID, for example, \"01010002\"\n        huc_type (str, optional): The HUC type, e.g., huc2, huc4, huc8. Defaults to \"huc8\".\n        datasets (str, optional): Comma-delimited list of valid dataset tag names. The commonly used datasets include:\n            Digital Elevation Model (DEM) 1 meter\n            National Elevation Dataset (NED) 1/3 arc-second Current\n            National Elevation Dataset (NED) 1/9 arc-second Current\n            National Elevation Dataset (NED) 1 arc-second Current\n            For more information, see https://apps.nationalmap.gov/tnmaccess/#/product\n            Defaults to None, which will be the (NED) 1/3 arc-second\n        out_dir (str, optional): The output directory. Defaults to None, which will use the current working directory.\n        return_url (bool, optional): If True, the URL will be returned instead of downloading the data. Defaults to False.\n        download_args (dict, optional): The download arguments to be passed to the download_file function. Defaults to {}.\n\n    Returns:\n        list: The list of downloaded files.\n    \"\"\"\n\n    import requests\n\n    endpoint = \"https://tnmaccess.nationalmap.gov/api/v1/products?\"\n\n    if datasets is None:\n        datasets = \"National Elevation Dataset (NED) 1/3 arc-second Current\"\n\n    if out_dir is None:\n        out_dir = os.getcwd()\n\n    kwargs[\"datasets\"] = datasets\n    kwargs[\"polyType\"] = huc_type\n    kwargs[\"polyCode\"] = huc_id\n\n    result = requests.get(endpoint, params=kwargs).json()\n    if \"errorMessage\" in result:\n        raise ValueError(result[\"errorMessage\"])\n    else:\n        links = [x[\"downloadURL\"] for x in result[\"items\"]]\n        for index, link in enumerate(links):\n            if \"historical\" in link:\n                link = link.replace(\"historical\", \"current\")[:-13] + \".tif\"\n                links[index] = link\n\n    if return_url:\n        return links\n    else:\n        for index, link in enumerate(links):\n\n            r = requests.head(link)\n            if r.status_code == 200:\n                filepath = os.path.join(out_dir, os.path.basename(link))\n                print(\n                    f\"Downloading {index + 1} of {len(links)}: {os.path.basename(link)}\"\n                )\n                download_file(link, filepath, **download_args)\n            else:\n                print(f\"{link} does not exist.\")\n</code></pre>"},{"location":"common/#lidar.common.geometry_bounds","title":"<code>geometry_bounds(geometry, decimals=4)</code>","text":"<p>Returns the bounds of a geometry.</p> <p>Parameters:</p> Name Type Description Default <code>geometry</code> <code>dict</code> <p>A GeoJSON geometry.</p> required <code>decimals</code> <code>int</code> <p>The number of decimal places to round the bounds to. Defaults to 4.</p> <code>4</code> <p>Returns:</p> Name Type Description <code>list</code> <p>A list of bounds in the form of [minx, miny, maxx, maxy].</p> Source code in <code>lidar/common.py</code> <pre><code>def geometry_bounds(geometry, decimals=4):\n    \"\"\"Returns the bounds of a geometry.\n\n    Args:\n        geometry (dict): A GeoJSON geometry.\n        decimals (int, optional): The number of decimal places to round the bounds to. Defaults to 4.\n\n    Returns:\n        list: A list of bounds in the form of [minx, miny, maxx, maxy].\n    \"\"\"\n    if isinstance(geometry, dict):\n        if \"geometry\" in geometry:\n            coords = geometry[\"geometry\"][\"coordinates\"][0]\n        else:\n            coords = geometry[\"coordinates\"][0]\n\n    else:\n        raise ValueError(\"geometry must be a GeoJSON-like dictionary.\")\n\n    x = [p[0] for p in coords]\n    y = [p[1] for p in coords]\n    west = round(min(x), decimals)\n    east = round(max(x), decimals)\n    south = round(min(y), decimals)\n    north = round(max(y), decimals)\n    return [west, south, east, north]\n</code></pre>"},{"location":"common/#lidar.common.github_raw_url","title":"<code>github_raw_url(url)</code>","text":"<p>Get the raw URL for a GitHub file.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The GitHub URL.</p> required <p>Returns:     str: The raw URL.</p> Source code in <code>lidar/common.py</code> <pre><code>def github_raw_url(url):\n    \"\"\"Get the raw URL for a GitHub file.\n\n    Args:\n        url (str): The GitHub URL.\n    Returns:\n        str: The raw URL.\n    \"\"\"\n    if isinstance(url, str) and url.startswith(\"https://github.com/\") and \"blob\" in url:\n        url = url.replace(\"github.com\", \"raw.githubusercontent.com\").replace(\n            \"blob/\", \"\"\n        )\n    return url\n</code></pre>"},{"location":"common/#lidar.common.in_colab_shell","title":"<code>in_colab_shell()</code>","text":"<p>Tests if the code is being executed within Google Colab.</p> Source code in <code>lidar/common.py</code> <pre><code>def in_colab_shell():\n    \"\"\"Tests if the code is being executed within Google Colab.\"\"\"\n    try:\n        import google.colab  # pylint: disable=unused-variable\n\n        return True\n    except ImportError:\n        return False\n</code></pre>"},{"location":"common/#lidar.common.is_drive_mounted","title":"<code>is_drive_mounted()</code>","text":"<p>Checks whether Google Drive is mounted in Google Colab.</p> <p>Returns:</p> Name Type Description <code>bool</code> <p>Returns True if Google Drive is mounted, False otherwise.</p> Source code in <code>lidar/common.py</code> <pre><code>def is_drive_mounted():\n    \"\"\"Checks whether Google Drive is mounted in Google Colab.\n\n    Returns:\n        bool: Returns True if Google Drive is mounted, False otherwise.\n    \"\"\"\n    drive_path = \"/content/drive/My Drive\"\n    if os.path.exists(drive_path):\n        return True\n    else:\n        return False\n</code></pre>"},{"location":"common/#lidar.common.is_tool","title":"<code>is_tool(name)</code>","text":"<p>Check whether <code>name</code> is on PATH and marked as executable.</p> Source code in <code>lidar/common.py</code> <pre><code>def is_tool(name):\n    \"\"\"Check whether `name` is on PATH and marked as executable.\"\"\"\n\n    from shutil import which\n\n    return which(name) is not None\n</code></pre>"},{"location":"common/#lidar.common.join_csv_to_gdf","title":"<code>join_csv_to_gdf(shapefile_path, csv_path, gdf_join_column, csv_join_column)</code>","text":"<p>Joins a CSV file to a GeoDataFrame based on a common column.</p> <p>Parameters:</p> Name Type Description Default <code>shapefile_path</code> <code>str</code> <p>Path to the Shapefile.</p> required <code>csv_path</code> <code>str</code> <p>Path to the CSV file.</p> required <code>gdf_join_column</code> <code>str</code> <p>Name of the join column in the GeoDataFrame.</p> required <code>csv_join_column</code> <code>str</code> <p>Name of the join column in the CSV.</p> required <p>Returns:</p> Type Description <p>geopandas.GeoDataFrame: The GeoDataFrame with the joined data.</p> Source code in <code>lidar/common.py</code> <pre><code>def join_csv_to_gdf(shapefile_path, csv_path, gdf_join_column, csv_join_column):\n    \"\"\"\n    Joins a CSV file to a GeoDataFrame based on a common column.\n\n    Args:\n        shapefile_path (str): Path to the Shapefile.\n        csv_path (str): Path to the CSV file.\n        gdf_join_column (str): Name of the join column in the GeoDataFrame.\n        csv_join_column (str): Name of the join column in the CSV.\n\n    Returns:\n        geopandas.GeoDataFrame: The GeoDataFrame with the joined data.\n    \"\"\"\n    import pandas as pd\n    import geopandas as gpd\n\n    # Load the datasets\n    gdf = gpd.read_file(shapefile_path)\n    csv_data = pd.read_csv(csv_path)\n\n    # Perform the join\n    result = gdf.merge(\n        csv_data, left_on=gdf_join_column, right_on=csv_join_column, how=\"left\"\n    )\n\n    return result\n</code></pre>"},{"location":"common/#lidar.common.join_tables","title":"<code>join_tables(in_shp, in_csv, out_shp)</code>","text":"<p>Joins a CSV table to a shapefile.</p> <p>Parameters:</p> Name Type Description Default <code>in_shp</code> <code>str</code> <p>Path to the input shapefile.</p> required <code>in_csv</code> <code>str</code> <p>Path to the input CSV file.</p> required <code>out_shp</code> <code>str</code> <p>Path to the output shapefile.</p> required Source code in <code>lidar/common.py</code> <pre><code>def join_tables(in_shp, in_csv, out_shp):\n    \"\"\"Joins a CSV table to a shapefile.\n\n    Args:\n        in_shp (str): Path to the input shapefile.\n        in_csv (str): Path to the input CSV file.\n        out_shp (str): Path to the output shapefile.\n    \"\"\"\n    import geopandas as gpd\n    import pandas as pd\n\n    dep_df = gpd.read_file(in_shp)\n    info_df = pd.read_csv(in_csv)\n    if len(info_df) &gt; 0:\n        info_df.columns = [col.replace(\"-\", \"_\")[:10] for col in info_df.columns]\n        info_df[\"id\"] = info_df[\"region_id\"]\n        info_df.drop(\"region_id\", axis=1, inplace=True)\n        df = pd.merge(dep_df, info_df, on=\"id\")\n        df.to_file(out_shp)\n    else:\n        print(\"No data to join\")\n</code></pre>"},{"location":"common/#lidar.common.lidar_to_dsm","title":"<code>lidar_to_dsm(filename, output=None, resolution=1.0, radius=0.5, minz=None, maxz=None, max_triangle_edge_length=None, verbose=True, **kwargs)</code>","text":"<p>Generates a digital surface model (DSM) from a LiDAR point cloud. It is a wrapper for the <code>whitebox.lidar_digital_surface_model</code>.     See https://www.whiteboxgeo.com/manual/wbt_book/available_tools/lidar_tools.html#LidarDigitalSurfaceModel</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>The input LiDAR file.</p> required <code>output</code> <code>str</code> <p>The output file. Defaults to None.</p> <code>None</code> <code>resolution</code> <code>float</code> <p>The resolution of the output raster. Defaults to 1.0.</p> <code>1.0</code> <code>radius</code> <code>float</code> <p>The search radius. Defaults to 0.5.</p> <code>0.5</code> <code>minz</code> <code>float</code> <p>Optional minimum elevation for inclusion in interpolation.</p> <code>None</code> <code>maxz</code> <code>float</code> <p>Optional maximum elevation for inclusion in interpolation.</p> <code>None</code> <code>max_triangle_edge_length</code> <code>float</code> <p>Optional maximum triangle edge length; triangles larger than this size will not be gridded</p> <code>None</code> <code>verbose</code> <code>bool</code> <p>description. Defaults to True.</p> <code>True</code> Source code in <code>lidar/common.py</code> <pre><code>def lidar_to_dsm(\n    filename,\n    output=None,\n    resolution=1.0,\n    radius=0.5,\n    minz=None,\n    maxz=None,\n    max_triangle_edge_length=None,\n    verbose=True,\n    **kwargs,\n):\n    \"\"\"Generates a digital surface model (DSM) from a LiDAR point cloud. It is a wrapper for the `whitebox.lidar_digital_surface_model`.\n        See https://www.whiteboxgeo.com/manual/wbt_book/available_tools/lidar_tools.html#LidarDigitalSurfaceModel\n\n    Args:\n        filename (str): The input LiDAR file.\n        output (str, optional): The output file. Defaults to None.\n        resolution (float, optional): The resolution of the output raster. Defaults to 1.0.\n        radius (float, optional): The search radius. Defaults to 0.5.\n        minz (float, optional): Optional minimum elevation for inclusion in interpolation.\n        maxz (float, optional): Optional maximum elevation for inclusion in interpolation.\n        max_triangle_edge_length (float, optional): Optional maximum triangle edge length; triangles larger than this size will not be gridded\n        verbose (bool, optional): _description_. Defaults to True.\n    \"\"\"\n    import whitebox\n\n    wbt = whitebox.WhiteboxTools()\n    wbt.verbose = verbose\n\n    filename = os.path.abspath(filename)\n    if output is not None:\n        output = os.path.abspath(output)\n\n    wbt.lidar_digital_surface_model(\n        i=filename,\n        output=output,\n        resolution=resolution,\n        radius=radius,\n        minz=minz,\n        maxz=maxz,\n        max_triangle_edge_length=max_triangle_edge_length,\n        **kwargs,\n    )\n</code></pre>"},{"location":"common/#lidar.common.mosaic","title":"<code>mosaic(images, output, ext='.tif', merge_args={}, verbose=True, **kwargs)</code>","text":"<p>Mosaics a list of images into a single image. Inspired by https://bit.ly/3A6roDK.</p> <p>Parameters:</p> Name Type Description Default <code>images</code> <code>str | list</code> <p>An input directory containing images or a list of images.</p> required <code>output</code> <code>str</code> <p>The output image filepath.</p> required <code>ext</code> <code>str</code> <p>The image file extension. Defaults to '.tif'.</p> <code>'.tif'</code> <code>merge_args</code> <code>dict</code> <p>A dictionary of arguments to pass to the rasterio.merge function. Defaults to {}.</p> <code>{}</code> <code>verbose</code> <code>bool</code> <p>Whether to print progress. Defaults to True.</p> <code>True</code> Source code in <code>lidar/common.py</code> <pre><code>def mosaic(images, output, ext=\".tif\", merge_args={}, verbose=True, **kwargs):\n    \"\"\"Mosaics a list of images into a single image. Inspired by https://bit.ly/3A6roDK.\n\n    Args:\n        images (str | list): An input directory containing images or a list of images.\n        output (str): The output image filepath.\n        ext (str, optional): The image file extension. Defaults to '.tif'.\n        merge_args (dict, optional): A dictionary of arguments to pass to the rasterio.merge function. Defaults to {}.\n        verbose (bool, optional): Whether to print progress. Defaults to True.\n\n    \"\"\"\n    from rasterio.merge import merge\n    import rasterio as rio\n    from pathlib import Path\n    import shutil\n\n    output = os.path.abspath(output)\n\n    if isinstance(images, str):\n        path = Path(images)\n        raster_files = list(path.iterdir())\n        raster_files = [f for f in raster_files if f.suffix == ext]\n    elif isinstance(images, list):\n        raster_files = images\n    else:\n        raise ValueError(\"images must be a list of raster files.\")\n\n    if len(raster_files) == 0:\n        print(\"No raster files found.\")\n        return\n    elif len(raster_files) == 1:\n        shutil.copyfile(raster_files[0], output)\n        return\n\n    raster_to_mosiac = []\n\n    if not os.path.exists(os.path.dirname(output)):\n        os.makedirs(os.path.dirname(output))\n\n    for index, p in enumerate(raster_files):\n        if verbose:\n            print(f\"Reading {index+1}/{len(raster_files)}: {os.path.basename(p)}\")\n        raster = rio.open(p, **kwargs)\n        raster_to_mosiac.append(raster)\n\n    if verbose:\n        print(\"Merging rasters...\")\n    arr, transform = merge(raster_to_mosiac, **merge_args)\n\n    output_meta = raster.meta.copy()\n    output_meta.update(\n        {\n            \"driver\": \"GTiff\",\n            \"height\": arr.shape[1],\n            \"width\": arr.shape[2],\n            \"transform\": transform,\n        }\n    )\n\n    with rio.open(output, \"w\", **output_meta) as m:\n        m.write(arr)\n</code></pre>"},{"location":"common/#lidar.common.random_string","title":"<code>random_string(string_length=3)</code>","text":"<p>Generates a random string of fixed length.</p> <p>Parameters:</p> Name Type Description Default <code>string_length</code> <code>int</code> <p>Fixed length. Defaults to 3.</p> <code>3</code> <p>Returns:</p> Name Type Description <code>str</code> <p>A random string</p> Source code in <code>lidar/common.py</code> <pre><code>def random_string(string_length=3):\n    \"\"\"Generates a random string of fixed length.\n\n    Args:\n        string_length (int, optional): Fixed length. Defaults to 3.\n\n    Returns:\n        str: A random string\n    \"\"\"\n    import random\n    import string\n\n    # random.seed(1001)\n    letters = string.ascii_lowercase\n    return \"\".join(random.choice(letters) for i in range(string_length))\n</code></pre>"},{"location":"common/#lidar.common.read_lidar","title":"<code>read_lidar(filename, **kwargs)</code>","text":"<p>Read a LAS file.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>A local file path or HTTP URL to a LAS file.</p> required <p>Returns:</p> Name Type Description <code>LasData</code> <p>The LasData object return by laspy.read.</p> Source code in <code>lidar/common.py</code> <pre><code>def read_lidar(filename, **kwargs):\n    \"\"\"Read a LAS file.\n\n    Args:\n        filename (str): A local file path or HTTP URL to a LAS file.\n\n    Returns:\n        LasData: The LasData object return by laspy.read.\n    \"\"\"\n    try:\n        import laspy\n    except ImportError:\n        print(\n            \"The laspy package is required for this function. Use `pip install laspy[lazrs,laszip]` to install it.\"\n        )\n        return\n\n    if (\n        isinstance(filename, str)\n        and filename.startswith(\"http\")\n        and (filename.endswith(\".las\") or filename.endswith(\".laz\"))\n    ):\n        filename = github_raw_url(filename)\n        filename = download_file(filename)\n\n    return laspy.read(filename, **kwargs)\n</code></pre>"},{"location":"common/#lidar.common.reproject_image","title":"<code>reproject_image(image, output, dst_crs='EPSG:4326', resampling='nearest', **kwargs)</code>","text":"<p>Reprojects an image.</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>str</code> <p>The input image filepath.</p> required <code>output</code> <code>str</code> <p>The output image filepath.</p> required <code>dst_crs</code> <code>str</code> <p>The destination CRS. Defaults to \"EPSG:4326\".</p> <code>'EPSG:4326'</code> <code>resampling</code> <code>Resampling</code> <p>The resampling method. Defaults to \"nearest\".</p> <code>'nearest'</code> <code>**kwargs</code> <p>Additional keyword arguments to pass to rasterio.open.</p> <code>{}</code> Source code in <code>lidar/common.py</code> <pre><code>def reproject_image(image, output, dst_crs=\"EPSG:4326\", resampling=\"nearest\", **kwargs):\n    \"\"\"Reprojects an image.\n\n    Args:\n        image (str): The input image filepath.\n        output (str): The output image filepath.\n        dst_crs (str, optional): The destination CRS. Defaults to \"EPSG:4326\".\n        resampling (Resampling, optional): The resampling method. Defaults to \"nearest\".\n        **kwargs: Additional keyword arguments to pass to rasterio.open.\n\n    \"\"\"\n    import rasterio as rio\n    from rasterio.warp import calculate_default_transform, reproject, Resampling\n\n    if isinstance(resampling, str):\n        resampling = getattr(Resampling, resampling)\n\n    image = os.path.abspath(image)\n    output = os.path.abspath(output)\n\n    if not os.path.exists(os.path.dirname(output)):\n        os.makedirs(os.path.dirname(output))\n\n    with rio.open(image, **kwargs) as src:\n        transform, width, height = calculate_default_transform(\n            src.crs, dst_crs, src.width, src.height, *src.bounds\n        )\n        kwargs = src.meta.copy()\n        kwargs.update(\n            {\n                \"crs\": dst_crs,\n                \"transform\": transform,\n                \"width\": width,\n                \"height\": height,\n            }\n        )\n\n        with rio.open(output, \"w\", **kwargs) as dst:\n            for i in range(1, src.count + 1):\n                reproject(\n                    source=rio.band(src, i),\n                    destination=rio.band(dst, i),\n                    src_transform=src.transform,\n                    src_crs=src.crs,\n                    dst_transform=transform,\n                    dst_crs=dst_crs,\n                    resampling=resampling,\n                    dst_resolution=(10, 10),\n                    **kwargs,\n                )\n</code></pre>"},{"location":"common/#lidar.common.resample","title":"<code>resample(src, dst, resolution, **kwargs)</code>","text":"<p>Resample a raster to a new resolution.</p> <p>Parameters:</p> Name Type Description Default <code>src</code> <code>str</code> <p>The source raster.</p> required <code>dst</code> <code>str</code> <p>The destination raster.</p> required <code>resolution</code> <code>float</code> <p>The new resolution.</p> required Source code in <code>lidar/common.py</code> <pre><code>def resample(src, dst, resolution, **kwargs):\n    \"\"\"Resample a raster to a new resolution.\n\n    Args:\n        src (str): The source raster.\n        dst (str): The destination raster.\n        resolution (float): The new resolution.\n    \"\"\"\n    from osgeo import gdal\n\n    gdal.Warp(dst, src, xRes=resolution, yRes=resolution, **kwargs)\n</code></pre>"},{"location":"common/#lidar.common.temp_file_path","title":"<code>temp_file_path(extension)</code>","text":"<p>Returns a temporary file path.</p> <p>Parameters:</p> Name Type Description Default <code>extension</code> <code>str</code> <p>The file extension.</p> required <p>Returns:</p> Name Type Description <code>str</code> <p>The temporary file path.</p> Source code in <code>lidar/common.py</code> <pre><code>def temp_file_path(extension):\n    \"\"\"Returns a temporary file path.\n\n    Args:\n        extension (str): The file extension.\n\n    Returns:\n        str: The temporary file path.\n    \"\"\"\n\n    import tempfile\n    import uuid\n\n    if not extension.startswith(\".\"):\n        extension = \".\" + extension\n    file_id = str(uuid.uuid4())\n    file_path = os.path.join(tempfile.gettempdir(), f\"{file_id}{extension}\")\n\n    return file_path\n</code></pre>"},{"location":"common/#lidar.common.update_package","title":"<code>update_package()</code>","text":"<p>Updates the lidar package from the lidar GitHub repository without the need to use pip or conda. In this way, I don't have to keep updating pypi and conda-forge with every minor update of the package.</p> Source code in <code>lidar/common.py</code> <pre><code>def update_package():\n    \"\"\"Updates the lidar package from the lidar GitHub repository without the need to use pip or conda.\n    In this way, I don't have to keep updating pypi and conda-forge with every minor update of the package.\n\n    \"\"\"\n    import shutil\n\n    try:\n        download_dir = os.path.join(os.path.expanduser(\"~\"), \"Downloads\")\n        if not os.path.exists(download_dir):\n            os.makedirs(download_dir)\n        clone_repo(out_dir=download_dir)\n\n        pkg_dir = os.path.join(download_dir, \"lidar-master\")\n        work_dir = os.getcwd()\n        os.chdir(pkg_dir)\n\n        if shutil.which(\"pip\") is None:\n            cmd = \"pip3 install .\"\n        else:\n            cmd = \"pip install .\"\n\n        os.system(cmd)\n        os.chdir(work_dir)\n\n        print(\n            \"\\nPlease comment out 'lidar.update_package()' and restart the kernel to take effect:\\nJupyter menu -&gt; Kernel -&gt; Restart &amp; Clear Output\"\n        )\n\n    except Exception as e:\n        raise Exception(e)\n</code></pre>"},{"location":"common/#lidar.common.view_lidar","title":"<code>view_lidar(filename, cmap='terrain', backend='pyvista', background=None, eye_dome_lighting=False, **kwargs)</code>","text":"<p>View LiDAR data in 3D.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>The filepath to the LiDAR data.</p> required <code>cmap</code> <code>str</code> <p>The colormap to use. Defaults to \"terrain\". cmap currently does not work for the open3d backend.</p> <code>'terrain'</code> <code>backend</code> <code>str</code> <p>The plotting backend to use, can be pyvista, ipygany, panel, and open3d. Defaults to \"pyvista\".</p> <code>'pyvista'</code> <code>background</code> <code>str</code> <p>The background color to use. Defaults to None.</p> <code>None</code> <code>eye_dome_lighting</code> <code>bool</code> <p>Whether to use eye dome lighting. Defaults to False.</p> <code>False</code> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the file does not exist.</p> <code>ValueError</code> <p>If the backend is not supported.</p> Source code in <code>lidar/common.py</code> <pre><code>def view_lidar(\n    filename,\n    cmap=\"terrain\",\n    backend=\"pyvista\",\n    background=None,\n    eye_dome_lighting=False,\n    **kwargs,\n):\n    \"\"\"View LiDAR data in 3D.\n\n    Args:\n        filename (str): The filepath to the LiDAR data.\n        cmap (str, optional): The colormap to use. Defaults to \"terrain\". cmap currently does not work for the open3d backend.\n        backend (str, optional): The plotting backend to use, can be pyvista, ipygany, panel, and open3d. Defaults to \"pyvista\".\n        background (str, optional): The background color to use. Defaults to None.\n        eye_dome_lighting (bool, optional): Whether to use eye dome lighting. Defaults to False.\n\n    Raises:\n        FileNotFoundError: If the file does not exist.\n        ValueError: If the backend is not supported.\n    \"\"\"\n\n    import sys\n\n    if os.environ.get(\"USE_MKDOCS\") is not None:\n        return\n\n    if \"google.colab\" in sys.modules:\n        print(\"This function is not supported in Google Colab.\")\n        return\n\n    warnings.filterwarnings(\"ignore\")\n    filename = os.path.abspath(filename)\n    if not os.path.exists(filename):\n        raise FileNotFoundError(f\"{filename} does not exist.\")\n\n    backend = backend.lower()\n    if backend in [\"pyvista\", \"ipygany\", \"panel\"]:\n        try:\n            import pyntcloud\n        except ImportError:\n            print(\n                \"The pyvista and pyntcloud packages are required for this function. Use pip install leafmap[lidar] to install them.\"\n            )\n            return\n\n        try:\n            if backend == \"pyvista\":\n                backend = None\n            if backend == \"ipygany\":\n                cmap = None\n            data = pyntcloud.PyntCloud.from_file(filename)\n            mesh = data.to_instance(\"pyvista\", mesh=False)\n            mesh = mesh.elevation()\n            mesh.plot(\n                scalars=\"Elevation\",\n                cmap=cmap,\n                jupyter_backend=backend,\n                background=background,\n                eye_dome_lighting=eye_dome_lighting,\n                **kwargs,\n            )\n\n        except Exception as e:\n            print(\"Something went wrong.\")\n            print(e)\n            return\n\n    elif backend == \"open3d\":\n        try:\n            import laspy\n            import open3d as o3d\n            import numpy as np\n        except ImportError:\n            print(\n                \"The laspy and open3d packages are required for this function. Use pip install laspy open3d to install them.\"\n            )\n            return\n\n        try:\n            las = laspy.read(filename)\n            point_data = np.stack([las.X, las.Y, las.Z], axis=0).transpose((1, 0))\n            geom = o3d.geometry.PointCloud()\n            geom.points = o3d.utility.Vector3dVector(point_data)\n            # geom.colors =  o3d.utility.Vector3dVector(colors)  # need to add colors. A list in the form of [[r,g,b], [r,g,b]] with value range 0-1. https://github.com/isl-org/Open3D/issues/614\n            o3d.visualization.draw_geometries([geom], **kwargs)\n\n        except Exception as e:\n            print(\"Something went wrong.\")\n            print(e)\n            return\n\n    else:\n        raise ValueError(f\"{backend} is not a valid backend.\")\n</code></pre>"},{"location":"common/#lidar.common.write_lidar","title":"<code>write_lidar(source, destination, do_compress=None, laz_backend=None)</code>","text":"<p>Writes to a stream or file.</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>str | LasBase</code> <p>The source data to be written.</p> required <code>destination</code> <code>str</code> <p>The destination filepath.</p> required <code>do_compress</code> <code>bool</code> <p>Flags to indicate if you want to compress the data. Defaults to None.</p> <code>None</code> <code>laz_backend</code> <code>str</code> <p>The laz backend to use. Defaults to None.</p> <code>None</code> Source code in <code>lidar/common.py</code> <pre><code>def write_lidar(source, destination, do_compress=None, laz_backend=None):\n    \"\"\"Writes to a stream or file.\n\n    Args:\n        source (str | laspy.lasdatas.base.LasBase): The source data to be written.\n        destination (str): The destination filepath.\n        do_compress (bool, optional): Flags to indicate if you want to compress the data. Defaults to None.\n        laz_backend (str, optional): The laz backend to use. Defaults to None.\n    \"\"\"\n\n    try:\n        import laspy\n    except ImportError:\n        print(\n            \"The laspy package is required for this function. Use `pip install laspy[lazrs,laszip]` to install it.\"\n        )\n        return\n\n    if isinstance(source, str):\n        source = read_lidar(source)\n\n    source.write(destination, do_compress=do_compress, laz_backend=laz_backend)\n</code></pre>"},{"location":"conf/","title":"Conf","text":"<p>lidar documentation build configuration file, created by sphinx-quickstart on Fri Jun  9 13:47:02 2017.</p> <p>This file is execfile()d with the current directory set to its containing dir.</p> <p>Note that not all possible configuration values are present in this autogenerated file.</p> <p>All configuration values have a default; values that are commented out serve to show the default.</p> In\u00a0[\u00a0]: Copied! <pre># If extensions (or modules to document with autodoc) are in another\n# directory, add these directories to sys.path here. If the directory is\n# relative to the documentation root, use os.path.abspath to make it\n# absolute, like shown here.\n#\nimport os\nimport sys\n</pre> # If extensions (or modules to document with autodoc) are in another # directory, add these directories to sys.path here. If the directory is # relative to the documentation root, use os.path.abspath to make it # absolute, like shown here. # import os import sys In\u00a0[\u00a0]: Copied! <pre>sys.path.insert(0, os.path.abspath(\"..\"))\n</pre> sys.path.insert(0, os.path.abspath(\"..\")) In\u00a0[\u00a0]: Copied! <pre>from unittest.mock import MagicMock\n</pre> from unittest.mock import MagicMock In\u00a0[\u00a0]: Copied! <pre>class Mock(MagicMock):\n    @classmethod\n    def __getattr__(cls, name):\n        return MagicMock()\n</pre> class Mock(MagicMock):     @classmethod     def __getattr__(cls, name):         return MagicMock() In\u00a0[\u00a0]: Copied! <pre>MOCK_MODULES = [\n    \"pygtk\",\n    \"gtk\",\n    \"gobject\",\n    \"argparse\",\n    \"numpy\",\n    \"pandas\",\n    \"richdem\",\n    \"scipy\",\n    \"skimage\",\n    \"osgeo\",\n    # \"PySimpleGUI\",\n]\nsys.modules.update((mod_name, Mock()) for mod_name in MOCK_MODULES)\nimport lidar\n</pre> MOCK_MODULES = [     \"pygtk\",     \"gtk\",     \"gobject\",     \"argparse\",     \"numpy\",     \"pandas\",     \"richdem\",     \"scipy\",     \"skimage\",     \"osgeo\",     # \"PySimpleGUI\", ] sys.modules.update((mod_name, Mock()) for mod_name in MOCK_MODULES) import lidar <p>-- General configuration ---------------------------------------------</p> <p>If your documentation needs a minimal Sphinx version, state it here.</p> <p>needs_sphinx = '1.0'</p> In\u00a0[\u00a0]: Copied! <pre># Add any Sphinx extension module names here, as strings. They can be\n# extensions coming with Sphinx (named 'sphinx.ext.*') or your custom ones.\nextensions = [\"sphinx.ext.autodoc\", \"sphinx.ext.viewcode\", \"sphinx.ext.napoleon\"]\n</pre> # Add any Sphinx extension module names here, as strings. They can be # extensions coming with Sphinx (named 'sphinx.ext.*') or your custom ones. extensions = [\"sphinx.ext.autodoc\", \"sphinx.ext.viewcode\", \"sphinx.ext.napoleon\"] In\u00a0[\u00a0]: Copied! <pre># Add any paths that contain templates here, relative to this directory.\ntemplates_path = [\"_templates\"]\n</pre> # Add any paths that contain templates here, relative to this directory. templates_path = [\"_templates\"] In\u00a0[\u00a0]: Copied! <pre># The suffix(es) of source filenames.\n# You can specify multiple suffix as a list of string:\n#\n# source_suffix = ['.rst', '.md']\nsource_suffix = \".rst\"\n</pre> # The suffix(es) of source filenames. # You can specify multiple suffix as a list of string: # # source_suffix = ['.rst', '.md'] source_suffix = \".rst\" In\u00a0[\u00a0]: Copied! <pre># The master toctree document.\nmaster_doc = \"index\"\n</pre> # The master toctree document. master_doc = \"index\" In\u00a0[\u00a0]: Copied! <pre># General information about the project.\nproject = \"lidar\"\ncopyright = \"2020, Qiusheng Wu\"\nauthor = \"Qiusheng Wu\"\n</pre> # General information about the project. project = \"lidar\" copyright = \"2020, Qiusheng Wu\" author = \"Qiusheng Wu\" In\u00a0[\u00a0]: Copied! <pre># The version info for the project you're documenting, acts as replacement\n# for |version| and |release|, also used in various other places throughout\n# the built documents.\n#\n# # The short X.Y version.\nversion = lidar.__version__\n# # The full version, including alpha/beta/rc tags.\nrelease = lidar.__version__\n</pre> # The version info for the project you're documenting, acts as replacement # for |version| and |release|, also used in various other places throughout # the built documents. # # # The short X.Y version. version = lidar.__version__ # # The full version, including alpha/beta/rc tags. release = lidar.__version__ In\u00a0[\u00a0]: Copied! <pre># The language for content autogenerated by Sphinx. Refer to documentation\n# for a list of supported languages.\n#\n# This is also used if you do content translation via gettext catalogs.\n# Usually you set \"language\" from the command line for these cases.\nlanguage = None\n</pre> # The language for content autogenerated by Sphinx. Refer to documentation # for a list of supported languages. # # This is also used if you do content translation via gettext catalogs. # Usually you set \"language\" from the command line for these cases. language = None In\u00a0[\u00a0]: Copied! <pre># List of patterns, relative to source directory, that match files and\n# directories to ignore when looking for source files.\n# This patterns also effect to html_static_path and html_extra_path\nexclude_patterns = [\"_build\", \"Thumbs.db\", \".DS_Store\"]\n</pre> # List of patterns, relative to source directory, that match files and # directories to ignore when looking for source files. # This patterns also effect to html_static_path and html_extra_path exclude_patterns = [\"_build\", \"Thumbs.db\", \".DS_Store\"] In\u00a0[\u00a0]: Copied! <pre># The name of the Pygments (syntax highlighting) style to use.\npygments_style = \"sphinx\"\n</pre> # The name of the Pygments (syntax highlighting) style to use. pygments_style = \"sphinx\" In\u00a0[\u00a0]: Copied! <pre># If true, `todo` and `todoList` produce output, else they produce nothing.\ntodo_include_todos = False\n</pre> # If true, `todo` and `todoList` produce output, else they produce nothing. todo_include_todos = False <p>-- Options for HTML output -------------------------------------------</p> In\u00a0[\u00a0]: Copied! <pre># The theme to use for HTML and HTML Help pages.  See the documentation for\n# a list of builtin themes.\n#\n# html_theme = 'alabaster'\nhtml_theme = \"sphinx_rtd_theme\"\non_rtd = os.environ.get(\"READTHEDOCS\", None) == \"True\"\n</pre> # The theme to use for HTML and HTML Help pages.  See the documentation for # a list of builtin themes. # # html_theme = 'alabaster' html_theme = \"sphinx_rtd_theme\" on_rtd = os.environ.get(\"READTHEDOCS\", None) == \"True\" <p>if not on_rtd:  # only import and set the theme if we're building docs locally import sphinx_rtd_theme html_theme = 'sphinx_rtd_theme' html_theme_path = [sphinx_rtd_theme.get_html_theme_path()]</p> <pre><code>html_context = {\n    'css_files': [\n        '_static/theme_overrides.css'\n    ]\n}</code></pre> <p>else: html_context = { 'css_files': [ '//media.readthedocs.org/css/sphinx_rtd_theme.css', '//media.readthedocs.org/css/readthedocs-doc-embed.css', '_static/theme_overrides.css' ] }</p> <p>Theme options are theme-specific and customize the look and feel of a theme further.  For a list of options available for each theme, see the documentation.</p> <p>html_theme_options = {}</p> In\u00a0[\u00a0]: Copied! <pre># Add any paths that contain custom static files (such as style sheets) here,\n# relative to this directory. They are copied after the builtin static files,\n# so a file named \"default.css\" will overwrite the builtin \"default.css\".\nhtml_static_path = [\"_static\"]\n</pre> # Add any paths that contain custom static files (such as style sheets) here, # relative to this directory. They are copied after the builtin static files, # so a file named \"default.css\" will overwrite the builtin \"default.css\". html_static_path = [\"_static\"] <p>-- Options for HTMLHelp output ---------------------------------------</p> In\u00a0[\u00a0]: Copied! <pre># Output file base name for HTML help builder.\nhtmlhelp_basename = \"lidardoc\"\n</pre> # Output file base name for HTML help builder. htmlhelp_basename = \"lidardoc\" <p>-- Options for LaTeX output ------------------------------------------</p> In\u00a0[\u00a0]: Copied! <pre>latex_elements = {\n    # The paper size ('letterpaper' or 'a4paper').\n    #\n    # 'papersize': 'letterpaper',\n    # The font size ('10pt', '11pt' or '12pt').\n    #\n    # 'pointsize': '10pt',\n    # Additional stuff for the LaTeX preamble.\n    #\n    # 'preamble': '',\n    # Latex figure (float) alignment\n    #\n    # 'figure_align': 'htbp',\n}\n</pre> latex_elements = {     # The paper size ('letterpaper' or 'a4paper').     #     # 'papersize': 'letterpaper',     # The font size ('10pt', '11pt' or '12pt').     #     # 'pointsize': '10pt',     # Additional stuff for the LaTeX preamble.     #     # 'preamble': '',     # Latex figure (float) alignment     #     # 'figure_align': 'htbp', } In\u00a0[\u00a0]: Copied! <pre># Grouping the document tree into LaTeX files. List of tuples\n# (source start file, target name, title, author, documentclass\n# [howto, manual, or own class]).\nlatex_documents = [\n    (master_doc, \"lidar.tex\", \"lidar Documentation\", \"Qiusheng Wu\", \"manual\"),\n]\n</pre> # Grouping the document tree into LaTeX files. List of tuples # (source start file, target name, title, author, documentclass # [howto, manual, or own class]). latex_documents = [     (master_doc, \"lidar.tex\", \"lidar Documentation\", \"Qiusheng Wu\", \"manual\"), ] <p>-- Options for manual page output ------------------------------------</p> In\u00a0[\u00a0]: Copied! <pre># One entry per manual page. List of tuples\n# (source start file, name, description, authors, manual section).\nman_pages = [(master_doc, \"lidar\", \"lidar Documentation\", [author], 1)]\n</pre> # One entry per manual page. List of tuples # (source start file, name, description, authors, manual section). man_pages = [(master_doc, \"lidar\", \"lidar Documentation\", [author], 1)] <p>-- Options for Texinfo output ----------------------------------------</p> In\u00a0[\u00a0]: Copied! <pre># Grouping the document tree into Texinfo files. List of tuples\n# (source start file, target name, title, author,\n#  dir menu entry, description, category)\ntexinfo_documents = [\n    (\n        master_doc,\n        \"lidar\",\n        \"lidar Documentation\",\n        author,\n        \"lidar\",\n        \"One line description of project.\",\n        \"Miscellaneous\",\n    ),\n]\n</pre> # Grouping the document tree into Texinfo files. List of tuples # (source start file, target name, title, author, #  dir menu entry, description, category) texinfo_documents = [     (         master_doc,         \"lidar\",         \"lidar Documentation\",         author,         \"lidar\",         \"One line description of project.\",         \"Miscellaneous\",     ), ]"},{"location":"contributing/","title":"Contributing","text":"<p>Contributions are welcome, and they are greatly appreciated! Every little bit helps, and credit will always be given. You can contribute in many ways:</p>"},{"location":"contributing/#types-of-contributions","title":"Types of Contributions","text":""},{"location":"contributing/#report-bugs","title":"Report Bugs","text":"<p>Report bugs at https://github.com/opengeos/lidar/issues.</p> <p>If you are reporting a bug, please include:</p> <ul> <li>Your operating system name and version.</li> <li>Any details about your local setup that might be helpful in troubleshooting.</li> <li>Detailed steps to reproduce the bug.</li> </ul>"},{"location":"contributing/#fix-bugs","title":"Fix Bugs","text":"<p>Look through the GitHub issues for bugs. Anything tagged with \"bug\" and \"help wanted\" is open to whoever wants to implement it.</p>"},{"location":"contributing/#implement-features","title":"Implement Features","text":"<p>Look through the GitHub issues for features. Anything tagged with \"enhancement\" and \"help wanted\" is open to whoever wants to implement it.</p>"},{"location":"contributing/#write-documentation","title":"Write Documentation","text":"<p>lidar could always use more documentation, whether as part of the official lidar docs, in docstrings, or even on the web in blog posts, articles, and such.</p>"},{"location":"contributing/#submit-feedback","title":"Submit Feedback","text":"<p>The best way to send feedback is to file an issue at https://github.com/opengeos/lidar/issues.</p> <p>If you are proposing a feature:</p> <ul> <li>Explain in detail how it would work.</li> <li>Keep the scope as narrow as possible, to make it easier to implement.</li> <li>Remember that this is a volunteer-driven project, and that contributions are welcome.</li> </ul>"},{"location":"contributing/#get-started","title":"Get Started","text":"<p>Ready to contribute? Here's how to set up lidar for local development.</p> <ol> <li> <p>Fork the lidar repo on GitHub.</p> </li> <li> <p>Clone your fork locally:</p> </li> </ol> <pre><code>git clone git@github.com:your_name_here/lidar.git\n</code></pre> <ol> <li>Install your local copy into a conda env. Assuming you have conda installed, this is how you set up your fork for local development:</li> </ol> <pre><code>conda create -n lidar-test python\nconda activate lidar-test\ncd lidar/\npip install -e .\n</code></pre> <ol> <li>Create a branch for local development:</li> </ol> <pre><code>git checkout -b name-of-your-bugfix-or-feature\n</code></pre> <p>Now you can make your changes locally.</p> <ol> <li>When you're done making changes, check that your changes pass flake8 and the tests, including testing other Python versions with tox:</li> </ol> <pre><code>flake8 lidar tests\npython setup.py test or pytest\n</code></pre> <p>To get flake8 and tox, just pip install them into your conda env.</p> <ol> <li>Commit your changes and push your branch to GitHub:</li> </ol> <pre><code>git add .\ngit commit -m \"Your detailed description of your changes.\"\ngit push origin name-of-your-bugfix-or-feature\n</code></pre> <ol> <li>Submit a pull request through the GitHub website.</li> </ol>"},{"location":"contributing/#pull-request-guidelines","title":"Pull Request Guidelines","text":"<p>Before you submit a pull request, check that it meets these guidelines:</p> <ol> <li>The pull request should include tests.</li> <li>If the pull request adds functionality, the docs should be updated. Put your new functionality into a function with a docstring, and add the feature to the list in README.md.</li> <li>The pull request should work for Python 3.7 and 3.8. Check https://github.com/opengeos/lidar/actions and make sure that the tests pass for all supported Python versions.</li> </ol>"},{"location":"filling/","title":"filling module","text":"<p>Module for filling surface depressions.</p>"},{"location":"filling/#lidar.filling.Depression","title":"<code>Depression</code>","text":"<p>The class for storing depression info.</p> Source code in <code>lidar/filling.py</code> <pre><code>class Depression:\n    \"\"\"The class for storing depression info.\"\"\"\n\n    def __init__(\n        self,\n        id,\n        count,\n        size,\n        volume,\n        meanDepth,\n        maxDepth,\n        minElev,\n        bndElev,\n        perimeter,\n        major_axis,\n        minor_axis,\n        elongatedness,\n        eccentricity,\n        orientation,\n        area_bbox_ratio,\n    ):\n        self.id = id\n        self.count = count\n        self.size = size\n        self.volume = volume\n        self.meanDepth = meanDepth\n        self.maxDepth = maxDepth\n        self.minElev = minElev\n        self.bndElev = bndElev\n        self.perimeter = perimeter\n        self.major_axis = major_axis\n        self.minor_axis = minor_axis\n        self.elongatedness = elongatedness\n        self.eccentricity = eccentricity\n        self.orientation = orientation\n        self.area_bbox_ratio = area_bbox_ratio\n</code></pre>"},{"location":"filling/#lidar.filling.ExtractSinks","title":"<code>ExtractSinks(in_dem, min_size, out_dir, filled_dem=None, engine='whitebox', keep_files=True)</code>","text":"<p>Extract sinks (e.g., maximum depression extent) from a DEM.</p> <p>Parameters:</p> Name Type Description Default <code>in_dem</code> <code>str</code> <p>File path to the input DEM.</p> required <code>min_size</code> <code>int</code> <p>The minimum number of pixels to be considered as a sink.</p> required <code>out_dir</code> <code>str</code> <p>File path to the output directory.</p> required <code>fill_dem</code> <code>str</code> <p>The filled DEM.</p> required <p>Returns:</p> Name Type Description <code>object</code> <p>The richDEM array containing sinks.</p> Source code in <code>lidar/filling.py</code> <pre><code>def ExtractSinks(\n    in_dem, min_size, out_dir, filled_dem=None, engine=\"whitebox\", keep_files=True\n):\n    \"\"\"Extract sinks (e.g., maximum depression extent) from a DEM.\n\n    Args:\n        in_dem (str): File path to the input DEM.\n        min_size (int): The minimum number of pixels to be considered as a sink.\n        out_dir (str): File path to the output directory.\n        fill_dem (str, optional): The filled DEM.\n\n    Returns:\n        object: The richDEM array containing sinks.\n    \"\"\"\n    start_time = time.time()\n\n    out_dem = os.path.join(out_dir, \"dem.tif\")\n    out_dem_diff = os.path.join(out_dir, \"dem_diff.tif\")\n    out_sink = os.path.join(out_dir, \"sink.tif\")\n    out_region = os.path.join(out_dir, \"region.tif\")\n    out_depth = os.path.join(out_dir, \"depth.tif\")\n    out_csv_file = os.path.join(out_dir, \"regions_info.csv\")\n    out_vec_file = os.path.join(out_dir, \"regions.shp\")\n\n    basename = os.path.splitext(os.path.basename(in_dem))[0]\n    out_gpkg = os.path.join(out_dir, basename + \".gpkg\")\n\n    # out_gpkg = os.path.join(out_dir, \"regions.gpkg\")\n    if filled_dem is None:\n        out_dem_filled = os.path.join(out_dir, \"dem_filled.tif\")\n    else:\n        out_dem_filled = filled_dem\n    # create output folder if nonexistent\n    if not os.path.exists(out_dir):\n        os.mkdir(out_dir)\n\n    # load the dem and get dem info\n    print(\"Loading data ...\")\n    dem = rd.LoadGDAL(in_dem)\n    no_data = dem.no_data\n    projection = dem.projection\n    geotransform = dem.geotransform\n    cell_size = np.round(geotransform[1], decimals=2)\n\n    # get min and max elevation of the dem\n    # max_elev = float(np.max(dem[dem != no_data]))\n    max_elev = float(np.nanmax(dem))\n    # min_elev = float(np.min(dem[dem &gt; 0]))\n    # min_elev = float(np.min(dem[dem &gt; 0]))\n    min_elev = float(np.nanmin(dem))\n    print(\n        \"min = {:.2f}, max = {:.2f}, no_data = {}, cell_size = {}\".format(\n            min_elev, max_elev, no_data, cell_size\n        )\n    )\n\n    # depression filling\n    if filled_dem is None:\n        print(\"Depression filling ...\")\n        if engine == \"richdem\":\n            dem_filled = rd.FillDepressions(dem, in_place=False)\n            dem_filled[np.isnan(dem)] = np.nan\n        elif engine == \"whitebox\":\n            wbt = whitebox.WhiteboxTools()\n            wbt.verbose = False\n            wbt.fill_depressions_wang_and_liu(\n                os.path.abspath(in_dem), os.path.abspath(out_dem_filled)\n            )\n            dem_filled = rd.LoadGDAL(out_dem_filled)\n\n    else:\n        dem_filled = rd.LoadGDAL(filled_dem)\n    dem_diff = dem_filled - dem\n    dem_diff.no_data = 0\n\n    if filled_dem is None:\n        print(\"Saving filled dem ...\")\n        rd.SaveGDAL(out_dem_filled, dem_filled)\n    rd.SaveGDAL(out_dem_diff, dem_diff)\n\n    # nb_labels is the total number of objects. 0 represents background object.\n    print(\"Region grouping ...\")\n    label_objects, nb_labels = regionGroup(dem_diff, min_size, no_data)\n    dem_diff[label_objects == 0] = 0\n    depth = np2rdarray(\n        dem_diff, no_data=0, projection=projection, geotransform=geotransform\n    )\n    rd.SaveGDAL(out_depth, depth)\n    del dem_diff, depth\n\n    print(\"Computing properties ...\")\n    # objects = measure.regionprops(label_objects, dem, coordinates='xy')\n    objects = measure.regionprops(label_objects, dem)\n    dep_list = get_dep_props(objects, cell_size)\n    write_dep_csv(dep_list, out_csv_file)\n    del objects, dep_list\n\n    # convert numpy to richdem data format\n    region = np2rdarray(\n        label_objects, no_data=0, projection=projection, geotransform=geotransform\n    )\n    del label_objects\n\n    region[np.isnan(dem)] = 0\n\n    print(\"Saving sink dem ...\")\n    sink = np.copy(dem)\n    sink[region == 0] = 0\n    sink = np2rdarray(sink, no_data=0, projection=projection, geotransform=geotransform)\n    rd.SaveGDAL(out_sink, sink)\n    # del sink\n\n    print(\"Saving refined dem ...\")\n    dem_refined = dem_filled\n    dem_refined[region &gt; 0] = dem[region &gt; 0]\n    dem_refined = np2rdarray(\n        dem_refined, no_data=no_data, projection=projection, geotransform=geotransform\n    )\n    dem_refined[np.isnan(dem)] = np.nan\n    rd.SaveGDAL(out_dem, dem_refined)\n    rd.SaveGDAL(out_region, region)\n    del dem_refined, region, dem\n\n    print(\"Converting raster to vector ...\")\n    polygonize(out_region, out_vec_file)\n\n    gdf = join_csv_to_gdf(out_vec_file, out_csv_file, \"id\", \"region_id\")\n    gdf.drop(columns=[\"id\"], inplace=True)\n    gdf.to_file(out_gpkg, driver=\"GPKG\")\n\n    if not keep_files:\n        for file in [\n            out_dem,\n            out_dem_diff,\n            out_depth,\n            out_sink,\n            out_dem_filled,\n            out_region,\n            out_csv_file,\n        ]:\n            if os.path.exists(file):\n                os.remove(file)\n\n        out_vec_file_dbf = os.path.splitext(out_vec_file)[0] + \".dbf\"\n        out_vec_file_shx = os.path.splitext(out_vec_file)[0] + \".shx\"\n        out_csv_file_prj = os.path.splitext(out_vec_file)[0] + \".prj\"\n        for file in [\n            out_vec_file,\n            out_vec_file_dbf,\n            out_vec_file_shx,\n            out_csv_file_prj,\n        ]:\n            if os.path.exists(file):\n                os.remove(file)\n\n    end_time = time.time()\n    print(\"Total run time:\\t\\t\\t {:.4f} s\\n\".format(end_time - start_time))\n\n    return out_sink\n</code></pre>"},{"location":"filling/#lidar.filling.GaussianFilter","title":"<code>GaussianFilter(in_dem, sigma=1, out_file=None)</code>","text":"<p>Applies a Gaussian filter to an image.</p> <p>Parameters:</p> Name Type Description Default <code>in_dem</code> <code>str</code> <p>File path to the input image.</p> required <code>sigma</code> <code>int</code> <p>Standard deviation. Defaults to 1.</p> <code>1</code> <code>out_file</code> <code>str</code> <p>File path to the output image. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <p>np.array: The numpy array containing the filtered image.</p> Source code in <code>lidar/filtering.py</code> <pre><code>def GaussianFilter(in_dem, sigma=1, out_file=None):\n    \"\"\"Applies a Gaussian filter to an image.\n\n    Args:\n        in_dem (str): File path to the input image.\n        sigma (int, optional): Standard deviation. Defaults to 1.\n        out_file (str, optional): File path to the output image. Defaults to None.\n\n    Returns:\n        np.array: The numpy array containing the filtered image.\n    \"\"\"\n    print(\"Gaussian filtering ...\")\n    start_time = time.time()\n    dem = rd.LoadGDAL(in_dem)\n    no_data = dem.no_data\n    projection = dem.projection\n    geotransform = dem.geotransform\n\n    gau = ndimage.gaussian_filter(dem, sigma=sigma)\n    gau = np2rdarray(gau, no_data, projection, geotransform)\n    print(\"Run time: {:.4f} seconds\".format(time.time() - start_time))\n\n    if out_file is not None:\n        print(\"Saving dem ...\")\n        rd.SaveGDAL(out_file, gau)\n        return out_file\n\n    return gau\n</code></pre>"},{"location":"filling/#lidar.filling.MeanFilter","title":"<code>MeanFilter(in_dem, kernel_size=3, out_file=None)</code>","text":"<p>Applies a mean filter to an image.</p> <p>Parameters:</p> Name Type Description Default <code>in_dem</code> <code>str</code> <p>File path to the input image.</p> required <code>kernel_size</code> <code>int</code> <p>The size of the moving window. Defaults to 3.</p> <code>3</code> <code>out_file</code> <code>str</code> <p>File path to the output image. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <p>np.array: The numpy array containing the filtered image.</p> Source code in <code>lidar/filtering.py</code> <pre><code>def MeanFilter(in_dem, kernel_size=3, out_file=None):\n    \"\"\"Applies a mean filter to an image.\n\n    Args:\n        in_dem (str): File path to the input image.\n        kernel_size (int, optional): The size of the moving window. Defaults to 3.\n        out_file (str, optional): File path to the output image. Defaults to None.\n\n    Returns:\n        np.array: The numpy array containing the filtered image.\n    \"\"\"\n    print(\"Mean filtering ...\")\n    start_time = time.time()\n    dem = rd.LoadGDAL(in_dem)\n    no_data = dem.no_data\n    projection = dem.projection\n    geotransform = dem.geotransform\n\n    weights = np.full((kernel_size, kernel_size), 1.0 / (kernel_size * kernel_size))\n    mean = ndimage.filters.convolve(dem, weights)\n    mean = np2rdarray(mean, no_data, projection, geotransform)\n    print(\"Run time: {:.4f} seconds\".format(time.time() - start_time))\n\n    if out_file is not None:\n        print(\"Saving dem ...\")\n        rd.SaveGDAL(out_file, mean)\n        return out_file\n\n    return mean\n</code></pre>"},{"location":"filling/#lidar.filling.MedianFilter","title":"<code>MedianFilter(in_dem, kernel_size=3, out_file=None)</code>","text":"<p>Applies a median filter to an image.</p> <p>Parameters:</p> Name Type Description Default <code>in_dem</code> <code>str</code> <p>File path to the input image.</p> required <code>kernel_size</code> <code>int</code> <p>The size of the moving window. Defaults to 3.</p> <code>3</code> <code>out_file</code> <code>str</code> <p>File path to the output image. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <p>np.array: The numpy array containing the filtered image.</p> Source code in <code>lidar/filtering.py</code> <pre><code>def MedianFilter(in_dem, kernel_size=3, out_file=None):\n    \"\"\"Applies a median filter to an image.\n\n    Args:\n        in_dem (str): File path to the input image.\n        kernel_size (int, optional): The size of the moving window. Defaults to 3.\n        out_file (str, optional): File path to the output image. Defaults to None.\n\n    Returns:\n        np.array: The numpy array containing the filtered image.\n    \"\"\"\n    print(\"Median filtering ...\")\n    start_time = time.time()\n    dem = rd.LoadGDAL(in_dem)\n    no_data = dem.no_data\n    projection = dem.projection\n    geotransform = dem.geotransform\n\n    med = ndimage.median_filter(dem, size=kernel_size)\n    med = np2rdarray(med, no_data, projection, geotransform)\n    print(\"Run time: {:.4f} seconds\".format(time.time() - start_time))\n\n    if out_file is not None:\n        print(\"Saving dem ...\")\n        rd.SaveGDAL(out_file, med)\n        return out_file\n\n    return med\n</code></pre>"},{"location":"filling/#lidar.filling.add_crs","title":"<code>add_crs(filename, epsg)</code>","text":"<p>Add a CRS to a raster dataset.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>The filename of the raster dataset.</p> required <code>epsg</code> <code>int | str</code> <p>The EPSG code of the CRS.</p> required Source code in <code>lidar/common.py</code> <pre><code>def add_crs(filename, epsg):\n    \"\"\"Add a CRS to a raster dataset.\n\n    Args:\n        filename (str): The filename of the raster dataset.\n        epsg (int | str): The EPSG code of the CRS.\n\n    \"\"\"\n    try:\n        import rasterio\n    except ImportError:\n        raise ImportError(\n            \"rasterio is required for adding a CRS to a raster. Please install it using 'pip install rasterio'.\"\n        )\n\n    if not os.path.exists(filename):\n        raise ValueError(\"filename must exist.\")\n\n    if isinstance(epsg, int):\n        epsg = f\"EPSG:{epsg}\"\n    elif isinstance(epsg, str):\n        epsg = \"EPSG:\" + epsg\n    else:\n        raise ValueError(\"epsg must be an integer or string.\")\n\n    crs = rasterio.crs.CRS({\"init\": epsg})\n    with rasterio.open(filename, mode=\"r+\") as src:\n        src.crs = crs\n</code></pre>"},{"location":"filling/#lidar.filling.check_file_path","title":"<code>check_file_path(file_path, make_dirs=True)</code>","text":"<p>Gets the absolute file path.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>str</code> <p>The path to the file.</p> required <code>make_dirs</code> <code>bool</code> <p>Whether to create the directory if it does not exist. Defaults to True.</p> <code>True</code> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the directory could not be found.</p> <code>TypeError</code> <p>If the input directory path is not a string.</p> <p>Returns:</p> Name Type Description <code>str</code> <p>The absolute path to the file.</p> Source code in <code>lidar/common.py</code> <pre><code>def check_file_path(file_path, make_dirs=True):\n    \"\"\"Gets the absolute file path.\n\n    Args:\n        file_path (str): The path to the file.\n        make_dirs (bool, optional): Whether to create the directory if it does not exist. Defaults to True.\n\n    Raises:\n        FileNotFoundError: If the directory could not be found.\n        TypeError: If the input directory path is not a string.\n\n    Returns:\n        str: The absolute path to the file.\n    \"\"\"\n    if isinstance(file_path, str):\n        if file_path.startswith(\"~\"):\n            file_path = os.path.expanduser(file_path)\n        else:\n            file_path = os.path.abspath(file_path)\n\n        file_dir = os.path.dirname(file_path)\n        if not os.path.exists(file_dir) and make_dirs:\n            os.makedirs(file_dir)\n\n        return file_path\n\n    else:\n        raise TypeError(\"The provided file path must be a string.\")\n</code></pre>"},{"location":"filling/#lidar.filling.check_install","title":"<code>check_install(package)</code>","text":"<p>Checks whether a package is installed. If not, it will install the package.</p> <p>Parameters:</p> Name Type Description Default <code>package</code> <code>str</code> <p>The name of the package to check.</p> required Source code in <code>lidar/common.py</code> <pre><code>def check_install(package):\n    \"\"\"Checks whether a package is installed. If not, it will install the package.\n\n    Args:\n        package (str): The name of the package to check.\n    \"\"\"\n    import subprocess\n\n    try:\n        __import__(package)\n        # print('{} is already installed.'.format(package))\n    except ImportError:\n        print(\"{} is not installed. Installing ...\".format(package))\n        try:\n            subprocess.check_call([\"python\", \"-m\", \"pip\", \"install\", package])\n        except Exception as e:\n            print(\"Failed to install {}\".format(package))\n            print(e)\n        print(\"{} has been installed successfully.\".format(package))\n</code></pre>"},{"location":"filling/#lidar.filling.clip_image","title":"<code>clip_image(image, mask, output)</code>","text":"<p>Clip an image by mask.</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>str</code> <p>Path to the image file in GeoTIFF format.</p> required <code>mask</code> <code>str | list | dict</code> <p>The mask used to extract the image. It can be a path to vector datasets (e.g., GeoJSON, Shapefile), a list of coordinates, or m.user_roi.</p> required <code>output</code> <code>str</code> <p>Path to the output file.</p> required <p>Raises:</p> Type Description <code>ImportError</code> <p>If the fiona or rasterio package is not installed.</p> <code>FileNotFoundError</code> <p>If the image is not found.</p> <code>ValueError</code> <p>If the mask is not a valid GeoJSON or raster file.</p> <code>FileNotFoundError</code> <p>If the mask file is not found.</p> Source code in <code>lidar/common.py</code> <pre><code>def clip_image(image, mask, output):\n    \"\"\"Clip an image by mask.\n\n    Args:\n        image (str): Path to the image file in GeoTIFF format.\n        mask (str | list | dict): The mask used to extract the image. It can be a path to vector datasets (e.g., GeoJSON, Shapefile), a list of coordinates, or m.user_roi.\n        output (str): Path to the output file.\n\n    Raises:\n        ImportError: If the fiona or rasterio package is not installed.\n        FileNotFoundError: If the image is not found.\n        ValueError: If the mask is not a valid GeoJSON or raster file.\n        FileNotFoundError: If the mask file is not found.\n    \"\"\"\n    import json\n\n    try:\n        import fiona\n        import rasterio\n        import rasterio.mask\n    except ImportError as e:\n        raise ImportError(e)\n\n    if not os.path.exists(image):\n        raise FileNotFoundError(f\"{image} does not exist.\")\n\n    if not output.endswith(\".tif\"):\n        raise ValueError(\"Output must be a tif file.\")\n\n    output = check_file_path(output)\n\n    if isinstance(mask, str):\n        if mask.startswith(\"http\"):\n            mask = download_file(mask, output)\n        if not os.path.exists(mask):\n            raise FileNotFoundError(f\"{mask} does not exist.\")\n    elif isinstance(mask, list) or isinstance(mask, dict):\n\n        if isinstance(mask, list):\n            geojson = {\n                \"type\": \"FeatureCollection\",\n                \"features\": [\n                    {\n                        \"type\": \"Feature\",\n                        \"properties\": {},\n                        \"geometry\": {\"type\": \"Polygon\", \"coordinates\": [mask]},\n                    }\n                ],\n            }\n        else:\n            geojson = {\n                \"type\": \"FeatureCollection\",\n                \"features\": [mask],\n            }\n        mask = temp_file_path(\".geojson\")\n        with open(mask, \"w\") as f:\n            json.dump(geojson, f)\n\n    with fiona.open(mask, \"r\") as shapefile:\n        shapes = [feature[\"geometry\"] for feature in shapefile]\n\n    with rasterio.open(image) as src:\n        out_image, out_transform = rasterio.mask.mask(src, shapes, crop=True)\n        out_meta = src.meta\n\n    out_meta.update(\n        {\n            \"driver\": \"GTiff\",\n            \"height\": out_image.shape[1],\n            \"width\": out_image.shape[2],\n            \"transform\": out_transform,\n        }\n    )\n\n    with rasterio.open(output, \"w\", **out_meta) as dest:\n        dest.write(out_image)\n</code></pre>"},{"location":"filling/#lidar.filling.clone_repo","title":"<code>clone_repo(out_dir='.', unzip=True)</code>","text":"<p>Clones the lidar GitHub repository.</p> <p>Parameters:</p> Name Type Description Default <code>out_dir</code> <code>str</code> <p>Output folder for the repo. Defaults to '.'.</p> <code>'.'</code> <code>unzip</code> <code>bool</code> <p>Whether to unzip the repository. Defaults to True.</p> <code>True</code> Source code in <code>lidar/common.py</code> <pre><code>def clone_repo(out_dir=\".\", unzip=True):\n    \"\"\"Clones the lidar GitHub repository.\n\n    Args:\n        out_dir (str, optional): Output folder for the repo. Defaults to '.'.\n        unzip (bool, optional): Whether to unzip the repository. Defaults to True.\n    \"\"\"\n    url = \"https://github.com/opengeos/lidar/archive/master.zip\"\n    filename = \"lidar-master.zip\"\n    download_from_url(url, out_file_name=filename, out_dir=out_dir, unzip=unzip)\n</code></pre>"},{"location":"filling/#lidar.filling.convert_lidar","title":"<code>convert_lidar(source, destination=None, point_format_id=None, file_version=None, **kwargs)</code>","text":"<p>Converts a Las from one point format to another Automatically upgrades the file version if source file version     is not compatible with the new point_format_id</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>str | LasBase</code> <p>The source data to be converted.</p> required <code>destination</code> <code>str</code> <p>The destination file path. Defaults to None.</p> <code>None</code> <code>point_format_id</code> <code>int</code> <p>The new point format id (the default is None, which won't change the source format id).</p> <code>None</code> <code>file_version</code> <code>str</code> <p>The new file version. None by default which means that the file_version may be upgraded for compatibility with the new point_format. The file version will not be downgraded.</p> <code>None</code> <p>Returns:</p> Type Description <p>aspy.lasdatas.base.LasBase: The converted LasData object.</p> Source code in <code>lidar/common.py</code> <pre><code>def convert_lidar(\n    source, destination=None, point_format_id=None, file_version=None, **kwargs\n):\n    \"\"\"Converts a Las from one point format to another Automatically upgrades the file version if source file version\n        is not compatible with the new point_format_id\n\n    Args:\n        source (str | laspy.lasdatas.base.LasBase): The source data to be converted.\n        destination (str, optional): The destination file path. Defaults to None.\n        point_format_id (int, optional): The new point format id (the default is None, which won't change the source format id).\n        file_version (str, optional): The new file version. None by default which means that the file_version may be upgraded\n            for compatibility with the new point_format. The file version will not be downgraded.\n\n    Returns:\n        aspy.lasdatas.base.LasBase: The converted LasData object.\n    \"\"\"\n    try:\n        import laspy\n    except ImportError:\n        print(\n            \"The laspy package is required for this function. Use `pip install laspy[lazrs,laszip]` to install it.\"\n        )\n        return\n\n    if isinstance(source, str):\n        source = read_lidar(source)\n\n    las = laspy.convert(\n        source, point_format_id=point_format_id, file_version=file_version\n    )\n\n    if destination is None:\n        return las\n    else:\n        destination = check_file_path(destination)\n        write_lidar(las, destination, **kwargs)\n        return destination\n</code></pre>"},{"location":"filling/#lidar.filling.csv_points_to_shp","title":"<code>csv_points_to_shp(in_csv, out_shp, latitude='latitude', longitude='longitude')</code>","text":"<p>Converts a csv file containing points (latitude, longitude) into a shapefile.</p> <p>Parameters:</p> Name Type Description Default <code>in_csv</code> <code>str</code> <p>File path or HTTP URL to the input csv file. For example, https://raw.githubusercontent.com/giswqs/data/main/world/world_cities.csv</p> required <code>out_shp</code> <code>str</code> <p>File path to the output shapefile.</p> required <code>latitude</code> <code>str</code> <p>Column name for the latitude column. Defaults to 'latitude'.</p> <code>'latitude'</code> <code>longitude</code> <code>str</code> <p>Column name for the longitude column. Defaults to 'longitude'.</p> <code>'longitude'</code> Source code in <code>lidar/common.py</code> <pre><code>def csv_points_to_shp(in_csv, out_shp, latitude=\"latitude\", longitude=\"longitude\"):\n    \"\"\"Converts a csv file containing points (latitude, longitude) into a shapefile.\n\n    Args:\n        in_csv (str): File path or HTTP URL to the input csv file. For example, https://raw.githubusercontent.com/giswqs/data/main/world/world_cities.csv\n        out_shp (str): File path to the output shapefile.\n        latitude (str, optional): Column name for the latitude column. Defaults to 'latitude'.\n        longitude (str, optional): Column name for the longitude column. Defaults to 'longitude'.\n\n    \"\"\"\n    import whitebox\n\n    if in_csv.startswith(\"http\") and in_csv.endswith(\".csv\"):\n        out_dir = os.path.join(os.path.expanduser(\"~\"), \"Downloads\")\n        out_name = os.path.basename(in_csv)\n\n        if not os.path.exists(out_dir):\n            os.makedirs(out_dir)\n        download_from_url(in_csv, out_dir=out_dir)\n        in_csv = os.path.join(out_dir, out_name)\n\n    wbt = whitebox.WhiteboxTools()\n    in_csv = os.path.abspath(in_csv)\n    out_shp = os.path.abspath(out_shp)\n\n    if not os.path.exists(in_csv):\n        raise Exception(\"The provided csv file does not exist.\")\n\n    with open(in_csv, encoding=\"utf-8\") as csv_file:\n        reader = csv.DictReader(csv_file)\n        fields = reader.fieldnames\n        xfield = fields.index(longitude)\n        yfield = fields.index(latitude)\n\n    wbt.csv_points_to_vector(in_csv, out_shp, xfield=xfield, yfield=yfield, epsg=4326)\n</code></pre>"},{"location":"filling/#lidar.filling.csv_to_shp","title":"<code>csv_to_shp(in_csv, out_shp, latitude='latitude', longitude='longitude')</code>","text":"<p>Converts a csv file with latlon info to a point shapefile.</p> <p>Parameters:</p> Name Type Description Default <code>in_csv</code> <code>str</code> <p>The input csv file containing longitude and latitude columns.</p> required <code>out_shp</code> <code>str</code> <p>The file path to the output shapefile.</p> required <code>latitude</code> <code>str</code> <p>The column name of the latitude column. Defaults to 'latitude'.</p> <code>'latitude'</code> <code>longitude</code> <code>str</code> <p>The column name of the longitude column. Defaults to 'longitude'.</p> <code>'longitude'</code> Source code in <code>lidar/common.py</code> <pre><code>def csv_to_shp(in_csv, out_shp, latitude=\"latitude\", longitude=\"longitude\"):\n    \"\"\"Converts a csv file with latlon info to a point shapefile.\n\n    Args:\n        in_csv (str): The input csv file containing longitude and latitude columns.\n        out_shp (str): The file path to the output shapefile.\n        latitude (str, optional): The column name of the latitude column. Defaults to 'latitude'.\n        longitude (str, optional): The column name of the longitude column. Defaults to 'longitude'.\n    \"\"\"\n    import csv\n    import shapefile as shp\n\n    if in_csv.startswith(\"http\") and in_csv.endswith(\".csv\"):\n        out_dir = os.path.join(os.path.expanduser(\"~\"), \"Downloads\")\n        out_name = os.path.basename(in_csv)\n\n        if not os.path.exists(out_dir):\n            os.makedirs(out_dir)\n        download_from_url(in_csv, out_dir=out_dir)\n        in_csv = os.path.join(out_dir, out_name)\n\n    out_dir = os.path.dirname(out_shp)\n    if not os.path.exists(out_dir):\n        os.makedirs(out_dir)\n\n    try:\n        points = shp.Writer(out_shp, shapeType=shp.POINT)\n        with open(in_csv, encoding=\"utf-8\") as csvfile:\n            csvreader = csv.DictReader(csvfile)\n            header = csvreader.fieldnames\n            [points.field(field) for field in header]\n            for row in csvreader:\n                points.point((float(row[longitude])), (float(row[latitude])))\n                points.record(*tuple([row[f] for f in header]))\n\n        out_prj = out_shp.replace(\".shp\", \".prj\")\n        with open(out_prj, \"w\") as f:\n            prj_str = 'GEOGCS[\"GCS_WGS_1984\",DATUM[\"D_WGS_1984\",SPHEROID[\"WGS_1984\",6378137,298.257223563]],PRIMEM[\"Greenwich\",0],UNIT[\"Degree\",0.0174532925199433]] '\n            f.write(prj_str)\n\n    except Exception as e:\n        print(e)\n</code></pre>"},{"location":"filling/#lidar.filling.download_file","title":"<code>download_file(url=None, output=None, quiet=False, proxy=None, speed=None, use_cookies=True, verify=True, id=None, fuzzy=False, resume=False, unzip=True, overwrite=False)</code>","text":"<p>Download a file from URL, including Google Drive shared URL.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>Google Drive URL is also supported. Defaults to None.</p> <code>None</code> <code>output</code> <code>str</code> <p>Output filename. Default is basename of URL.</p> <code>None</code> <code>quiet</code> <code>bool</code> <p>Suppress terminal output. Default is False.</p> <code>False</code> <code>proxy</code> <code>str</code> <p>Proxy. Defaults to None.</p> <code>None</code> <code>speed</code> <code>float</code> <p>Download byte size per second (e.g., 256KB/s = 256 * 1024). Defaults to None.</p> <code>None</code> <code>use_cookies</code> <code>bool</code> <p>Flag to use cookies. Defaults to True.</p> <code>True</code> <code>verify</code> <code>bool | str</code> <p>Either a bool, in which case it controls whether the server's TLS certificate is verified, or a string, in which case it must be a path to a CA bundle to use. Default is True.. Defaults to True.</p> <code>True</code> <code>id</code> <code>str</code> <p>Google Drive's file ID. Defaults to None.</p> <code>None</code> <code>fuzzy</code> <code>bool</code> <p>Fuzzy extraction of Google Drive's file Id. Defaults to False.</p> <code>False</code> <code>resume</code> <code>bool</code> <p>Resume the download from existing tmp file if possible. Defaults to False.</p> <code>False</code> <code>unzip</code> <code>bool</code> <p>Unzip the file. Defaults to True.</p> <code>True</code> <code>overwrite</code> <code>bool</code> <p>Overwrite the file if it already exists. Defaults to False.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>str</code> <p>The output file path.</p> Source code in <code>lidar/common.py</code> <pre><code>def download_file(\n    url=None,\n    output=None,\n    quiet=False,\n    proxy=None,\n    speed=None,\n    use_cookies=True,\n    verify=True,\n    id=None,\n    fuzzy=False,\n    resume=False,\n    unzip=True,\n    overwrite=False,\n):\n    \"\"\"Download a file from URL, including Google Drive shared URL.\n\n    Args:\n        url (str, optional): Google Drive URL is also supported. Defaults to None.\n        output (str, optional): Output filename. Default is basename of URL.\n        quiet (bool, optional): Suppress terminal output. Default is False.\n        proxy (str, optional): Proxy. Defaults to None.\n        speed (float, optional): Download byte size per second (e.g., 256KB/s = 256 * 1024). Defaults to None.\n        use_cookies (bool, optional): Flag to use cookies. Defaults to True.\n        verify (bool | str, optional): Either a bool, in which case it controls whether the server's TLS certificate is verified, or a string, in which case it must be a path to a CA bundle to use. Default is True.. Defaults to True.\n        id (str, optional): Google Drive's file ID. Defaults to None.\n        fuzzy (bool, optional): Fuzzy extraction of Google Drive's file Id. Defaults to False.\n        resume (bool, optional): Resume the download from existing tmp file if possible. Defaults to False.\n        unzip (bool, optional): Unzip the file. Defaults to True.\n        overwrite (bool, optional): Overwrite the file if it already exists. Defaults to False.\n\n    Returns:\n        str: The output file path.\n    \"\"\"\n\n    import gdown\n\n    if output is None:\n        if isinstance(url, str) and url.startswith(\"http\"):\n            output = os.path.basename(url)\n\n    if isinstance(url, str):\n        if os.path.exists(os.path.abspath(output)) and (not overwrite):\n            print(\n                f\"{output} already exists. Skip downloading. Set overwrite=True to overwrite.\"\n            )\n            return os.path.abspath(output)\n        else:\n            url = github_raw_url(url)\n\n    if \"https://drive.google.com/file/d/\" in url:\n        fuzzy = True\n\n    output = gdown.download(\n        url, output, quiet, proxy, speed, use_cookies, verify, id, fuzzy, resume\n    )\n\n    if unzip and output.endswith(\".zip\"):\n\n        with zipfile.ZipFile(output, \"r\") as zip_ref:\n            if not quiet:\n                print(\"Extracting files...\")\n            zip_ref.extractall(os.path.dirname(output))\n\n    return os.path.abspath(output)\n</code></pre>"},{"location":"filling/#lidar.filling.download_folder","title":"<code>download_folder(url=None, id=None, output=None, quiet=False, proxy=None, speed=None, use_cookies=True, remaining_ok=False)</code>","text":"<p>Downloads the entire folder from URL.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>URL of the Google Drive folder. Must be of the format 'https://drive.google.com/drive/folders/{url}'. Defaults to None.</p> <code>None</code> <code>id</code> <code>str</code> <p>Google Drive's folder ID. Defaults to None.</p> <code>None</code> <code>output</code> <code>str</code> <p>String containing the path of the output folder. Defaults to current working directory.</p> <code>None</code> <code>quiet</code> <code>bool</code> <p>Suppress terminal output. Defaults to False.</p> <code>False</code> <code>proxy</code> <code>str</code> <p>Proxy. Defaults to None.</p> <code>None</code> <code>speed</code> <code>float</code> <p>Download byte size per second (e.g., 256KB/s = 256 * 1024). Defaults to None.</p> <code>None</code> <code>use_cookies</code> <code>bool</code> <p>Flag to use cookies. Defaults to True.</p> <code>True</code> <code>resume</code> <code>bool</code> <p>Resume the download from existing tmp file if possible. Defaults to False.</p> required <p>Returns:</p> Name Type Description <code>list</code> <p>List of files downloaded, or None if failed.</p> Source code in <code>lidar/common.py</code> <pre><code>def download_folder(\n    url=None,\n    id=None,\n    output=None,\n    quiet=False,\n    proxy=None,\n    speed=None,\n    use_cookies=True,\n    remaining_ok=False,\n):\n    \"\"\"Downloads the entire folder from URL.\n\n    Args:\n        url (str, optional): URL of the Google Drive folder. Must be of the format 'https://drive.google.com/drive/folders/{url}'. Defaults to None.\n        id (str, optional): Google Drive's folder ID. Defaults to None.\n        output (str, optional):  String containing the path of the output folder. Defaults to current working directory.\n        quiet (bool, optional): Suppress terminal output. Defaults to False.\n        proxy (str, optional): Proxy. Defaults to None.\n        speed (float, optional): Download byte size per second (e.g., 256KB/s = 256 * 1024). Defaults to None.\n        use_cookies (bool, optional): Flag to use cookies. Defaults to True.\n        resume (bool, optional): Resume the download from existing tmp file if possible. Defaults to False.\n\n    Returns:\n        list: List of files downloaded, or None if failed.\n    \"\"\"\n    import gdown\n\n    files = gdown.download_folder(\n        url, id, output, quiet, proxy, speed, use_cookies, remaining_ok\n    )\n    return files\n</code></pre>"},{"location":"filling/#lidar.filling.download_from_gdrive","title":"<code>download_from_gdrive(gfile_url, file_name, out_dir='.', unzip=True, verbose=True)</code>","text":"<p>Download a file shared via Google Drive    (e.g., https://drive.google.com/file/d/18SUo_HcDGltuWYZs1s7PpOmOq_FvFn04/view?usp=sharing)</p> <p>Parameters:</p> Name Type Description Default <code>gfile_url</code> <code>str</code> <p>The Google Drive shared file URL</p> required <code>file_name</code> <code>str</code> <p>The output file name to use.</p> required <code>out_dir</code> <code>str</code> <p>The output directory. Defaults to '.'.</p> <code>'.'</code> <code>unzip</code> <code>bool</code> <p>Whether to unzip the output file if it is a zip file. Defaults to True.</p> <code>True</code> <code>verbose</code> <code>bool</code> <p>Whether to display or not the output of the function</p> <code>True</code> Source code in <code>lidar/common.py</code> <pre><code>def download_from_gdrive(gfile_url, file_name, out_dir=\".\", unzip=True, verbose=True):\n    \"\"\"Download a file shared via Google Drive\n       (e.g., https://drive.google.com/file/d/18SUo_HcDGltuWYZs1s7PpOmOq_FvFn04/view?usp=sharing)\n\n    Args:\n        gfile_url (str): The Google Drive shared file URL\n        file_name (str): The output file name to use.\n        out_dir (str, optional): The output directory. Defaults to '.'.\n        unzip (bool, optional): Whether to unzip the output file if it is a zip file. Defaults to True.\n        verbose (bool, optional): Whether to display or not the output of the function\n    \"\"\"\n    try:\n        from google_drive_downloader import GoogleDriveDownloader as gdd\n    except ImportError:\n        print(\"GoogleDriveDownloader package not installed. Installing ...\")\n        subprocess.check_call(\n            [\"python\", \"-m\", \"pip\", \"install\", \"googledrivedownloader\"]\n        )\n        from google_drive_downloader import GoogleDriveDownloader as gdd\n\n    file_id = gfile_url.split(\"/\")[5]\n    if verbose:\n        print(\"Google Drive file id: {}\".format(file_id))\n\n    dest_path = os.path.join(out_dir, file_name)\n    gdd.download_file_from_google_drive(file_id, dest_path, True, unzip)\n\n    return\n</code></pre>"},{"location":"filling/#lidar.filling.download_from_url","title":"<code>download_from_url(url, out_file_name=None, out_dir='.', unzip=True, verbose=True)</code>","text":"<p>Download a file from a URL (e.g., https://github.com/giswqs/whitebox/raw/master/examples/testdata.zip)</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The HTTP URL to download.</p> required <code>out_file_name</code> <code>str</code> <p>The output file name to use. Defaults to None.</p> <code>None</code> <code>out_dir</code> <code>str</code> <p>The output directory to use. Defaults to '.'.</p> <code>'.'</code> <code>unzip</code> <code>bool</code> <p>Whether to unzip the downloaded file if it is a zip file. Defaults to True.</p> <code>True</code> <code>verbose</code> <code>bool</code> <p>Whether to display or not the output of the function</p> <code>True</code> Source code in <code>lidar/common.py</code> <pre><code>def download_from_url(url, out_file_name=None, out_dir=\".\", unzip=True, verbose=True):\n    \"\"\"Download a file from a URL (e.g., https://github.com/giswqs/whitebox/raw/master/examples/testdata.zip)\n\n    Args:\n        url (str): The HTTP URL to download.\n        out_file_name (str, optional): The output file name to use. Defaults to None.\n        out_dir (str, optional): The output directory to use. Defaults to '.'.\n        unzip (bool, optional): Whether to unzip the downloaded file if it is a zip file. Defaults to True.\n        verbose (bool, optional): Whether to display or not the output of the function\n    \"\"\"\n    in_file_name = os.path.basename(url)\n\n    if out_file_name is None:\n        out_file_name = in_file_name\n    out_file_path = os.path.join(os.path.abspath(out_dir), out_file_name)\n\n    if verbose:\n        print(\"Downloading {} ...\".format(url))\n\n    try:\n        urllib.request.urlretrieve(url, out_file_path)\n    except Exception:\n        raise Exception(\"The URL is invalid. Please double check the URL.\")\n\n    final_path = out_file_path\n\n    if unzip:\n        # if it is a zip file\n        if \".zip\" in out_file_name:\n            if verbose:\n                print(\"Unzipping {} ...\".format(out_file_name))\n            with zipfile.ZipFile(out_file_path, \"r\") as zip_ref:\n                zip_ref.extractall(out_dir)\n            final_path = os.path.join(\n                os.path.abspath(out_dir), out_file_name.replace(\".zip\", \"\")\n            )\n\n        # if it is a tar file\n        if \".tar\" in out_file_name:\n            if verbose:\n                print(\"Unzipping {} ...\".format(out_file_name))\n            with tarfile.open(out_file_path, \"r\") as tar_ref:\n\n                def is_within_directory(directory, target):\n\n                    abs_directory = os.path.abspath(directory)\n                    abs_target = os.path.abspath(target)\n\n                    prefix = os.path.commonprefix([abs_directory, abs_target])\n\n                    return prefix == abs_directory\n\n                def safe_extract(tar, path=\".\", members=None, *, numeric_owner=False):\n\n                    for member in tar.getmembers():\n                        member_path = os.path.join(path, member.name)\n                        if not is_within_directory(path, member_path):\n                            raise Exception(\"Attempted Path Traversal in Tar File\")\n\n                    tar.extractall(path, members, numeric_owner=numeric_owner)\n\n                safe_extract(tar_ref, out_dir)\n            final_path = os.path.join(\n                os.path.abspath(out_dir), out_file_name.replace(\".tart\", \"\")\n            )\n\n    if verbose:\n        print(\"Data downloaded to: {}\".format(final_path))\n\n    return\n</code></pre>"},{"location":"filling/#lidar.filling.download_ned_by_bbox","title":"<code>download_ned_by_bbox(bbox, datasets=None, out_dir=None, return_url=False, download_args={}, **kwargs)</code>","text":"<p>Download the US National Elevation Datasets (NED) for a bounding box. See https://apps.nationalmap.gov/tnmaccess/#/ for more information.</p> <p>Parameters:</p> Name Type Description Default <code>bbox</code> <code>list</code> <p>The bounding box in the form [xmin, ymin, xmax, ymax].</p> required <code>huc_type</code> <code>str</code> <p>The HUC type, e.g., huc2, huc4, huc8. Defaults to \"huc8\".</p> required <code>datasets</code> <code>str</code> <p>Comma-delimited list of valid dataset tag names. The commonly used datasets include: Digital Elevation Model (DEM) 1 meter National Elevation Dataset (NED) 1/3 arc-second Current National Elevation Dataset (NED) 1/9 arc-second Current National Elevation Dataset (NED) 1 arc-second Current For more information, see https://apps.nationalmap.gov/tnmaccess/#/product Defaults to None, which will be the (NED) 1/3 arc-second</p> <code>None</code> <code>out_dir</code> <code>str</code> <p>The output directory. Defaults to None, which will use the current working directory.</p> <code>None</code> <code>return_url</code> <code>bool</code> <p>If True, the URL will be returned instead of downloading the data. Defaults to False.</p> <code>False</code> <code>download_args</code> <code>dict</code> <p>The download arguments to be passed to the download_file function. Defaults to {}.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>list</code> <p>The list of downloaded files.</p> Source code in <code>lidar/common.py</code> <pre><code>def download_ned_by_bbox(\n    bbox,\n    datasets=None,\n    out_dir=None,\n    return_url=False,\n    download_args={},\n    **kwargs,\n):\n    \"\"\"Download the US National Elevation Datasets (NED) for a bounding box. See https://apps.nationalmap.gov/tnmaccess/#/ for more information.\n\n    Args:\n        bbox (list): The bounding box in the form [xmin, ymin, xmax, ymax].\n        huc_type (str, optional): The HUC type, e.g., huc2, huc4, huc8. Defaults to \"huc8\".\n        datasets (str, optional): Comma-delimited list of valid dataset tag names. The commonly used datasets include:\n            Digital Elevation Model (DEM) 1 meter\n            National Elevation Dataset (NED) 1/3 arc-second Current\n            National Elevation Dataset (NED) 1/9 arc-second Current\n            National Elevation Dataset (NED) 1 arc-second Current\n            For more information, see https://apps.nationalmap.gov/tnmaccess/#/product\n            Defaults to None, which will be the (NED) 1/3 arc-second\n        out_dir (str, optional): The output directory. Defaults to None, which will use the current working directory.\n        return_url (bool, optional): If True, the URL will be returned instead of downloading the data. Defaults to False.\n        download_args (dict, optional): The download arguments to be passed to the download_file function. Defaults to {}.\n\n    Returns:\n        list: The list of downloaded files.\n    \"\"\"\n\n    import requests\n\n    endpoint = \"https://tnmaccess.nationalmap.gov/api/v1/products?\"\n\n    if datasets is None:\n        datasets = \"National Elevation Dataset (NED) 1/3 arc-second Current\"\n\n    if out_dir is None:\n        out_dir = os.getcwd()\n\n    if isinstance(bbox, list):\n        bbox = \",\".join([str(x) for x in bbox])\n\n    kwargs[\"datasets\"] = datasets\n    kwargs[\"bbox\"] = bbox\n\n    result = requests.get(endpoint, params=kwargs).json()\n    if \"errorMessage\" in result:\n        raise ValueError(result[\"errorMessage\"])\n    else:\n        links = [x[\"downloadURL\"] for x in result[\"items\"]]\n        for index, link in enumerate(links):\n            if \"historical\" in link:\n                link = link.replace(\"historical\", \"current\")[:-13] + \".tif\"\n                links[index] = link\n\n    if return_url:\n        return links\n    else:\n        for index, link in enumerate(links):\n\n            r = requests.head(link)\n            if r.status_code == 200:\n                filepath = os.path.join(out_dir, os.path.basename(link))\n                print(\n                    f\"Downloading {index + 1} of {len(links)}: {os.path.basename(link)}\"\n                )\n                download_file(link, filepath, **download_args)\n            else:\n                print(f\"{link} does not exist.\")\n</code></pre>"},{"location":"filling/#lidar.filling.download_ned_by_huc","title":"<code>download_ned_by_huc(huc_id, huc_type='huc8', datasets=None, out_dir=None, return_url=False, download_args={}, **kwargs)</code>","text":"<p>Download the US National Elevation Datasets (NED) for a Hydrologic Unit region. See https://apps.nationalmap.gov/tnmaccess/#/ for more information.</p> <p>Parameters:</p> Name Type Description Default <code>huc_id</code> <code>str</code> <p>The HUC ID, for example, \"01010002\"</p> required <code>huc_type</code> <code>str</code> <p>The HUC type, e.g., huc2, huc4, huc8. Defaults to \"huc8\".</p> <code>'huc8'</code> <code>datasets</code> <code>str</code> <p>Comma-delimited list of valid dataset tag names. The commonly used datasets include: Digital Elevation Model (DEM) 1 meter National Elevation Dataset (NED) 1/3 arc-second Current National Elevation Dataset (NED) 1/9 arc-second Current National Elevation Dataset (NED) 1 arc-second Current For more information, see https://apps.nationalmap.gov/tnmaccess/#/product Defaults to None, which will be the (NED) 1/3 arc-second</p> <code>None</code> <code>out_dir</code> <code>str</code> <p>The output directory. Defaults to None, which will use the current working directory.</p> <code>None</code> <code>return_url</code> <code>bool</code> <p>If True, the URL will be returned instead of downloading the data. Defaults to False.</p> <code>False</code> <code>download_args</code> <code>dict</code> <p>The download arguments to be passed to the download_file function. Defaults to {}.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>list</code> <p>The list of downloaded files.</p> Source code in <code>lidar/common.py</code> <pre><code>def download_ned_by_huc(\n    huc_id,\n    huc_type=\"huc8\",\n    datasets=None,\n    out_dir=None,\n    return_url=False,\n    download_args={},\n    **kwargs,\n):\n    \"\"\"Download the US National Elevation Datasets (NED) for a Hydrologic Unit region. See https://apps.nationalmap.gov/tnmaccess/#/ for more information.\n\n    Args:\n        huc_id (str): The HUC ID, for example, \"01010002\"\n        huc_type (str, optional): The HUC type, e.g., huc2, huc4, huc8. Defaults to \"huc8\".\n        datasets (str, optional): Comma-delimited list of valid dataset tag names. The commonly used datasets include:\n            Digital Elevation Model (DEM) 1 meter\n            National Elevation Dataset (NED) 1/3 arc-second Current\n            National Elevation Dataset (NED) 1/9 arc-second Current\n            National Elevation Dataset (NED) 1 arc-second Current\n            For more information, see https://apps.nationalmap.gov/tnmaccess/#/product\n            Defaults to None, which will be the (NED) 1/3 arc-second\n        out_dir (str, optional): The output directory. Defaults to None, which will use the current working directory.\n        return_url (bool, optional): If True, the URL will be returned instead of downloading the data. Defaults to False.\n        download_args (dict, optional): The download arguments to be passed to the download_file function. Defaults to {}.\n\n    Returns:\n        list: The list of downloaded files.\n    \"\"\"\n\n    import requests\n\n    endpoint = \"https://tnmaccess.nationalmap.gov/api/v1/products?\"\n\n    if datasets is None:\n        datasets = \"National Elevation Dataset (NED) 1/3 arc-second Current\"\n\n    if out_dir is None:\n        out_dir = os.getcwd()\n\n    kwargs[\"datasets\"] = datasets\n    kwargs[\"polyType\"] = huc_type\n    kwargs[\"polyCode\"] = huc_id\n\n    result = requests.get(endpoint, params=kwargs).json()\n    if \"errorMessage\" in result:\n        raise ValueError(result[\"errorMessage\"])\n    else:\n        links = [x[\"downloadURL\"] for x in result[\"items\"]]\n        for index, link in enumerate(links):\n            if \"historical\" in link:\n                link = link.replace(\"historical\", \"current\")[:-13] + \".tif\"\n                links[index] = link\n\n    if return_url:\n        return links\n    else:\n        for index, link in enumerate(links):\n\n            r = requests.head(link)\n            if r.status_code == 200:\n                filepath = os.path.join(out_dir, os.path.basename(link))\n                print(\n                    f\"Downloading {index + 1} of {len(links)}: {os.path.basename(link)}\"\n                )\n                download_file(link, filepath, **download_args)\n            else:\n                print(f\"{link} does not exist.\")\n</code></pre>"},{"location":"filling/#lidar.filling.extract_sinks_by_bbox","title":"<code>extract_sinks_by_bbox(bbox, filename, min_size=10, tmp_dir=None, mask=None, crs='EPSG:5070', kernel_size=3, resolution=10, to_cog=False, keep_files=True, ignore_warnings=True)</code>","text":"<p>Extract sinks from a DEM by HUC8.</p> <p>Parameters:</p> Name Type Description Default <code>bbox</code> <code>list</code> <p>The bounding box in the form of [minx, miny, maxx, maxy].</p> required <code>filename</code> <code>str</code> <p>The output depression file name.</p> required <code>min_size</code> <code>int</code> <p>The minimum number of pixels to be considered as a sink. Defaults to 10.</p> <code>10</code> <code>tmp_dir</code> <code>str</code> <p>The temporary directory. Defaults to None, e.g., using the current directory.</p> <code>None</code> <code>mask</code> <code>str</code> <p>The mask file path. Defaults to None.</p> <code>None</code> <code>crs</code> <code>str</code> <p>The coordinate reference system. Defaults to \"EPSG:5070\".</p> <code>'EPSG:5070'</code> <code>kernel_size</code> <code>int</code> <p>The kernel size for smoothing the DEM. Defaults to 3.</p> <code>3</code> <code>resolution</code> <code>int</code> <p>The resolution of the DEM. Defaults to 10.</p> <code>10</code> <code>to_cog</code> <code>bool</code> <p>Whether to convert the output to COG. Defaults to False.</p> <code>False</code> <code>keep_files</code> <code>bool</code> <p>Whether to keep the intermediate files. Defaults to True.</p> <code>True</code> <code>ignore_warnings</code> <code>bool</code> <p>Whether to ignore warnings. Defaults to True.</p> <code>True</code> Source code in <code>lidar/filling.py</code> <pre><code>def extract_sinks_by_bbox(\n    bbox,\n    filename,\n    min_size=10,\n    tmp_dir=None,\n    mask=None,\n    crs=\"EPSG:5070\",\n    kernel_size=3,\n    resolution=10,\n    to_cog=False,\n    keep_files=True,\n    ignore_warnings=True,\n):\n    \"\"\"Extract sinks from a DEM by HUC8.\n\n    Args:\n        bbox (list): The bounding box in the form of [minx, miny, maxx, maxy].\n        filename (str, optional): The output depression file name.\n        min_size (int, optional): The minimum number of pixels to be considered as a sink. Defaults to 10.\n        tmp_dir (str, optional): The temporary directory. Defaults to None, e.g., using the current directory.\n        mask (str, optional): The mask file path. Defaults to None.\n        crs (str, optional): The coordinate reference system. Defaults to \"EPSG:5070\".\n        kernel_size (int, optional): The kernel size for smoothing the DEM. Defaults to 3.\n        resolution (int, optional): The resolution of the DEM. Defaults to 10.\n        to_cog (bool, optional): Whether to convert the output to COG. Defaults to False.\n        keep_files (bool, optional): Whether to keep the intermediate files. Defaults to True.\n        ignore_warnings (bool, optional): Whether to ignore warnings. Defaults to True.\n    \"\"\"\n    import shutil\n    import warnings\n\n    if ignore_warnings:\n        warnings.filterwarnings(\"ignore\")\n\n    start_time = time.time()\n\n    if not filename.endswith(\".shp\"):\n        filename = filename + \".shp\"\n\n    filename = os.path.abspath(filename)\n\n    if tmp_dir is None:\n        tmp_dir = os.path.join(os.getcwd(), \"tmp\")\n\n    if not os.path.exists(tmp_dir):\n        os.makedirs(tmp_dir)\n\n    merge = os.path.join(tmp_dir, \"mosaic.tif\")\n    clip = os.path.join(tmp_dir, \"clip.tif\")\n    reproj = os.path.join(tmp_dir, \"reproj.tif\")\n    image = os.path.join(tmp_dir, \"image.tif\")\n    median = os.path.join(tmp_dir, \"median.tif\")\n    regions = os.path.join(tmp_dir, \"regions.shp\")\n    regions_info = os.path.join(tmp_dir, \"regions_info.csv\")\n\n    try:\n        download_ned_by_bbox(bbox, out_dir=tmp_dir)\n\n        if not os.path.exists(merge):\n            print(\"Merging NED tiles ...\")\n            mosaic(tmp_dir, merge)\n\n        if mask is not None:\n            clip_image(merge, mask, clip)\n        else:\n            clip = merge\n\n        reproject_image(clip, reproj, crs)\n        resample(reproj, image, resolution)\n        MedianFilter(image, kernel_size, median)\n        if to_cog:\n            image_to_cog(median, median)\n        ExtractSinks(median, min_size, tmp_dir)\n        join_tables(regions, regions_info, filename)\n\n        for file in [merge, clip, reproj, image]:\n            if os.path.exists(file):\n                os.remove(file)\n\n        if not keep_files:\n            shutil.rmtree(tmp_dir)\n    except Exception as e:\n        print(e)\n        return None\n\n    end_time = time.time()\n    print(\"Total run time:\\t\\t\\t {:.4f} s\\n\".format(end_time - start_time))\n</code></pre>"},{"location":"filling/#lidar.filling.extract_sinks_by_huc8","title":"<code>extract_sinks_by_huc8(huc8, min_size=10, filename=None, tmp_dir=None, wbd=None, crs='EPSG:5070', kernel_size=3, resolution=10, keep_files=True, error_file=None, ignore_warnings=True)</code>","text":"<p>Extract sinks from a DEM by HUC8.</p> <p>Parameters:</p> Name Type Description Default <code>huc8</code> <code>str</code> <p>The HUC8 code, e.g., 01010002</p> required <code>min_size</code> <code>int</code> <p>The minimum number of pixels to be considered as a sink. Defaults to 10.</p> <code>10</code> <code>filename</code> <code>str</code> <p>The output depression file name. Defaults to None, e,g., using the HUC8 code.</p> <code>None</code> <code>tmp_dir</code> <code>str</code> <p>The temporary directory. Defaults to None, e.g., using the current directory.</p> <code>None</code> <code>wbd</code> <code>str | GeoDataFrame</code> <p>The watershed boundary file. Defaults to None.</p> <code>None</code> <code>crs</code> <code>str</code> <p>The coordinate reference system. Defaults to \"EPSG:5070\".</p> <code>'EPSG:5070'</code> <code>kernel_size</code> <code>int</code> <p>The kernel size for smoothing the DEM. Defaults to 3.</p> <code>3</code> <code>resolution</code> <code>int</code> <p>The resolution of the DEM. Defaults to 10.</p> <code>10</code> <code>keep_files</code> <code>bool</code> <p>Whether to keep the intermediate files. Defaults to True.</p> <code>True</code> <code>error_file</code> <code>_type_</code> <p>The file to save the error IDs. Defaults to None.</p> <code>None</code> <code>ignore_warnings</code> <code>bool</code> <p>Whether to ignore warnings. Defaults to True.</p> <code>True</code> Source code in <code>lidar/filling.py</code> <pre><code>def extract_sinks_by_huc8(\n    huc8,\n    min_size=10,\n    filename=None,\n    tmp_dir=None,\n    wbd=None,\n    crs=\"EPSG:5070\",\n    kernel_size=3,\n    resolution=10,\n    keep_files=True,\n    error_file=None,\n    ignore_warnings=True,\n):\n    \"\"\"Extract sinks from a DEM by HUC8.\n\n    Args:\n        huc8 (str): The HUC8 code, e.g., 01010002\n        min_size (int, optional): The minimum number of pixels to be considered as a sink. Defaults to 10.\n        filename (str, optional): The output depression file name. Defaults to None, e,g., using the HUC8 code.\n        tmp_dir (str, optional): The temporary directory. Defaults to None, e.g., using the current directory.\n        wbd (str | GeoDataFrame, optional): The watershed boundary file. Defaults to None.\n        crs (str, optional): The coordinate reference system. Defaults to \"EPSG:5070\".\n        kernel_size (int, optional): The kernel size for smoothing the DEM. Defaults to 3.\n        resolution (int, optional): The resolution of the DEM. Defaults to 10.\n        keep_files (bool, optional): Whether to keep the intermediate files. Defaults to True.\n        error_file (_type_, optional): The file to save the error IDs. Defaults to None.\n        ignore_warnings (bool, optional): Whether to ignore warnings. Defaults to True.\n    \"\"\"\n    import shutil\n    import warnings\n    import geopandas as gpd\n\n    if ignore_warnings:\n        warnings.filterwarnings(\"ignore\")\n\n    start_time = time.time()\n\n    if filename is None:\n        filename = huc8\n\n    if not filename.endswith(\".shp\"):\n        filename = filename + \".shp\"\n\n    filename = os.path.abspath(filename)\n\n    if tmp_dir is None:\n        tmp_dir = os.path.join(os.getcwd(), huc8)\n\n    if not os.path.exists(tmp_dir):\n        os.makedirs(tmp_dir)\n\n    merge = os.path.join(tmp_dir, \"mosaic.tif\")\n    mask = os.path.join(tmp_dir, \"mask.geojson\")\n    clip = os.path.join(tmp_dir, \"clip.tif\")\n    reproj = os.path.join(tmp_dir, \"reproj.tif\")\n    image = os.path.join(tmp_dir, \"image.tif\")\n    median = os.path.join(tmp_dir, \"median.tif\")\n    regions = os.path.join(tmp_dir, \"regions.shp\")\n    regions_info = os.path.join(tmp_dir, \"regions_info.csv\")\n\n    try:\n        download_ned_by_huc(huc8, out_dir=tmp_dir)\n\n        if wbd is None:\n            print(\"Downloading WBD ...\")\n            hu8_url = \"https://drive.google.com/file/d/1AVBPVVAzsLs8dnF_bCvFvGMCAEgaPthh/view?usp=sharing\"\n            output = os.path.join(tmp_dir, \"WBDHU8_CONUS.zip\")\n            wbd = download_file(hu8_url, output=output, unzip=False)\n\n        if isinstance(wbd, str):\n            print(\"Reading WBD ...\")\n            gdf = gpd.read_file(wbd)\n        elif isinstance(wbd, gpd.GeoDataFrame):\n            gdf = wbd\n        else:\n            raise ValueError(\"shp_path must be a filepath or a GeoDataFrame.\")\n\n        selected = gdf[gdf[\"huc8\"] == huc8].copy()\n        selected.to_crs(epsg=4326, inplace=True)\n        selected.to_file(mask)\n\n        if not os.path.exists(merge):\n            print(\"Merging NED tiles ...\")\n            mosaic(tmp_dir, merge)\n        clip_image(merge, mask, clip)\n        reproject_image(clip, reproj, crs)\n        resample(reproj, image, resolution)\n        MedianFilter(image, kernel_size, median)\n        ExtractSinks(median, min_size, tmp_dir)\n        join_tables(regions, regions_info, filename)\n\n        for file in [merge, mask, clip, reproj, image]:\n            if os.path.exists(file):\n                os.remove(file)\n\n        if not keep_files:\n            shutil.rmtree(tmp_dir)\n    except Exception as e:\n        if error_file is not None:\n            with open(error_file, \"a\") as f:\n                f.write(huc8 + \"\\n\")\n\n        if os.path.exists(tmp_dir):\n            shutil.rmtree(tmp_dir)\n        print(e)\n        return None\n\n    end_time = time.time()\n    print(\"Total run time:\\t\\t\\t {:.4f} s\\n\".format(end_time - start_time))\n</code></pre>"},{"location":"filling/#lidar.filling.extract_sinks_by_huc8_batch","title":"<code>extract_sinks_by_huc8_batch(huc_ids=None, min_size=10, out_dir=None, tmp_dir=None, wbd=None, crs='EPSG:5070', kernel_size=3, resolution=10, keep_files=False, reverse=False, error_file=None, ignore_warnings=True, ignored_ids=[], overwrite=False)</code>","text":"<p>Extract sinks from NED by HUC8.</p> <p>Parameters:</p> Name Type Description Default <code>huc8</code> <code>str</code> <p>The HUC8 code, e.g., 01010002</p> required <code>min_size</code> <code>int</code> <p>The minimum number of pixels to be considered as a sink. Defaults to 10.</p> <code>10</code> <code>filename</code> <code>str</code> <p>The output depression file name. Defaults to None, e,g., using the HUC8 code.</p> required <code>tmp_dir</code> <code>str</code> <p>The temporary directory. Defaults to None, e.g., using the current directory.</p> <code>None</code> <code>wbd</code> <code>str | GeoDataFrame</code> <p>The watershed boundary file. Defaults to None.</p> <code>None</code> <code>crs</code> <code>str</code> <p>The coordinate reference system. Defaults to \"EPSG:5070\".</p> <code>'EPSG:5070'</code> <code>kernel_size</code> <code>int</code> <p>The kernel size for smoothing the DEM. Defaults to 3.</p> <code>3</code> <code>resolution</code> <code>int</code> <p>The resolution of the DEM. Defaults to 10.</p> <code>10</code> <code>keep_files</code> <code>bool</code> <p>Whether to keep the intermediate files. Defaults to True.</p> <code>False</code> <code>reverse</code> <code>bool</code> <p>Whether to reverse the HUC8 list. Defaults to False.</p> <code>False</code> <code>error_file</code> <code>_type_</code> <p>The file to save the error IDs. Defaults to None.</p> <code>None</code> <code>ignore_warnings</code> <code>bool</code> <p>Whether to ignore warnings. Defaults to True.</p> <code>True</code> <code>overwrite</code> <code>bool</code> <p>Whether to overwrite the existing files. Defaults to False.</p> <code>False</code> Source code in <code>lidar/filling.py</code> <pre><code>def extract_sinks_by_huc8_batch(\n    huc_ids=None,\n    min_size=10,\n    out_dir=None,\n    tmp_dir=None,\n    wbd=None,\n    crs=\"EPSG:5070\",\n    kernel_size=3,\n    resolution=10,\n    keep_files=False,\n    reverse=False,\n    error_file=None,\n    ignore_warnings=True,\n    ignored_ids=[],\n    overwrite=False,\n):\n    \"\"\"Extract sinks from NED by HUC8.\n\n    Args:\n        huc8 (str): The HUC8 code, e.g., 01010002\n        min_size (int, optional): The minimum number of pixels to be considered as a sink. Defaults to 10.\n        filename (str, optional): The output depression file name. Defaults to None, e,g., using the HUC8 code.\n        tmp_dir (str, optional): The temporary directory. Defaults to None, e.g., using the current directory.\n        wbd (str | GeoDataFrame, optional): The watershed boundary file. Defaults to None.\n        crs (str, optional): The coordinate reference system. Defaults to \"EPSG:5070\".\n        kernel_size (int, optional): The kernel size for smoothing the DEM. Defaults to 3.\n        resolution (int, optional): The resolution of the DEM. Defaults to 10.\n        keep_files (bool, optional): Whether to keep the intermediate files. Defaults to True.\n        reverse (bool, optional): Whether to reverse the HUC8 list. Defaults to False.\n        error_file (_type_, optional): The file to save the error IDs. Defaults to None.\n        ignore_warnings (bool, optional): Whether to ignore warnings. Defaults to True.\n        overwrite (bool, optional): Whether to overwrite the existing files. Defaults to False.\n    \"\"\"\n    import pandas as pd\n\n    if huc_ids is None:\n        url = \"https://raw.githubusercontent.com/giswqs/lidar/master/examples/data/huc8.csv\"\n        df = pd.read_csv(url, dtype=str)\n        huc_ids = df[\"huc8_id\"].tolist()\n\n    if not isinstance(huc_ids, list):\n        huc_ids = [huc_ids]\n\n    if reverse:\n        huc_ids = huc_ids[::-1]\n\n    if out_dir is None:\n        out_dir = os.getcwd()\n\n    for index, huc8 in enumerate(huc_ids):\n        print(f\"Processing {index+1}:{len(huc_ids)}: {huc8} ...\")\n        if huc8 in ignored_ids:\n            continue\n        filename = os.path.join(out_dir, str(huc8) + \".shp\")\n        if not os.path.exists(filename) or (os.path.exists(filename) and overwrite):\n            extract_sinks_by_huc8(\n                huc8,\n                min_size,\n                filename,\n                tmp_dir,\n                wbd,\n                crs,\n                kernel_size,\n                resolution,\n                keep_files,\n                error_file,\n                ignore_warnings,\n            )\n        else:\n            print(f\"File already exists: {filename}\")\n</code></pre>"},{"location":"filling/#lidar.filling.geometry_bounds","title":"<code>geometry_bounds(geometry, decimals=4)</code>","text":"<p>Returns the bounds of a geometry.</p> <p>Parameters:</p> Name Type Description Default <code>geometry</code> <code>dict</code> <p>A GeoJSON geometry.</p> required <code>decimals</code> <code>int</code> <p>The number of decimal places to round the bounds to. Defaults to 4.</p> <code>4</code> <p>Returns:</p> Name Type Description <code>list</code> <p>A list of bounds in the form of [minx, miny, maxx, maxy].</p> Source code in <code>lidar/common.py</code> <pre><code>def geometry_bounds(geometry, decimals=4):\n    \"\"\"Returns the bounds of a geometry.\n\n    Args:\n        geometry (dict): A GeoJSON geometry.\n        decimals (int, optional): The number of decimal places to round the bounds to. Defaults to 4.\n\n    Returns:\n        list: A list of bounds in the form of [minx, miny, maxx, maxy].\n    \"\"\"\n    if isinstance(geometry, dict):\n        if \"geometry\" in geometry:\n            coords = geometry[\"geometry\"][\"coordinates\"][0]\n        else:\n            coords = geometry[\"coordinates\"][0]\n\n    else:\n        raise ValueError(\"geometry must be a GeoJSON-like dictionary.\")\n\n    x = [p[0] for p in coords]\n    y = [p[1] for p in coords]\n    west = round(min(x), decimals)\n    east = round(max(x), decimals)\n    south = round(min(y), decimals)\n    north = round(max(y), decimals)\n    return [west, south, east, north]\n</code></pre>"},{"location":"filling/#lidar.filling.get_dep_props","title":"<code>get_dep_props(objects, resolution)</code>","text":"<p>Computes depression attributes.</p> <p>Parameters:</p> Name Type Description Default <code>objects</code> <code>object</code> <p>The labeled objects.</p> required <code>resolution</code> <code>float</code> <p>The spatial reoslution of the image.</p> required <p>Returns:</p> Name Type Description <code>list</code> <p>A list of depression objects with attributes.</p> Source code in <code>lidar/filling.py</code> <pre><code>def get_dep_props(objects, resolution):\n    \"\"\"Computes depression attributes.\n\n    Args:\n        objects (object): The labeled objects.\n        resolution (float): The spatial reoslution of the image.\n\n    Returns:\n        list: A list of depression objects with attributes.\n    \"\"\"\n    dep_list = []\n\n    for object in objects:\n        unique_id = object.label\n        count = object.area\n        size = count * pow(resolution, 2)  # depression size\n        min_elev = float(object.min_intensity)  # depression min elevation\n        max_elev = float(object.max_intensity)  # depression max elevation\n        max_depth = max_elev - min_elev  # depression max depth\n        mean_depth = float(\n            (max_elev * count - np.sum(object.intensity_image)) / count\n        )  # depression mean depth\n        volume = mean_depth * count * pow(resolution, 2)  # depression volume\n        perimeter = object.perimeter * resolution\n        major_axis = object.major_axis_length * resolution\n        minor_axis = object.minor_axis_length * resolution\n        if minor_axis == 0:\n            minor_axis = resolution\n        elongatedness = major_axis * 1.0 / minor_axis\n        eccentricity = object.eccentricity\n        orientation = object.orientation / 3.1415 * 180\n        area_bbox_ratio = object.extent\n\n        dep_list.append(\n            Depression(\n                unique_id,\n                count,\n                size,\n                volume,\n                mean_depth,\n                max_depth,\n                min_elev,\n                max_elev,\n                perimeter,\n                major_axis,\n                minor_axis,\n                elongatedness,\n                eccentricity,\n                orientation,\n                area_bbox_ratio,\n            )\n        )\n\n    return dep_list\n</code></pre>"},{"location":"filling/#lidar.filling.github_raw_url","title":"<code>github_raw_url(url)</code>","text":"<p>Get the raw URL for a GitHub file.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The GitHub URL.</p> required <p>Returns:     str: The raw URL.</p> Source code in <code>lidar/common.py</code> <pre><code>def github_raw_url(url):\n    \"\"\"Get the raw URL for a GitHub file.\n\n    Args:\n        url (str): The GitHub URL.\n    Returns:\n        str: The raw URL.\n    \"\"\"\n    if isinstance(url, str) and url.startswith(\"https://github.com/\") and \"blob\" in url:\n        url = url.replace(\"github.com\", \"raw.githubusercontent.com\").replace(\n            \"blob/\", \"\"\n        )\n    return url\n</code></pre>"},{"location":"filling/#lidar.filling.image_to_cog","title":"<code>image_to_cog(source, dst_path=None, profile='deflate', **kwargs)</code>","text":"<p>Converts an image to a COG file.</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>str</code> <p>A dataset path, URL or rasterio.io.DatasetReader object.</p> required <code>dst_path</code> <code>str</code> <p>An output dataset path or or PathLike object. Defaults to None.</p> <code>None</code> <code>profile</code> <code>str</code> <p>COG profile. More at https://cogeotiff.github.io/rio-cogeo/profile. Defaults to \"deflate\".</p> <code>'deflate'</code> <p>Raises:</p> Type Description <code>ImportError</code> <p>If rio-cogeo is not installed.</p> <code>FileNotFoundError</code> <p>If the source file could not be found.</p> Source code in <code>lidar/filling.py</code> <pre><code>def image_to_cog(source, dst_path=None, profile=\"deflate\", **kwargs):\n    \"\"\"Converts an image to a COG file.\n\n    Args:\n        source (str): A dataset path, URL or rasterio.io.DatasetReader object.\n        dst_path (str, optional): An output dataset path or or PathLike object. Defaults to None.\n        profile (str, optional): COG profile. More at https://cogeotiff.github.io/rio-cogeo/profile. Defaults to \"deflate\".\n\n    Raises:\n        ImportError: If rio-cogeo is not installed.\n        FileNotFoundError: If the source file could not be found.\n    \"\"\"\n    try:\n        from rio_cogeo.cogeo import cog_translate\n        from rio_cogeo.profiles import cog_profiles\n\n    except ImportError:\n        raise ImportError(\n            \"The rio-cogeo package is not installed. Please install it with `pip install rio-cogeo` or `conda install rio-cogeo -c conda-forge`.\"\n        )\n\n    if not source.startswith(\"http\"):\n        source = check_file_path(source)\n\n        if not os.path.exists(source):\n            raise FileNotFoundError(\"The provided input file could not be found.\")\n\n    if dst_path is None:\n        if not source.startswith(\"http\"):\n            dst_path = os.path.splitext(source)[0] + \"_cog.tif\"\n        else:\n            dst_path = temp_file_path(extension=\".tif\")\n\n    dst_path = check_file_path(dst_path)\n\n    dst_profile = cog_profiles.get(profile)\n    cog_translate(source, dst_path, dst_profile, **kwargs)\n</code></pre>"},{"location":"filling/#lidar.filling.in_colab_shell","title":"<code>in_colab_shell()</code>","text":"<p>Tests if the code is being executed within Google Colab.</p> Source code in <code>lidar/common.py</code> <pre><code>def in_colab_shell():\n    \"\"\"Tests if the code is being executed within Google Colab.\"\"\"\n    try:\n        import google.colab  # pylint: disable=unused-variable\n\n        return True\n    except ImportError:\n        return False\n</code></pre>"},{"location":"filling/#lidar.filling.is_drive_mounted","title":"<code>is_drive_mounted()</code>","text":"<p>Checks whether Google Drive is mounted in Google Colab.</p> <p>Returns:</p> Name Type Description <code>bool</code> <p>Returns True if Google Drive is mounted, False otherwise.</p> Source code in <code>lidar/common.py</code> <pre><code>def is_drive_mounted():\n    \"\"\"Checks whether Google Drive is mounted in Google Colab.\n\n    Returns:\n        bool: Returns True if Google Drive is mounted, False otherwise.\n    \"\"\"\n    drive_path = \"/content/drive/My Drive\"\n    if os.path.exists(drive_path):\n        return True\n    else:\n        return False\n</code></pre>"},{"location":"filling/#lidar.filling.is_tool","title":"<code>is_tool(name)</code>","text":"<p>Check whether <code>name</code> is on PATH and marked as executable.</p> Source code in <code>lidar/common.py</code> <pre><code>def is_tool(name):\n    \"\"\"Check whether `name` is on PATH and marked as executable.\"\"\"\n\n    from shutil import which\n\n    return which(name) is not None\n</code></pre>"},{"location":"filling/#lidar.filling.join_csv_to_gdf","title":"<code>join_csv_to_gdf(shapefile_path, csv_path, gdf_join_column, csv_join_column)</code>","text":"<p>Joins a CSV file to a GeoDataFrame based on a common column.</p> <p>Parameters:</p> Name Type Description Default <code>shapefile_path</code> <code>str</code> <p>Path to the Shapefile.</p> required <code>csv_path</code> <code>str</code> <p>Path to the CSV file.</p> required <code>gdf_join_column</code> <code>str</code> <p>Name of the join column in the GeoDataFrame.</p> required <code>csv_join_column</code> <code>str</code> <p>Name of the join column in the CSV.</p> required <p>Returns:</p> Type Description <p>geopandas.GeoDataFrame: The GeoDataFrame with the joined data.</p> Source code in <code>lidar/common.py</code> <pre><code>def join_csv_to_gdf(shapefile_path, csv_path, gdf_join_column, csv_join_column):\n    \"\"\"\n    Joins a CSV file to a GeoDataFrame based on a common column.\n\n    Args:\n        shapefile_path (str): Path to the Shapefile.\n        csv_path (str): Path to the CSV file.\n        gdf_join_column (str): Name of the join column in the GeoDataFrame.\n        csv_join_column (str): Name of the join column in the CSV.\n\n    Returns:\n        geopandas.GeoDataFrame: The GeoDataFrame with the joined data.\n    \"\"\"\n    import pandas as pd\n    import geopandas as gpd\n\n    # Load the datasets\n    gdf = gpd.read_file(shapefile_path)\n    csv_data = pd.read_csv(csv_path)\n\n    # Perform the join\n    result = gdf.merge(\n        csv_data, left_on=gdf_join_column, right_on=csv_join_column, how=\"left\"\n    )\n\n    return result\n</code></pre>"},{"location":"filling/#lidar.filling.join_tables","title":"<code>join_tables(in_shp, in_csv, out_shp)</code>","text":"<p>Joins a CSV table to a shapefile.</p> <p>Parameters:</p> Name Type Description Default <code>in_shp</code> <code>str</code> <p>Path to the input shapefile.</p> required <code>in_csv</code> <code>str</code> <p>Path to the input CSV file.</p> required <code>out_shp</code> <code>str</code> <p>Path to the output shapefile.</p> required Source code in <code>lidar/common.py</code> <pre><code>def join_tables(in_shp, in_csv, out_shp):\n    \"\"\"Joins a CSV table to a shapefile.\n\n    Args:\n        in_shp (str): Path to the input shapefile.\n        in_csv (str): Path to the input CSV file.\n        out_shp (str): Path to the output shapefile.\n    \"\"\"\n    import geopandas as gpd\n    import pandas as pd\n\n    dep_df = gpd.read_file(in_shp)\n    info_df = pd.read_csv(in_csv)\n    if len(info_df) &gt; 0:\n        info_df.columns = [col.replace(\"-\", \"_\")[:10] for col in info_df.columns]\n        info_df[\"id\"] = info_df[\"region_id\"]\n        info_df.drop(\"region_id\", axis=1, inplace=True)\n        df = pd.merge(dep_df, info_df, on=\"id\")\n        df.to_file(out_shp)\n    else:\n        print(\"No data to join\")\n</code></pre>"},{"location":"filling/#lidar.filling.lidar_to_dsm","title":"<code>lidar_to_dsm(filename, output=None, resolution=1.0, radius=0.5, minz=None, maxz=None, max_triangle_edge_length=None, verbose=True, **kwargs)</code>","text":"<p>Generates a digital surface model (DSM) from a LiDAR point cloud. It is a wrapper for the <code>whitebox.lidar_digital_surface_model</code>.     See https://www.whiteboxgeo.com/manual/wbt_book/available_tools/lidar_tools.html#LidarDigitalSurfaceModel</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>The input LiDAR file.</p> required <code>output</code> <code>str</code> <p>The output file. Defaults to None.</p> <code>None</code> <code>resolution</code> <code>float</code> <p>The resolution of the output raster. Defaults to 1.0.</p> <code>1.0</code> <code>radius</code> <code>float</code> <p>The search radius. Defaults to 0.5.</p> <code>0.5</code> <code>minz</code> <code>float</code> <p>Optional minimum elevation for inclusion in interpolation.</p> <code>None</code> <code>maxz</code> <code>float</code> <p>Optional maximum elevation for inclusion in interpolation.</p> <code>None</code> <code>max_triangle_edge_length</code> <code>float</code> <p>Optional maximum triangle edge length; triangles larger than this size will not be gridded</p> <code>None</code> <code>verbose</code> <code>bool</code> <p>description. Defaults to True.</p> <code>True</code> Source code in <code>lidar/common.py</code> <pre><code>def lidar_to_dsm(\n    filename,\n    output=None,\n    resolution=1.0,\n    radius=0.5,\n    minz=None,\n    maxz=None,\n    max_triangle_edge_length=None,\n    verbose=True,\n    **kwargs,\n):\n    \"\"\"Generates a digital surface model (DSM) from a LiDAR point cloud. It is a wrapper for the `whitebox.lidar_digital_surface_model`.\n        See https://www.whiteboxgeo.com/manual/wbt_book/available_tools/lidar_tools.html#LidarDigitalSurfaceModel\n\n    Args:\n        filename (str): The input LiDAR file.\n        output (str, optional): The output file. Defaults to None.\n        resolution (float, optional): The resolution of the output raster. Defaults to 1.0.\n        radius (float, optional): The search radius. Defaults to 0.5.\n        minz (float, optional): Optional minimum elevation for inclusion in interpolation.\n        maxz (float, optional): Optional maximum elevation for inclusion in interpolation.\n        max_triangle_edge_length (float, optional): Optional maximum triangle edge length; triangles larger than this size will not be gridded\n        verbose (bool, optional): _description_. Defaults to True.\n    \"\"\"\n    import whitebox\n\n    wbt = whitebox.WhiteboxTools()\n    wbt.verbose = verbose\n\n    filename = os.path.abspath(filename)\n    if output is not None:\n        output = os.path.abspath(output)\n\n    wbt.lidar_digital_surface_model(\n        i=filename,\n        output=output,\n        resolution=resolution,\n        radius=radius,\n        minz=minz,\n        maxz=maxz,\n        max_triangle_edge_length=max_triangle_edge_length,\n        **kwargs,\n    )\n</code></pre>"},{"location":"filling/#lidar.filling.mosaic","title":"<code>mosaic(images, output, ext='.tif', merge_args={}, verbose=True, **kwargs)</code>","text":"<p>Mosaics a list of images into a single image. Inspired by https://bit.ly/3A6roDK.</p> <p>Parameters:</p> Name Type Description Default <code>images</code> <code>str | list</code> <p>An input directory containing images or a list of images.</p> required <code>output</code> <code>str</code> <p>The output image filepath.</p> required <code>ext</code> <code>str</code> <p>The image file extension. Defaults to '.tif'.</p> <code>'.tif'</code> <code>merge_args</code> <code>dict</code> <p>A dictionary of arguments to pass to the rasterio.merge function. Defaults to {}.</p> <code>{}</code> <code>verbose</code> <code>bool</code> <p>Whether to print progress. Defaults to True.</p> <code>True</code> Source code in <code>lidar/common.py</code> <pre><code>def mosaic(images, output, ext=\".tif\", merge_args={}, verbose=True, **kwargs):\n    \"\"\"Mosaics a list of images into a single image. Inspired by https://bit.ly/3A6roDK.\n\n    Args:\n        images (str | list): An input directory containing images or a list of images.\n        output (str): The output image filepath.\n        ext (str, optional): The image file extension. Defaults to '.tif'.\n        merge_args (dict, optional): A dictionary of arguments to pass to the rasterio.merge function. Defaults to {}.\n        verbose (bool, optional): Whether to print progress. Defaults to True.\n\n    \"\"\"\n    from rasterio.merge import merge\n    import rasterio as rio\n    from pathlib import Path\n    import shutil\n\n    output = os.path.abspath(output)\n\n    if isinstance(images, str):\n        path = Path(images)\n        raster_files = list(path.iterdir())\n        raster_files = [f for f in raster_files if f.suffix == ext]\n    elif isinstance(images, list):\n        raster_files = images\n    else:\n        raise ValueError(\"images must be a list of raster files.\")\n\n    if len(raster_files) == 0:\n        print(\"No raster files found.\")\n        return\n    elif len(raster_files) == 1:\n        shutil.copyfile(raster_files[0], output)\n        return\n\n    raster_to_mosiac = []\n\n    if not os.path.exists(os.path.dirname(output)):\n        os.makedirs(os.path.dirname(output))\n\n    for index, p in enumerate(raster_files):\n        if verbose:\n            print(f\"Reading {index+1}/{len(raster_files)}: {os.path.basename(p)}\")\n        raster = rio.open(p, **kwargs)\n        raster_to_mosiac.append(raster)\n\n    if verbose:\n        print(\"Merging rasters...\")\n    arr, transform = merge(raster_to_mosiac, **merge_args)\n\n    output_meta = raster.meta.copy()\n    output_meta.update(\n        {\n            \"driver\": \"GTiff\",\n            \"height\": arr.shape[1],\n            \"width\": arr.shape[2],\n            \"transform\": transform,\n        }\n    )\n\n    with rio.open(output, \"w\", **output_meta) as m:\n        m.write(arr)\n</code></pre>"},{"location":"filling/#lidar.filling.np2rdarray","title":"<code>np2rdarray(in_array, no_data, projection, geotransform)</code>","text":"<p>Converts an numpy array to rdarray.</p> <p>Parameters:</p> Name Type Description Default <code>in_array</code> <code>array</code> <p>The input numpy array.</p> required <code>no_data</code> <code>float</code> <p>The no_data value of the array.</p> required <code>projection</code> <code>str</code> <p>The projection of the image.</p> required <code>geotransform</code> <code>str</code> <p>The geotransform of the image.</p> required <p>Returns:</p> Name Type Description <code>object</code> <p>The richDEM array.</p> Source code in <code>lidar/filling.py</code> <pre><code>def np2rdarray(in_array, no_data, projection, geotransform):\n    \"\"\"Converts an numpy array to rdarray.\n\n    Args:\n        in_array (array): The input numpy array.\n        no_data (float): The no_data value of the array.\n        projection (str): The projection of the image.\n        geotransform (str): The geotransform of the image.\n\n    Returns:\n        object: The richDEM array.\n    \"\"\"\n    out_array = rd.rdarray(in_array, no_data=no_data)\n    out_array.projection = projection\n    out_array.geotransform = geotransform\n    return out_array\n</code></pre>"},{"location":"filling/#lidar.filling.polygonize","title":"<code>polygonize(img, shp_path)</code>","text":"<p>Converts a raster image to vector.</p> <p>Parameters:</p> Name Type Description Default <code>img</code> <code>str</code> <p>File path to the input image.</p> required <code>shp_path</code> <code>str</code> <p>File path to the output shapefile.</p> required Source code in <code>lidar/filling.py</code> <pre><code>def polygonize(img, shp_path):\n    \"\"\"Converts a raster image to vector.\n\n    Args:\n        img (str): File path to the input image.\n        shp_path (str): File path to the output shapefile.\n    \"\"\"\n    # mapping between gdal type and ogr field type\n    type_mapping = {\n        gdal.GDT_Byte: ogr.OFTInteger,\n        gdal.GDT_UInt16: ogr.OFTInteger,\n        gdal.GDT_Int16: ogr.OFTInteger,\n        gdal.GDT_UInt32: ogr.OFTInteger,\n        gdal.GDT_Int32: ogr.OFTInteger,\n        gdal.GDT_Float32: ogr.OFTReal,\n        gdal.GDT_Float64: ogr.OFTReal,\n        gdal.GDT_CInt16: ogr.OFTInteger,\n        gdal.GDT_CInt32: ogr.OFTInteger,\n        gdal.GDT_CFloat32: ogr.OFTReal,\n        gdal.GDT_CFloat64: ogr.OFTReal,\n    }\n\n    ds = gdal.Open(img)\n    prj = ds.GetProjection()\n    srcband = ds.GetRasterBand(1)\n\n    dst_layername = \"Shape\"\n    drv = ogr.GetDriverByName(\"ESRI Shapefile\")\n    dst_ds = drv.CreateDataSource(shp_path)\n    srs = osr.SpatialReference(wkt=prj)\n\n    dst_layer = dst_ds.CreateLayer(dst_layername, srs=srs)\n    # raster_field = ogr.FieldDefn('id', type_mapping[srcband.DataType])\n    raster_field = ogr.FieldDefn(\"id\", type_mapping[gdal.GDT_Int32])\n    dst_layer.CreateField(raster_field)\n    gdal.Polygonize(srcband, srcband, dst_layer, 0, [], callback=None)\n    del img, ds, srcband, dst_ds, dst_layer\n</code></pre>"},{"location":"filling/#lidar.filling.random_string","title":"<code>random_string(string_length=3)</code>","text":"<p>Generates a random string of fixed length.</p> <p>Parameters:</p> Name Type Description Default <code>string_length</code> <code>int</code> <p>Fixed length. Defaults to 3.</p> <code>3</code> <p>Returns:</p> Name Type Description <code>str</code> <p>A random string</p> Source code in <code>lidar/common.py</code> <pre><code>def random_string(string_length=3):\n    \"\"\"Generates a random string of fixed length.\n\n    Args:\n        string_length (int, optional): Fixed length. Defaults to 3.\n\n    Returns:\n        str: A random string\n    \"\"\"\n    import random\n    import string\n\n    # random.seed(1001)\n    letters = string.ascii_lowercase\n    return \"\".join(random.choice(letters) for i in range(string_length))\n</code></pre>"},{"location":"filling/#lidar.filling.read_lidar","title":"<code>read_lidar(filename, **kwargs)</code>","text":"<p>Read a LAS file.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>A local file path or HTTP URL to a LAS file.</p> required <p>Returns:</p> Name Type Description <code>LasData</code> <p>The LasData object return by laspy.read.</p> Source code in <code>lidar/common.py</code> <pre><code>def read_lidar(filename, **kwargs):\n    \"\"\"Read a LAS file.\n\n    Args:\n        filename (str): A local file path or HTTP URL to a LAS file.\n\n    Returns:\n        LasData: The LasData object return by laspy.read.\n    \"\"\"\n    try:\n        import laspy\n    except ImportError:\n        print(\n            \"The laspy package is required for this function. Use `pip install laspy[lazrs,laszip]` to install it.\"\n        )\n        return\n\n    if (\n        isinstance(filename, str)\n        and filename.startswith(\"http\")\n        and (filename.endswith(\".las\") or filename.endswith(\".laz\"))\n    ):\n        filename = github_raw_url(filename)\n        filename = download_file(filename)\n\n    return laspy.read(filename, **kwargs)\n</code></pre>"},{"location":"filling/#lidar.filling.regionGroup","title":"<code>regionGroup(img_array, min_size, no_data)</code>","text":"<p>IdentifIies regions based on region growing method</p> <p>Parameters:</p> Name Type Description Default <code>img_array</code> <code>array</code> <p>The numpy array containing the image.</p> required <code>min_size</code> <code>int</code> <p>The minimum number of pixels to be considered as a depression.</p> required <code>no_data</code> <code>float</code> <p>The no_data value of the image.</p> required <p>Returns:</p> Name Type Description <code>tuple</code> <p>The labelled objects and total number of labels.</p> Source code in <code>lidar/filling.py</code> <pre><code>def regionGroup(img_array, min_size, no_data):\n    \"\"\"IdentifIies regions based on region growing method\n\n    Args:\n        img_array (array): The numpy array containing the image.\n        min_size (int): The minimum number of pixels to be considered as a depression.\n        no_data (float): The no_data value of the image.\n\n    Returns:\n        tuple: The labelled objects and total number of labels.\n    \"\"\"\n    img_array[img_array == no_data] = 0\n    label_objects, nb_labels = ndimage.label(img_array)\n    sizes = np.bincount(label_objects.ravel())\n    mask_sizes = sizes &gt; min_size\n    mask_sizes[0] = 0\n    image_cleaned = mask_sizes[label_objects]\n    label_objects, nb_labels = ndimage.label(image_cleaned)\n    # nb_labels is the total number of objects. 0 represents background object.\n    return label_objects, nb_labels\n</code></pre>"},{"location":"filling/#lidar.filling.reproject_image","title":"<code>reproject_image(image, output, dst_crs='EPSG:4326', resampling='nearest', **kwargs)</code>","text":"<p>Reprojects an image.</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>str</code> <p>The input image filepath.</p> required <code>output</code> <code>str</code> <p>The output image filepath.</p> required <code>dst_crs</code> <code>str</code> <p>The destination CRS. Defaults to \"EPSG:4326\".</p> <code>'EPSG:4326'</code> <code>resampling</code> <code>Resampling</code> <p>The resampling method. Defaults to \"nearest\".</p> <code>'nearest'</code> <code>**kwargs</code> <p>Additional keyword arguments to pass to rasterio.open.</p> <code>{}</code> Source code in <code>lidar/common.py</code> <pre><code>def reproject_image(image, output, dst_crs=\"EPSG:4326\", resampling=\"nearest\", **kwargs):\n    \"\"\"Reprojects an image.\n\n    Args:\n        image (str): The input image filepath.\n        output (str): The output image filepath.\n        dst_crs (str, optional): The destination CRS. Defaults to \"EPSG:4326\".\n        resampling (Resampling, optional): The resampling method. Defaults to \"nearest\".\n        **kwargs: Additional keyword arguments to pass to rasterio.open.\n\n    \"\"\"\n    import rasterio as rio\n    from rasterio.warp import calculate_default_transform, reproject, Resampling\n\n    if isinstance(resampling, str):\n        resampling = getattr(Resampling, resampling)\n\n    image = os.path.abspath(image)\n    output = os.path.abspath(output)\n\n    if not os.path.exists(os.path.dirname(output)):\n        os.makedirs(os.path.dirname(output))\n\n    with rio.open(image, **kwargs) as src:\n        transform, width, height = calculate_default_transform(\n            src.crs, dst_crs, src.width, src.height, *src.bounds\n        )\n        kwargs = src.meta.copy()\n        kwargs.update(\n            {\n                \"crs\": dst_crs,\n                \"transform\": transform,\n                \"width\": width,\n                \"height\": height,\n            }\n        )\n\n        with rio.open(output, \"w\", **kwargs) as dst:\n            for i in range(1, src.count + 1):\n                reproject(\n                    source=rio.band(src, i),\n                    destination=rio.band(dst, i),\n                    src_transform=src.transform,\n                    src_crs=src.crs,\n                    dst_transform=transform,\n                    dst_crs=dst_crs,\n                    resampling=resampling,\n                    dst_resolution=(10, 10),\n                    **kwargs,\n                )\n</code></pre>"},{"location":"filling/#lidar.filling.resample","title":"<code>resample(src, dst, resolution, **kwargs)</code>","text":"<p>Resample a raster to a new resolution.</p> <p>Parameters:</p> Name Type Description Default <code>src</code> <code>str</code> <p>The source raster.</p> required <code>dst</code> <code>str</code> <p>The destination raster.</p> required <code>resolution</code> <code>float</code> <p>The new resolution.</p> required Source code in <code>lidar/common.py</code> <pre><code>def resample(src, dst, resolution, **kwargs):\n    \"\"\"Resample a raster to a new resolution.\n\n    Args:\n        src (str): The source raster.\n        dst (str): The destination raster.\n        resolution (float): The new resolution.\n    \"\"\"\n    from osgeo import gdal\n\n    gdal.Warp(dst, src, xRes=resolution, yRes=resolution, **kwargs)\n</code></pre>"},{"location":"filling/#lidar.filling.temp_file_path","title":"<code>temp_file_path(extension)</code>","text":"<p>Returns a temporary file path.</p> <p>Parameters:</p> Name Type Description Default <code>extension</code> <code>str</code> <p>The file extension.</p> required <p>Returns:</p> Name Type Description <code>str</code> <p>The temporary file path.</p> Source code in <code>lidar/common.py</code> <pre><code>def temp_file_path(extension):\n    \"\"\"Returns a temporary file path.\n\n    Args:\n        extension (str): The file extension.\n\n    Returns:\n        str: The temporary file path.\n    \"\"\"\n\n    import tempfile\n    import uuid\n\n    if not extension.startswith(\".\"):\n        extension = \".\" + extension\n    file_id = str(uuid.uuid4())\n    file_path = os.path.join(tempfile.gettempdir(), f\"{file_id}{extension}\")\n\n    return file_path\n</code></pre>"},{"location":"filling/#lidar.filling.update_package","title":"<code>update_package()</code>","text":"<p>Updates the lidar package from the lidar GitHub repository without the need to use pip or conda. In this way, I don't have to keep updating pypi and conda-forge with every minor update of the package.</p> Source code in <code>lidar/common.py</code> <pre><code>def update_package():\n    \"\"\"Updates the lidar package from the lidar GitHub repository without the need to use pip or conda.\n    In this way, I don't have to keep updating pypi and conda-forge with every minor update of the package.\n\n    \"\"\"\n    import shutil\n\n    try:\n        download_dir = os.path.join(os.path.expanduser(\"~\"), \"Downloads\")\n        if not os.path.exists(download_dir):\n            os.makedirs(download_dir)\n        clone_repo(out_dir=download_dir)\n\n        pkg_dir = os.path.join(download_dir, \"lidar-master\")\n        work_dir = os.getcwd()\n        os.chdir(pkg_dir)\n\n        if shutil.which(\"pip\") is None:\n            cmd = \"pip3 install .\"\n        else:\n            cmd = \"pip install .\"\n\n        os.system(cmd)\n        os.chdir(work_dir)\n\n        print(\n            \"\\nPlease comment out 'lidar.update_package()' and restart the kernel to take effect:\\nJupyter menu -&gt; Kernel -&gt; Restart &amp; Clear Output\"\n        )\n\n    except Exception as e:\n        raise Exception(e)\n</code></pre>"},{"location":"filling/#lidar.filling.view_lidar","title":"<code>view_lidar(filename, cmap='terrain', backend='pyvista', background=None, eye_dome_lighting=False, **kwargs)</code>","text":"<p>View LiDAR data in 3D.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>The filepath to the LiDAR data.</p> required <code>cmap</code> <code>str</code> <p>The colormap to use. Defaults to \"terrain\". cmap currently does not work for the open3d backend.</p> <code>'terrain'</code> <code>backend</code> <code>str</code> <p>The plotting backend to use, can be pyvista, ipygany, panel, and open3d. Defaults to \"pyvista\".</p> <code>'pyvista'</code> <code>background</code> <code>str</code> <p>The background color to use. Defaults to None.</p> <code>None</code> <code>eye_dome_lighting</code> <code>bool</code> <p>Whether to use eye dome lighting. Defaults to False.</p> <code>False</code> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the file does not exist.</p> <code>ValueError</code> <p>If the backend is not supported.</p> Source code in <code>lidar/common.py</code> <pre><code>def view_lidar(\n    filename,\n    cmap=\"terrain\",\n    backend=\"pyvista\",\n    background=None,\n    eye_dome_lighting=False,\n    **kwargs,\n):\n    \"\"\"View LiDAR data in 3D.\n\n    Args:\n        filename (str): The filepath to the LiDAR data.\n        cmap (str, optional): The colormap to use. Defaults to \"terrain\". cmap currently does not work for the open3d backend.\n        backend (str, optional): The plotting backend to use, can be pyvista, ipygany, panel, and open3d. Defaults to \"pyvista\".\n        background (str, optional): The background color to use. Defaults to None.\n        eye_dome_lighting (bool, optional): Whether to use eye dome lighting. Defaults to False.\n\n    Raises:\n        FileNotFoundError: If the file does not exist.\n        ValueError: If the backend is not supported.\n    \"\"\"\n\n    import sys\n\n    if os.environ.get(\"USE_MKDOCS\") is not None:\n        return\n\n    if \"google.colab\" in sys.modules:\n        print(\"This function is not supported in Google Colab.\")\n        return\n\n    warnings.filterwarnings(\"ignore\")\n    filename = os.path.abspath(filename)\n    if not os.path.exists(filename):\n        raise FileNotFoundError(f\"{filename} does not exist.\")\n\n    backend = backend.lower()\n    if backend in [\"pyvista\", \"ipygany\", \"panel\"]:\n        try:\n            import pyntcloud\n        except ImportError:\n            print(\n                \"The pyvista and pyntcloud packages are required for this function. Use pip install leafmap[lidar] to install them.\"\n            )\n            return\n\n        try:\n            if backend == \"pyvista\":\n                backend = None\n            if backend == \"ipygany\":\n                cmap = None\n            data = pyntcloud.PyntCloud.from_file(filename)\n            mesh = data.to_instance(\"pyvista\", mesh=False)\n            mesh = mesh.elevation()\n            mesh.plot(\n                scalars=\"Elevation\",\n                cmap=cmap,\n                jupyter_backend=backend,\n                background=background,\n                eye_dome_lighting=eye_dome_lighting,\n                **kwargs,\n            )\n\n        except Exception as e:\n            print(\"Something went wrong.\")\n            print(e)\n            return\n\n    elif backend == \"open3d\":\n        try:\n            import laspy\n            import open3d as o3d\n            import numpy as np\n        except ImportError:\n            print(\n                \"The laspy and open3d packages are required for this function. Use pip install laspy open3d to install them.\"\n            )\n            return\n\n        try:\n            las = laspy.read(filename)\n            point_data = np.stack([las.X, las.Y, las.Z], axis=0).transpose((1, 0))\n            geom = o3d.geometry.PointCloud()\n            geom.points = o3d.utility.Vector3dVector(point_data)\n            # geom.colors =  o3d.utility.Vector3dVector(colors)  # need to add colors. A list in the form of [[r,g,b], [r,g,b]] with value range 0-1. https://github.com/isl-org/Open3D/issues/614\n            o3d.visualization.draw_geometries([geom], **kwargs)\n\n        except Exception as e:\n            print(\"Something went wrong.\")\n            print(e)\n            return\n\n    else:\n        raise ValueError(f\"{backend} is not a valid backend.\")\n</code></pre>"},{"location":"filling/#lidar.filling.write_dep_csv","title":"<code>write_dep_csv(dep_list, csv_file)</code>","text":"<p>Saves the depression list info to a CSV file.</p> <p>Parameters:</p> Name Type Description Default <code>dep_list</code> <code>list</code> <p>A list of depression objects with attributes.</p> required <code>csv_file</code> <code>str</code> <p>File path to the output CSV file.</p> required Source code in <code>lidar/filling.py</code> <pre><code>def write_dep_csv(dep_list, csv_file):\n    \"\"\"Saves the depression list info to a CSV file.\n\n    Args:\n        dep_list (list): A list of depression objects with attributes.\n        csv_file (str): File path to the output CSV file.\n    \"\"\"\n    csv = open(csv_file, \"w\")\n    header = (\n        \"region_id\"\n        + \",\"\n        + \"count\"\n        + \",\"\n        + \"area\"\n        + \",\"\n        + \"volume\"\n        + \",\"\n        + \"avg_depth\"\n        + \",\"\n        + \"max_depth\"\n        + \",\"\n        + \"min_elev\"\n        + \",\"\n        + \"max_elev\"\n        + \",\"\n        + \"perimeter\"\n        + \",\"\n        + \"major_axis\"\n        + \",\"\n        + \"minor_axis\"\n        + \",\"\n        + \"elongatedness\"\n        + \",\"\n        + \"eccentricity\"\n        + \",\"\n        + \"orientation\"\n        + \",\"\n        + \"area_bbox_ratio\"\n    )\n\n    csv.write(header + \"\\n\")\n    for dep in dep_list:\n        line = \"{},{},{:.2f},{:.2f},{:.2f},{:.2f},{:.2f},{:.2f}, {:.2f},{:.2f},{:.2f},{:.2f},{:.2f},{:.2f},{:.2f}\".format(\n            dep.id,\n            dep.count,\n            dep.size,\n            dep.volume,\n            dep.meanDepth,\n            dep.maxDepth,\n            dep.minElev,\n            dep.bndElev,\n            dep.perimeter,\n            dep.major_axis,\n            dep.minor_axis,\n            dep.elongatedness,\n            dep.eccentricity,\n            dep.orientation,\n            dep.area_bbox_ratio,\n        )\n        csv.write(line + \"\\n\")\n    csv.close()\n</code></pre>"},{"location":"filling/#lidar.filling.write_lidar","title":"<code>write_lidar(source, destination, do_compress=None, laz_backend=None)</code>","text":"<p>Writes to a stream or file.</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>str | LasBase</code> <p>The source data to be written.</p> required <code>destination</code> <code>str</code> <p>The destination filepath.</p> required <code>do_compress</code> <code>bool</code> <p>Flags to indicate if you want to compress the data. Defaults to None.</p> <code>None</code> <code>laz_backend</code> <code>str</code> <p>The laz backend to use. Defaults to None.</p> <code>None</code> Source code in <code>lidar/common.py</code> <pre><code>def write_lidar(source, destination, do_compress=None, laz_backend=None):\n    \"\"\"Writes to a stream or file.\n\n    Args:\n        source (str | laspy.lasdatas.base.LasBase): The source data to be written.\n        destination (str): The destination filepath.\n        do_compress (bool, optional): Flags to indicate if you want to compress the data. Defaults to None.\n        laz_backend (str, optional): The laz backend to use. Defaults to None.\n    \"\"\"\n\n    try:\n        import laspy\n    except ImportError:\n        print(\n            \"The laspy package is required for this function. Use `pip install laspy[lazrs,laszip]` to install it.\"\n        )\n        return\n\n    if isinstance(source, str):\n        source = read_lidar(source)\n\n    source.write(destination, do_compress=do_compress, laz_backend=laz_backend)\n</code></pre>"},{"location":"filtering/","title":"filtering module","text":"<p>Module for applying filters to image.</p>"},{"location":"filtering/#lidar.filtering.GaussianFilter","title":"<code>GaussianFilter(in_dem, sigma=1, out_file=None)</code>","text":"<p>Applies a Gaussian filter to an image.</p> <p>Parameters:</p> Name Type Description Default <code>in_dem</code> <code>str</code> <p>File path to the input image.</p> required <code>sigma</code> <code>int</code> <p>Standard deviation. Defaults to 1.</p> <code>1</code> <code>out_file</code> <code>str</code> <p>File path to the output image. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <p>np.array: The numpy array containing the filtered image.</p> Source code in <code>lidar/filtering.py</code> <pre><code>def GaussianFilter(in_dem, sigma=1, out_file=None):\n    \"\"\"Applies a Gaussian filter to an image.\n\n    Args:\n        in_dem (str): File path to the input image.\n        sigma (int, optional): Standard deviation. Defaults to 1.\n        out_file (str, optional): File path to the output image. Defaults to None.\n\n    Returns:\n        np.array: The numpy array containing the filtered image.\n    \"\"\"\n    print(\"Gaussian filtering ...\")\n    start_time = time.time()\n    dem = rd.LoadGDAL(in_dem)\n    no_data = dem.no_data\n    projection = dem.projection\n    geotransform = dem.geotransform\n\n    gau = ndimage.gaussian_filter(dem, sigma=sigma)\n    gau = np2rdarray(gau, no_data, projection, geotransform)\n    print(\"Run time: {:.4f} seconds\".format(time.time() - start_time))\n\n    if out_file is not None:\n        print(\"Saving dem ...\")\n        rd.SaveGDAL(out_file, gau)\n        return out_file\n\n    return gau\n</code></pre>"},{"location":"filtering/#lidar.filtering.MeanFilter","title":"<code>MeanFilter(in_dem, kernel_size=3, out_file=None)</code>","text":"<p>Applies a mean filter to an image.</p> <p>Parameters:</p> Name Type Description Default <code>in_dem</code> <code>str</code> <p>File path to the input image.</p> required <code>kernel_size</code> <code>int</code> <p>The size of the moving window. Defaults to 3.</p> <code>3</code> <code>out_file</code> <code>str</code> <p>File path to the output image. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <p>np.array: The numpy array containing the filtered image.</p> Source code in <code>lidar/filtering.py</code> <pre><code>def MeanFilter(in_dem, kernel_size=3, out_file=None):\n    \"\"\"Applies a mean filter to an image.\n\n    Args:\n        in_dem (str): File path to the input image.\n        kernel_size (int, optional): The size of the moving window. Defaults to 3.\n        out_file (str, optional): File path to the output image. Defaults to None.\n\n    Returns:\n        np.array: The numpy array containing the filtered image.\n    \"\"\"\n    print(\"Mean filtering ...\")\n    start_time = time.time()\n    dem = rd.LoadGDAL(in_dem)\n    no_data = dem.no_data\n    projection = dem.projection\n    geotransform = dem.geotransform\n\n    weights = np.full((kernel_size, kernel_size), 1.0 / (kernel_size * kernel_size))\n    mean = ndimage.filters.convolve(dem, weights)\n    mean = np2rdarray(mean, no_data, projection, geotransform)\n    print(\"Run time: {:.4f} seconds\".format(time.time() - start_time))\n\n    if out_file is not None:\n        print(\"Saving dem ...\")\n        rd.SaveGDAL(out_file, mean)\n        return out_file\n\n    return mean\n</code></pre>"},{"location":"filtering/#lidar.filtering.MedianFilter","title":"<code>MedianFilter(in_dem, kernel_size=3, out_file=None)</code>","text":"<p>Applies a median filter to an image.</p> <p>Parameters:</p> Name Type Description Default <code>in_dem</code> <code>str</code> <p>File path to the input image.</p> required <code>kernel_size</code> <code>int</code> <p>The size of the moving window. Defaults to 3.</p> <code>3</code> <code>out_file</code> <code>str</code> <p>File path to the output image. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <p>np.array: The numpy array containing the filtered image.</p> Source code in <code>lidar/filtering.py</code> <pre><code>def MedianFilter(in_dem, kernel_size=3, out_file=None):\n    \"\"\"Applies a median filter to an image.\n\n    Args:\n        in_dem (str): File path to the input image.\n        kernel_size (int, optional): The size of the moving window. Defaults to 3.\n        out_file (str, optional): File path to the output image. Defaults to None.\n\n    Returns:\n        np.array: The numpy array containing the filtered image.\n    \"\"\"\n    print(\"Median filtering ...\")\n    start_time = time.time()\n    dem = rd.LoadGDAL(in_dem)\n    no_data = dem.no_data\n    projection = dem.projection\n    geotransform = dem.geotransform\n\n    med = ndimage.median_filter(dem, size=kernel_size)\n    med = np2rdarray(med, no_data, projection, geotransform)\n    print(\"Run time: {:.4f} seconds\".format(time.time() - start_time))\n\n    if out_file is not None:\n        print(\"Saving dem ...\")\n        rd.SaveGDAL(out_file, med)\n        return out_file\n\n    return med\n</code></pre>"},{"location":"filtering/#lidar.filtering.np2rdarray","title":"<code>np2rdarray(in_array, no_data, projection, geotransform)</code>","text":"<p>Converts an numpy array to rdarray.</p> <p>Parameters:</p> Name Type Description Default <code>in_array</code> <code>array</code> <p>The input numpy array.</p> required <code>no_data</code> <code>float</code> <p>The no_data value of the array.</p> required <code>projection</code> <code>str</code> <p>The projection of the image.</p> required <code>geotransform</code> <code>str</code> <p>The geotransform of the image.</p> required <p>Returns:</p> Name Type Description <code>object</code> <p>The richDEM array.</p> Source code in <code>lidar/filtering.py</code> <pre><code>def np2rdarray(in_array, no_data, projection, geotransform):\n    \"\"\"Converts an numpy array to rdarray.\n\n    Args:\n        in_array (np.array): The input numpy array.\n        no_data (float): The no_data value of the array.\n        projection (str): The projection of the image.\n        geotransform (str): The geotransform of the image.\n\n    Returns:\n        object: The richDEM array.\n    \"\"\"\n    out_array = rd.rdarray(in_array, no_data=no_data)\n    out_array.projection = projection\n    out_array.geotransform = geotransform\n    return out_array\n</code></pre>"},{"location":"get-started/","title":"Get Started","text":"<p>Launch the interactive notebook tutorial for the lidar Python package with Google Colab now:</p> <p></p>"},{"location":"get-started/#a-quick-example","title":"A Quick Example","text":"<pre><code>import os\nimport pkg_resources\nfrom lidar import *\n\n# identify the sample data directory of the package\npackage_name = 'lidar'\ndata_dir = pkg_resources.resource_filename(package_name, 'data/')\n\n# use the sample dem. Change it to your own dem if needed\nin_dem = os.path.join(data_dir, 'dem.tif')\n# set the output directory\nout_dir = os.getcwd()\n\n# parameters for identifying sinks and delineating nested depressions\nmin_size = 1000      # minimum number of pixels as a depression\nmin_depth = 0.5      # minimum depth as a depression\ninterval = 0.3       # slicing interval for the level-set method\nbool_shp = True      # output shapefiles for each individual level\n\n# extracting sinks based on user-defined minimum depression size\nout_dem = os.path.join(out_dir, \"median.tif\")\nin_dem = MedianFilter(in_dem, kernel_size=3, out_file=out_dem)\nsink_path = ExtractSinks(in_dem, min_size, out_dir)\ndep_id_path, dep_level_path = DelineateDepressions(sink_path,\n                                                   min_size,\n                                                   min_depth,\n                                                   interval,\n                                                   out_dir,\n                                                   bool_shp)\nprint('Results are saved in: {}'.format(out_dir))\n</code></pre>"},{"location":"get-started/#lidar-gui","title":"lidar GUI","text":"<p>lidar also provides a Graphical User Interface (GUI), which can be invoked using the following Python script:</p> <pre><code>import lidar\nlidar.gui()\n</code></pre> <p></p>"},{"location":"get-started/#arcgis-toolbox","title":"ArcGIS Toolbox","text":""},{"location":"get-started/#toolbox-interface","title":"Toolbox interface","text":""},{"location":"get-started/#video-tutorials","title":"Video tutorials","text":"<p>Delineating nested surface depressions and catchments using ArcGIS Pro</p> <p></p> <p>Delineating nested surface depressions and catchments using ArcMap</p> <p></p>"},{"location":"installation/","title":"Installation","text":"<p>lidar supports a variety of platforms, including Microsoft Windows, macOS, and Linux operating systems. Note that you will need to have Python 3.x (&lt; 3.9) installed. Python 2.x is not supported. lidar is available on both PyPI and conda-forge. lidar has a GDAL dependency, which can be challenging to install using pip on Windows. Therefore, it is highly recommended to install lidar from the conda-forge channel. If you encounter any errors, please check the Dependencies section below.</p>"},{"location":"installation/#install-from-pypi","title":"Install from PyPI","text":"<p>To install lidar from PyPI, run this command in your terminal:</p> <pre><code>pip install lidar\n</code></pre>"},{"location":"installation/#install-from-conda-forage","title":"Install from conda-forage","text":"<p>If you have Anaconda or Miniconda installed on your computer, you can create a fresh conda environment to install lidar:</p> <pre><code>conda create -n geo python=3.11\nconda activate geo\nconda install -c conda-forge mamba\nmamba install -c conda-forge lidar\n</code></pre>"},{"location":"installation/#upgrade-lidar","title":"Upgrade lidar","text":"<p>If you have installed lidar before and want to upgrade to the latest version, you can run the following command in your terminal:</p> <pre><code>pip install -U lidar\n</code></pre> <p>If you use conda, you can update lidar to the latest version by running the following command in your terminal:</p> <pre><code>mamba update lidar -c conda-forge\n</code></pre> <p>To install the development version from GitHub directly using Git, run the following code:</p> <pre><code>pip install git+https://github.com/opengeos/lidar\n</code></pre>"},{"location":"installation/#dependencies","title":"Dependencies","text":"<p>lidar's Python dependencies are listed in its requirements.txt file. In addition, lidar has a C library dependency: GDAL &gt;=1.11.2. How to install GDAL in different operating systems will be explained below. More information about GDAL can be found here.</p>"},{"location":"installation/#linux","title":"Linux","text":""},{"location":"installation/#debian-based-linux","title":"Debian-based Linux","text":"<p>The following commands can be used to install GDAL for Debian-based Linux distributions (e.g., Ubuntu, Linux Mint).</p> <pre><code>sudo add-apt-repository ppa:ubuntugis/ppa\nsudo apt-get update\nsudo apt-get install gdal-bin libgdal-dev\n</code></pre> <p>If you encounter any compiling errors, try the following commands.</p> <pre><code>sudo apt-get install --reinstall build-essential\nsudo apt-get install python3-dev\npip install wheel\n</code></pre>"},{"location":"installation/#pacman-based-linux","title":"Pacman-based Linux","text":"<p>The following commands can be used to install GDAL for Pacman-based Linux distributions (e.g., Arch Linux, Manjaro). You might need to use sudo if you encounter permission errors.</p> <pre><code>sudo pacman -S yaourt --noconfirm\nyaourt -S gdal --noconfirm\nyaourt -S python-gdal --noconfirm\n</code></pre>"},{"location":"installation/#macos","title":"macOS","text":"<p>For a Homebrew based Python environment, do the following.</p> <pre><code>brew update\nbrew install gdal\n</code></pre> <p>Alternatively, you can install GDAL binaries from kyngchaos. You will then need to add the installed location <code>/Library/Frameworks/GDAL.framework/Programs</code> to your system path.</p>"},{"location":"installation/#windows","title":"Windows","text":"<p>The instruction below assumes that you have installed Anaconda. Open Anaconda Prompt and enter the following commands to create a conda environment and install required packages</p> <pre><code>conda create -n geo python=3.11\nconda activate geo\nconda install -c conda-forge mamba\nmamba install -c conda-forge lidar\n</code></pre> <p>When installing the lidar package, if you encounter an error saying <code>Microsoft Visual C++ 14.0 is required</code>, please follow the steps below to fix the error and reinstall lidar. More information can be found at this link Fix Python 3 on Windows error - Microsoft Visual C++ 14.0 is required.</p> <ul> <li>Download Microsoft Build Tools for Visual Studio 2017</li> <li>Double click to install the downloaded installer - Microsoft Build Tools for Visual Studio 2017.</li> <li>Open Microsoft Build Tools for Visual Studio 2017</li> <li>Select Workloads --&gt; Visual C++ build tools and click the install button</li> </ul>"},{"location":"mounts/","title":"mounts module","text":"<p>Module for delineating the nested hierarchy of elevated features (i.e., mounts).</p>"},{"location":"mounts/#lidar.mounts.DelineateMounts","title":"<code>DelineateMounts(in_dem, min_size, min_height, interval, out_dir, bool_shp=False)</code>","text":"<p>Delineates the nested hierarchy of elevated features (i.e., mounts).</p> <p>Parameters:</p> Name Type Description Default <code>in_dem</code> <code>str</code> <p>File path to the input DEM.</p> required <code>min_size</code> <code>int</code> <p>The minimum number of pixels to be considered as an object.</p> required <code>min_height</code> <code>float</code> <p>The minimum depth of the feature to be considered as an object.</p> required <code>interval</code> <code>float</code> <p>The slicing interval.</p> required <code>out_dir</code> <code>str</code> <p>The output directory.</p> required <code>bool_shp</code> <code>bool</code> <p>Whether to generate shapefiles. Defaults to False.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>tuple</code> <p>File paths to the depression ID and level.</p> Source code in <code>lidar/mounts.py</code> <pre><code>def DelineateMounts(in_dem, min_size, min_height, interval, out_dir, bool_shp=False):\n    \"\"\"Delineates the nested hierarchy of elevated features (i.e., mounts).\n\n    Args:\n        in_dem (str): File path to the input DEM.\n        min_size (int): The minimum number of pixels to be considered as an object.\n        min_height (float): The minimum depth of the feature to be considered as an object.\n        interval (float): The slicing interval.\n        out_dir (str): The output directory.\n        bool_shp (bool, optional): Whether to generate shapefiles. Defaults to False.\n\n    Returns:\n        tuple: File paths to the depression ID and level.\n    \"\"\"\n    if not os.path.exists(out_dir):\n        os.mkdir(out_dir)\n\n    print(\"Loading data ...\")\n    dem = rd.LoadGDAL(in_dem)\n    # projection = dem.projection\n    geotransform = dem.geotransform\n    cell_size = np.round(geotransform[1], decimals=3)\n\n    out_dem = os.path.join(out_dir, \"dem_flip.tif\")\n    in_dem = FlipDEM(dem, delta=100, out_file=out_dem)\n\n    min_elev, max_elev, no_data = get_min_max_nodata(dem)\n    print(\n        \"min = {:.2f}, max = {:.2f}, no_data = {}, cell_size = {}\".format(\n            min_elev, max_elev, no_data, cell_size\n        )\n    )\n\n    sink_path = ExtractSinks(in_dem, min_size, out_dir)\n    dep_id_path, dep_level_path = DelineateDepressions(\n        sink_path, min_size, min_height, interval, out_dir, bool_shp\n    )\n\n    return dep_id_path, dep_level_path\n</code></pre>"},{"location":"mounts/#lidar.mounts.FlipDEM","title":"<code>FlipDEM(dem, delta=100, out_file=None)</code>","text":"<p>Flips the DEM.</p> <p>Parameters:</p> Name Type Description Default <code>dem</code> <code>array</code> <p>The numpy array containing the image.</p> required <code>delta</code> <code>int</code> <p>The base value to be added to the flipped DEM. Defaults to 100.</p> <code>100</code> <code>out_file</code> <code>str</code> <p>File path to the output image. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <p>np.array: The numpy array containing the flipped DEM.</p> Source code in <code>lidar/mounts.py</code> <pre><code>def FlipDEM(dem, delta=100, out_file=None):\n    \"\"\"Flips the DEM.\n\n    Args:\n        dem (np.array): The numpy array containing the image.\n        delta (int, optional): The base value to be added to the flipped DEM. Defaults to 100.\n        out_file (str, optional): File path to the output image. Defaults to None.\n\n    Returns:\n        np.array: The numpy array containing the flipped DEM.\n    \"\"\"\n    # get min and max elevation of the dem\n    no_data = dem.no_data\n    max_elev = float(np.max(dem[dem != no_data]))\n    # min_elev = float(np.min(dem[dem != no_data]))\n\n    dem = dem * (-1) + max_elev + delta\n    dem[dem == no_data * (-1)] = no_data\n\n    if out_file is not None:\n        print(\"Saving flipped dem ...\")\n        rd.SaveGDAL(out_file, dem)\n        return out_file\n\n    return dem\n</code></pre>"},{"location":"mounts/#lidar.mounts.get_min_max_nodata","title":"<code>get_min_max_nodata(dem)</code>","text":"<p>Gets the minimum, maximum, and no_data value of a numpy array.</p> <p>Parameters:</p> Name Type Description Default <code>dem</code> <code>array</code> <p>The numpy array containing the image.</p> required <p>Returns:</p> Name Type Description <code>tuple</code> <p>The minimum, maximum, and no_data value.</p> Source code in <code>lidar/mounts.py</code> <pre><code>def get_min_max_nodata(dem):\n    \"\"\"Gets the minimum, maximum, and no_data value of a numpy array.\n\n    Args:\n        dem (np.array): The numpy array containing the image.\n\n    Returns:\n        tuple: The minimum, maximum, and no_data value.\n    \"\"\"\n    no_data = dem.no_data\n    max_elev = float(np.max(dem[dem != no_data]))\n    min_elev = float(np.min(dem[dem != no_data]))\n\n    return min_elev, max_elev, no_data\n</code></pre>"},{"location":"slicing/","title":"slicing module","text":"<p>Module for the level-set algorithm.</p>"},{"location":"slicing/#lidar.slicing.Depression","title":"<code>Depression</code>","text":"<p>The class for storing depression info.</p> Source code in <code>lidar/slicing.py</code> <pre><code>class Depression:\n    \"\"\"The class for storing depression info.\"\"\"\n\n    def __init__(\n        self,\n        id,\n        level,\n        count,\n        size,\n        volume,\n        meanDepth,\n        maxDepth,\n        minElev,\n        bndElev,\n        inNbrId,\n        regionId,\n        perimeter,\n        major_axis,\n        minor_axis,\n        elongatedness,\n        eccentricity,\n        orientation,\n        area_bbox_ratio,\n    ):\n        self.id = id\n        self.level = level\n        self.count = count\n        self.size = size\n        self.volume = volume\n        self.meanDepth = meanDepth\n        self.maxDepth = maxDepth\n        self.minElev = minElev\n        self.bndElev = bndElev\n        self.inNbrId = inNbrId\n        self.regionId = regionId\n        self.perimeter = perimeter\n        self.major_axis = major_axis\n        self.minor_axis = minor_axis\n        self.elongatedness = elongatedness\n        self.eccentricity = eccentricity\n        self.orientation = orientation\n        self.area_bbox_ratio = area_bbox_ratio\n</code></pre>"},{"location":"slicing/#lidar.slicing.DelineateDepressions","title":"<code>DelineateDepressions(in_sink, min_size, min_depth, interval, out_dir, bool_level_shp=False)</code>","text":"<p>Delineates nested depressions.</p> <p>Parameters:</p> Name Type Description Default <code>in_sink</code> <code>str</code> <p>The file path to the sink image.</p> required <code>min_size</code> <code>int</code> <p>The minimum number of pixels to be considered as a depression.</p> required <code>min_depth</code> <code>float</code> <p>The minimum depth to be considered as a depression.</p> required <code>interval</code> <code>float</code> <p>The slicing interval.</p> required <code>out_dir</code> <code>str</code> <p>The file path to the output directory.</p> required <code>bool_level_shp</code> <code>bool</code> <p>Whether to generate shapefiles for each individual level. Defaults to False.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>tuple</code> <p>The output level image, and the output object image.</p> Source code in <code>lidar/slicing.py</code> <pre><code>def DelineateDepressions(\n    in_sink, min_size, min_depth, interval, out_dir, bool_level_shp=False\n):\n    \"\"\"Delineates nested depressions.\n\n    Args:\n        in_sink (str): The file path to the sink image.\n        min_size (int): The minimum number of pixels to be considered as a depression.\n        min_depth (float): The minimum depth to be considered as a depression.\n        interval (float): The slicing interval.\n        out_dir (str): The file path to the output directory.\n        bool_level_shp (bool, optional): Whether to generate shapefiles for each individual level. Defaults to False.\n\n    Returns:\n        tuple: The output level image, and the output object image.\n    \"\"\"\n    # The following parameters can be used by default\n    interval = interval * (-1)  # convert slicing interval to negative value\n\n    out_img_dir = os.path.join(out_dir, \"img-level\")\n    out_shp_dir = os.path.join(out_dir, \"shp-level\")\n    out_obj_file = os.path.join(out_dir, \"depression_id.tif\")\n    out_level_file = os.path.join(out_dir, \"depression_level.tif\")\n    out_vec_file = os.path.join(out_dir, \"depressions.shp\")\n    out_csv_file = os.path.join(out_dir, \"depressions_info.csv\")\n\n    init_time = time.time()\n\n    # delete contents in output folder if existing\n    if not os.path.exists(out_dir):\n        os.mkdir(out_dir)\n    if os.path.exists(out_img_dir):\n        shutil.rmtree(out_img_dir)\n    os.mkdir(out_img_dir)\n    if os.path.exists(out_shp_dir):\n        shutil.rmtree(out_shp_dir)\n    os.mkdir(out_shp_dir)\n\n    print(\"Reading data ...\")\n    read_time = time.time()\n\n    image = rd.LoadGDAL(in_sink)\n    no_data_raw, projection, geotransform, resolution = getMetadata(image)\n    rows_cols = image.shape\n    print(\"rows, cols: \" + str(rows_cols))\n    print(\"Pixel resolution: \" + str(resolution))\n    print(\"Read data time: {:.4f} seconds\".format(time.time() - read_time))\n\n    min_elev, max_elev, no_data = get_min_max_nodata(\n        image\n    )  # set nodata value to a large value, e.g., 9999\n    # initialize output image\n    obj_image = np.zeros(\n        image.shape\n    )  # output depression image with unique id for each nested depression\n    level_image = np.zeros(image.shape)  # output depression level image\n\n    # nb_labels is the total number of objects. 0 represents background object.\n    label_objects, nb_labels = regionGroup(image, min_size, no_data)\n    # regions = measure.regionprops(label_objects, image, coordinates='xy')\n    regions = measure.regionprops(label_objects, image)\n    del image  # delete the original image to save memory\n    prep_time = time.time()\n    print(\"Data preparation time: {:.4f} seconds\".format(prep_time - init_time))\n    print(\"Total number of regions: {}\".format(nb_labels))\n\n    identify_time = time.time()\n\n    obj_uid = 0\n    global_dep_list = []\n\n    # loop through regions and identify nested depressions in each region using level-set method\n    for region in regions:  # iterate through each depression region\n        region_id = region.label\n        img = region.intensity_image  # dem subset for each region\n        bbox = region.bbox\n\n        # save all input parameters needed for level set methods as a dict\n        image_paras = set_image_paras(\n            no_data, min_size, min_depth, interval, resolution\n        )\n\n        # execute level set methods\n        out_obj, dep_list = levelSet(img, region_id, obj_uid, image_paras)\n\n        for dep in dep_list:\n            global_dep_list.append(dep)\n\n        obj_uid += len(dep_list)\n\n        level_obj = obj_to_level(out_obj, global_dep_list)\n        obj_image = writeObject(obj_image, out_obj, bbox)  # write region to whole image\n        level_image = writeObject(level_image, level_obj, bbox)\n\n        del out_obj, level_obj, region\n\n    del regions, label_objects\n\n    print(\"=========== Run time statistics =========== \")\n    print(\"(rows, cols):\\t\\t\\t {0}\".format(str(rows_cols)))\n    print(\"Pixel resolution:\\t\\t {0} m\".format(str(resolution)))\n    print(\"Number of regions:\\t\\t {0}\".format(str(nb_labels)))\n    print(\"Data preparation time:\\t\\t {:.4f} s\".format(prep_time - init_time))\n    print(\"Identify level time:\\t\\t {:.4f} s\".format(time.time() - identify_time))\n\n    write_time = time.time()\n    # writeRaster(obj_image, out_obj_file, in_sink)\n    # writeRaster(level_image, out_level_file, in_sink)\n    # SaveGDAL function can only save data as floating point\n    level_image = np2rdarray(\n        np.int32(level_image), no_data_raw, projection, geotransform\n    )\n    rd.SaveGDAL(out_level_file, level_image)\n    obj_image = np2rdarray(np.int32(obj_image), no_data_raw, projection, geotransform)\n    rd.SaveGDAL(out_obj_file, obj_image)\n    print(\"Write image time:\\t\\t {:.4f} s\".format(time.time() - write_time))\n\n    # converting object image to polygon\n    level_time = time.time()\n    polygonize(out_obj_file, out_vec_file)\n    write_dep_csv(global_dep_list, out_csv_file)\n    print(\"Polygonize time:\\t\\t {:.4f} s\".format(time.time() - level_time))\n\n    # extracting polygons for each individual level\n    if bool_level_shp:\n        level_time = time.time()\n        extract_levels(\n            level_image,\n            obj_image,\n            min_size,\n            no_data,\n            out_img_dir,\n            out_shp_dir,\n            in_sink,\n            False,\n        )\n        print(\"Extract level time:\\t\\t {:.4f} s\".format(time.time() - level_time))\n        shutil.rmtree(out_img_dir)\n    else:\n        shutil.rmtree(out_shp_dir)\n        shutil.rmtree(out_img_dir)\n    del level_image\n    del obj_image\n\n    end_time = time.time()\n    print(\"Total run time:\\t\\t\\t {:.4f} s\".format(end_time - init_time))\n    return out_obj_file, out_level_file\n</code></pre>"},{"location":"slicing/#lidar.slicing.extract_levels","title":"<code>extract_levels(level_img, obj_img, min_size, no_data, out_img_dir, out_shp_dir, template, bool_comb=False)</code>","text":"<p>Extracts individual level image.</p> <p>Parameters:</p> Name Type Description Default <code>level_img</code> <code>array</code> <p>The numpy array containing the level image.</p> required <code>obj_img</code> <code>array</code> <p>The numpy array containing the object image.</p> required <code>min_size</code> <code>int</code> <p>The minimum number of pixels to be considered as a depression.</p> required <code>no_data</code> <code>float</code> <p>The no_data value of the image.</p> required <code>out_img_dir</code> <code>str</code> <p>The output image directory.</p> required <code>out_shp_dir</code> <code>str</code> <p>The output shapefile directory.</p> required <code>template</code> <code>str</code> <p>The file path to the template image.</p> required <code>bool_comb</code> <code>bool</code> <p>Whether to extract combined level image. Defaults to False.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>tuple</code> <p>The single level image, properties of region grouped level image, properties of region grouped object image.</p> Source code in <code>lidar/slicing.py</code> <pre><code>def extract_levels(\n    level_img,\n    obj_img,\n    min_size,\n    no_data,\n    out_img_dir,\n    out_shp_dir,\n    template,\n    bool_comb=False,\n):\n    \"\"\"Extracts individual level image.\n\n    Args:\n        level_img (np.array): The numpy array containing the level image.\n        obj_img (np.array): The numpy array containing the object image.\n        min_size (int): The minimum number of pixels to be considered as a depression.\n        no_data (float): The no_data value of the image.\n        out_img_dir (str): The output image directory.\n        out_shp_dir (str): The output shapefile directory.\n        template (str): The file path to the template image.\n        bool_comb (bool, optional): Whether to extract combined level image. Defaults to False.\n\n    Returns:\n        tuple: The single level image, properties of region grouped level image, properties of region grouped object image.\n    \"\"\"\n    max_level = int(np.max(level_img))\n    combined_images = []\n    single_images = []\n    img = np.copy(level_img)\n\n    digits = (\n        int(math.log10(max_level)) + 1\n    )  # determine the level number of output file name\n    for i in range(1, max_level + 1):\n        img[(img &gt; 0) &amp; (img &lt;= i)] = i\n        tmp_img = np.copy(img)\n        tmp_img[tmp_img &gt; i] = 0\n        if bool_comb == True:  # whether to extract combined level image\n            combined_images.append(np.copy(tmp_img))\n            filename_combined = \"Combined_level_\" + str(i).zfill(digits) + \".tif\"\n            out_file = os.path.join(out_shp_dir, filename_combined)\n            writeRaster(tmp_img, out_file, template)\n\n        lbl_objects, n_labels = regionGroup(tmp_img, min_size, no_data)\n        # regs = measure.regionprops(lbl_objects, level_img, coordinates='xy')\n        regs = measure.regionprops(lbl_objects, level_img)\n        # regs2 = measure.regionprops(lbl_objects, obj_img, coordinates='xy')\n        regs2 = measure.regionprops(lbl_objects, obj_img)\n\n        sin_img = np.zeros(img.shape)\n\n        for index, reg in enumerate(regs):\n            uid = regs2[index].min_intensity\n            if reg.max_intensity &gt;= i:\n                bbox = reg.bbox\n                tmp_img = np.zeros(reg.image.shape)\n                tmp_img[reg.image] = uid\n                writeObject(sin_img, tmp_img, bbox)\n\n        # for reg in regs:\n        #     if reg.max_intensity &gt;= i:\n        #         bbox = reg.bbox\n        #         tmp_img = np.zeros(reg.image.shape)\n        #         tmp_img[reg.image] = i\n        #         writeObject(sin_img, tmp_img, bbox)\n        del tmp_img\n        # single_images.append(np.copy(sin_img))\n        filename_single = \"Single_level_\" + str(i).zfill(digits) + \".shp\"\n        out_shp_file = os.path.join(out_shp_dir, filename_single)\n\n        out_img_file = os.path.join(out_img_dir, \"tmp.tif\")\n        writeRaster(sin_img, out_img_file, template)\n        polygonize(out_img_file, out_shp_file)\n        # writeRaster(sin_img,out_file,template)\n        del sin_img, regs, regs2\n\n    del img\n    return True\n</code></pre>"},{"location":"slicing/#lidar.slicing.getMetadata","title":"<code>getMetadata(img)</code>","text":"<p>Gets rdarray metadata.</p> <p>Parameters:</p> Name Type Description Default <code>img</code> <code>rdarray</code> <p>The richDEM array containing the image.</p> required <p>Returns:</p> Name Type Description <code>tuple</code> <p>no_data, projection, geotransform, cell_size</p> Source code in <code>lidar/slicing.py</code> <pre><code>def getMetadata(img):\n    \"\"\"Gets rdarray metadata.\n\n    Args:\n        img (rdarray): The richDEM array containing the image.\n\n    Returns:\n        tuple: no_data, projection, geotransform, cell_size\n    \"\"\"\n    no_data = img.no_data\n    projection = img.projection\n    geotransform = img.geotransform\n    cell_size = np.round(geotransform[1], decimals=2)\n    return no_data, projection, geotransform, cell_size\n</code></pre>"},{"location":"slicing/#lidar.slicing.get_image_paras","title":"<code>get_image_paras(image_paras)</code>","text":"<p>Gets image parameters.</p> <p>Parameters:</p> Name Type Description Default <code>image_paras</code> <code>dict</code> <p>The dictionary containing image parameters.</p> required <p>Returns:</p> Name Type Description <code>tuple</code> <p>A tuple containing no_data, min_size, min_depth, interval, resolution.</p> Source code in <code>lidar/slicing.py</code> <pre><code>def get_image_paras(image_paras):\n    \"\"\"Gets image parameters.\n\n    Args:\n        image_paras (dict): The dictionary containing image parameters.\n\n    Returns:\n        tuple: A tuple containing no_data, min_size, min_depth, interval, resolution.\n    \"\"\"\n    no_data = image_paras[\"no_data\"]\n    min_size = image_paras[\"min_size\"]\n    min_depth = image_paras[\"min_depth\"]\n    interval = image_paras[\"interval\"]\n    resolution = image_paras[\"resolution\"]\n    return no_data, min_size, min_depth, interval, resolution\n</code></pre>"},{"location":"slicing/#lidar.slicing.get_min_max_nodata","title":"<code>get_min_max_nodata(image)</code>","text":"<p>Gets the minimum, maximum, and no_data value of a numpy array.</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>array</code> <p>The numpy array containing the image.</p> required <p>Returns:</p> Name Type Description <code>tuple</code> <p>The minimum, maximum, and no_data value.</p> Source code in <code>lidar/slicing.py</code> <pre><code>def get_min_max_nodata(image):\n    \"\"\"Gets the minimum, maximum, and no_data value of a numpy array.\n\n    Args:\n        image (np.array): The numpy array containing the image.\n\n    Returns:\n        tuple: The minimum, maximum, and no_data value.\n    \"\"\"\n    max_elev = np.max(image)\n    nodata = (\n        pow(10, math.floor(math.log10(np.max(image))) + 2) - 1\n    )  # assign no data value\n    image[image &lt;= 0] = nodata  # change no data value\n    min_elev = np.min(image)\n    return min_elev, max_elev, nodata\n</code></pre>"},{"location":"slicing/#lidar.slicing.img_to_shp","title":"<code>img_to_shp(in_img_dir, out_shp_dir)</code>","text":"<p>Converts images in a selected folder to shapefiles</p> <p>Parameters:</p> Name Type Description Default <code>in_img_dir</code> <code>str</code> <p>The input iimage directory.</p> required <code>out_shp_dir</code> <code>str</code> <p>The output shapefile directory.</p> required Source code in <code>lidar/slicing.py</code> <pre><code>def img_to_shp(in_img_dir, out_shp_dir):\n    \"\"\"Converts images in a selected folder to shapefiles\n\n    Args:\n        in_img_dir (str): The input iimage directory.\n        out_shp_dir (str): The output shapefile directory.\n    \"\"\"\n    img_files = os.listdir(in_img_dir)\n    for img_file in img_files:\n        if img_file.endswith(\".tif\"):\n            img_filename = os.path.join(in_img_dir, img_file)\n            shp_filename = os.path.join(out_shp_dir, img_file.replace(\"tif\", \"shp\"))\n            polygonize(img_filename, shp_filename)\n</code></pre>"},{"location":"slicing/#lidar.slicing.levelSet","title":"<code>levelSet(img, region_id, obj_uid, image_paras)</code>","text":"<p>Identifies nested depressions using level-set method.</p> <p>Parameters:</p> Name Type Description Default <code>img</code> <code>array</code> <p>The numpy array containing the image.</p> required <code>region_id</code> <code>int</code> <p>The unique id of the region.</p> required <code>obj_uid</code> <code>int</code> <p>The object id of the region.</p> required <code>image_paras</code> <code>dict</code> <p>The dictionary containing image parameters.</p> required <p>Returns:</p> Name Type Description <code>tuple</code> <p>(level image, depression list)</p> Source code in <code>lidar/slicing.py</code> <pre><code>def levelSet(img, region_id, obj_uid, image_paras):\n    \"\"\"Identifies nested depressions using level-set method.\n\n    Args:\n        img (np.array): The numpy array containing the image.\n        region_id (int): The unique id of the region.\n        obj_uid (int): The object id of the region.\n        image_paras (dict): The dictionary containing image parameters.\n\n    Returns:\n        tuple: (level image, depression list)\n    \"\"\"\n    # unzip input parameters from dict\n    no_data, min_size, min_depth, interval, resolution = get_image_paras(image_paras)\n\n    level_img = np.zeros(img.shape)  # init output level image\n    # flood_img = np.zeros(img.shape)     # init output flood time image\n\n    max_elev = np.max(img[img != no_data])\n    img[img == 0] = no_data\n    min_elev = np.min(img)\n\n    print(\"Processing Region # {} ...\".format(region_id))\n    # print(\"=========================================================================== Region: {}\".format(region_id))\n    unique_id = obj_uid\n    parent_ids = {}  # store current parent depressions\n    nbr_ids = {}  # store the inner-neighbor ids of current parent depressions\n    dep_list = []  # list for storing depressions\n    (rows, cols) = img.shape\n    if rows == 1 or cols == 1:  # if the depression is a horizontal or vertical line\n        cells = rows * cols\n        size = cells * pow(resolution, 2)  # depression size\n        max_depth = max_elev - min_elev\n        mean_depth = (max_elev * cells - np.sum(img)) / cells\n        volume = mean_depth * cells * pow(resolution, 2)\n        unique_id += 1\n        level = 1\n        perimeter = cells * resolution\n        major_axis = cells * resolution\n        minor_axis = resolution\n        area_bbox_ratio = 1\n        if rows == 1:\n            elongatedness = cols\n            eccentricity = 1\n            orientation = 0\n        else:\n            elongatedness = rows\n            eccentricity = 1\n            orientation = 90\n\n        dep_list.append(\n            Depression(\n                unique_id,\n                level,\n                cells,\n                size,\n                volume,\n                mean_depth,\n                max_depth,\n                min_elev,\n                max_elev,\n                [],\n                region_id,\n                perimeter,\n                major_axis,\n                minor_axis,\n                elongatedness,\n                eccentricity,\n                orientation,\n                area_bbox_ratio,\n            )\n        )\n        level_img = np.ones(img.shape)\n        del img\n        return level_img, dep_list\n\n    for elev in np.arange(\n        max_elev, min_elev, interval\n    ):  # slicing operation using top-down approach\n        img[img &gt; elev] = 0  # set elevation higher than xy-plane to zero\n        label_objects, nb_labels = regionGroup(img, min_size, no_data)\n        # print('slicing elev = {:.2f}, number of objects = {}'.format(elev, nb_labels))\n        if nb_labels == 0:  # if slicing results in no objects, quit\n            break\n\n        # objects = measure.regionprops(label_objects, img, coordinates='xy')\n        objects = measure.regionprops(label_objects, img)\n        for i, object in enumerate(objects):\n            (row, col) = object.coords[0]  # get a boundary cell\n            bbox = object.bbox\n\n            if len(parent_ids) == 0:  # This is the first depression, maximum depression\n                # print(\"This is the maximum depression extent.\")\n                cells = object.area\n                size = cells * pow(resolution, 2)  # depression size\n                max_depth = (\n                    object.max_intensity - object.min_intensity\n                )  # depression max depth\n                mean_depth = (\n                    object.max_intensity * cells - np.sum(object.intensity_image)\n                ) / cells  # depression mean depth\n                volume = mean_depth * cells * pow(resolution, 2)  # depression volume\n                # spill_elev = object.max_intensity   # to be implemented\n                min_elev = object.min_intensity  # depression min elevation\n                max_elev = object.max_intensity  # depression max elevation\n                # print(\"size = {}, max depth = {:.2f}, mean depth = {:.2f}, volume = {:.2f}, spill elev = {:.2f}\".format(\n                #     size, max_depth, mean_depth, volume, spill_elev))\n                unique_id += 1\n                level = 1\n                perimeter = object.perimeter * resolution\n                major_axis = object.major_axis_length * resolution\n                minor_axis = object.minor_axis_length * resolution\n                if minor_axis == 0:\n                    minor_axis = resolution\n                elongatedness = major_axis * 1.0 / minor_axis\n                eccentricity = object.eccentricity\n                orientation = object.orientation / 3.1415 * 180\n                area_bbox_ratio = object.extent\n                dep_list.append(\n                    Depression(\n                        unique_id,\n                        level,\n                        cells,\n                        size,\n                        volume,\n                        mean_depth,\n                        max_depth,\n                        min_elev,\n                        max_elev,\n                        [],\n                        region_id,\n                        perimeter,\n                        major_axis,\n                        minor_axis,\n                        elongatedness,\n                        eccentricity,\n                        orientation,\n                        area_bbox_ratio,\n                    )\n                )\n                parent_ids[unique_id] = 0  # number of inner neighbors\n                nbr_ids[unique_id] = []  # ids of inner neighbors\n                tmp_img = np.zeros(object.image.shape)\n                tmp_img[object.image] = unique_id\n                writeObject(\n                    level_img, tmp_img, bbox\n                )  # write the object to the final image\n\n            else:  # identify inner neighbors of parent depressions\n                # print(\"current id: {}\".format(parent_ids.keys()))\n                # (row, col) = object.coords[0]\n                parent_id = level_img[row, col]\n                parent_ids[parent_id] += 1\n                nbr_ids[parent_id].append(i)\n\n        for (\n            key\n        ) in (\n            parent_ids.copy()\n        ):  # check how many inner neighbors each upper level depression has\n            if parent_ids[key] &gt; 1:  # if the parent has two or more children\n                # print(\"Object id: {} has split into {} objects\".format(key, parent_ids[key]))\n                new_parent_keys = nbr_ids[key]\n                for new_key in new_parent_keys:\n                    object = objects[new_key]\n                    cells = object.area\n                    size = cells * pow(resolution, 2)\n                    max_depth = object.max_intensity - object.min_intensity\n                    mean_depth = (\n                        object.max_intensity * cells - np.sum(object.intensity_image)\n                    ) / cells\n                    volume = mean_depth * cells * pow(resolution, 2)\n                    spill_elev = object.max_intensity\n                    min_elev = object.min_intensity\n                    max_elev = object.max_intensity\n                    # print(\"  --  size = {}, max depth = {:.2f}, mean depth = {:.2f}, volume = {:.2f}, spill elev = {:.2f}\".format(\n                    #         size, max_depth, mean_depth, volume, spill_elev))\n                    unique_id += 1\n                    level = 1\n                    perimeter = object.perimeter * resolution\n                    major_axis = object.major_axis_length * resolution\n                    minor_axis = object.minor_axis_length * resolution\n                    if minor_axis == 0:\n                        minor_axis = resolution\n                    elongatedness = major_axis * 1.0 / minor_axis\n                    eccentricity = object.eccentricity\n                    orientation = object.orientation / 3.1415 * 180\n                    area_bbox_ratio = object.extent\n                    dep_list.append(\n                        Depression(\n                            unique_id,\n                            level,\n                            cells,\n                            size,\n                            volume,\n                            mean_depth,\n                            max_depth,\n                            min_elev,\n                            max_elev,\n                            [],\n                            region_id,\n                            perimeter,\n                            major_axis,\n                            minor_axis,\n                            elongatedness,\n                            eccentricity,\n                            orientation,\n                            area_bbox_ratio,\n                        )\n                    )\n                    dep_list[key - 1 - obj_uid].inNbrId.append(unique_id)\n                    parent_ids[unique_id] = 0\n                    nbr_ids[unique_id] = []\n                    bbox = object.bbox\n                    tmp_img = np.zeros(object.image.shape)\n                    tmp_img[object.image] = unique_id\n                    writeObject(level_img, tmp_img, bbox)\n\n                if key in parent_ids.keys():  # remove parent id that has split\n                    parent_ids.pop(key)\n            else:\n                parent_ids[key] = 0  # if a parent depression has not split, keep it\n                nbr_ids[key] = []\n\n    # for dep in dep_list:\n    #     print(\"id: {} has children {}\".format(dep.id, dep.inNbrId))\n    dep_list = updateLevel(\n        dep_list, obj_uid\n    )  # update the inner neighbors of each depression\n    # for dep in dep_list:\n    #     print(\"id: {} is level {}\".format(dep.id, dep.level))\n    del img\n\n    return level_img, dep_list\n</code></pre>"},{"location":"slicing/#lidar.slicing.np2rdarray","title":"<code>np2rdarray(in_array, no_data, projection, geotransform)</code>","text":"<p>Converts numpy array to rdarray.</p> <p>Parameters:</p> Name Type Description Default <code>in_array</code> <code>array</code> <p>The input numpy array containing the image.</p> required <code>no_data</code> <code>float</code> <p>The no_data value of the image.</p> required <code>projection</code> <code>str</code> <p>The projection coordinate system of the image.</p> required <code>geotransform</code> <code>str</code> <p>The geotransform of the image.</p> required <p>Returns:</p> Name Type Description <code>rdarray</code> <p>The richDEM array containing the image.</p> Source code in <code>lidar/slicing.py</code> <pre><code>def np2rdarray(in_array, no_data, projection, geotransform):\n    \"\"\"Converts numpy array to rdarray.\n\n    Args:\n        in_array (np.array): The input numpy array containing the image.\n        no_data (float): The no_data value of the image.\n        projection (str): The projection coordinate system of the image.\n        geotransform (str): The geotransform of the image.\n\n    Returns:\n        rdarray: The richDEM array containing the image.\n    \"\"\"\n    out_array = rd.rdarray(in_array, no_data=no_data)\n    out_array.projection = projection\n    out_array.geotransform = geotransform\n    return out_array\n</code></pre>"},{"location":"slicing/#lidar.slicing.obj_to_level","title":"<code>obj_to_level(obj_img, dep_list)</code>","text":"<p>Derives depression level image based on the depression id image and depression list.</p> <p>Parameters:</p> Name Type Description Default <code>obj_img</code> <code>array</code> <p>The numpy array containing the object image.</p> required <code>dep_list</code> <code>list</code> <p>A list containing depression info.</p> required <p>Returns:</p> Type Description <p>np.array: The numpy array containing the object level image.</p> Source code in <code>lidar/slicing.py</code> <pre><code>def obj_to_level(obj_img, dep_list):\n    \"\"\"Derives depression level image based on the depression id image and depression list.\n\n    Args:\n        obj_img (np.array): The numpy array containing the object image.\n        dep_list (list): A list containing depression info.\n\n    Returns:\n        np.array: The numpy array containing the object level image.\n    \"\"\"\n    level_img = np.copy(obj_img)\n\n    max_id = int(np.max(level_img))\n    # print(\"max id = \" + str(max_id))\n    if max_id &gt; 0:\n        min_id = int(np.min(level_img[np.nonzero(level_img)]))\n        # print(\"min_id = \" + str(min_id))\n        for i in range(min_id, max_id + 1):\n            level_img[level_img == i] = dep_list[i - 1].level + max_id\n    level_img = level_img - max_id\n\n    return level_img\n</code></pre>"},{"location":"slicing/#lidar.slicing.polygonize","title":"<code>polygonize(img, shp_path)</code>","text":"<p>Converts a raster image to vector.</p> <p>Parameters:</p> Name Type Description Default <code>img</code> <code>str</code> <p>File path to the input image.</p> required <code>shp_path</code> <code>str</code> <p>File path to the output shapefile.</p> required Source code in <code>lidar/slicing.py</code> <pre><code>def polygonize(img, shp_path):\n    \"\"\"Converts a raster image to vector.\n\n    Args:\n        img (str): File path to the input image.\n        shp_path (str): File path to the output shapefile.\n    \"\"\"\n    # mapping between gdal type and ogr field type\n    type_mapping = {\n        gdal.GDT_Byte: ogr.OFTInteger,\n        gdal.GDT_UInt16: ogr.OFTInteger,\n        gdal.GDT_Int16: ogr.OFTInteger,\n        gdal.GDT_UInt32: ogr.OFTInteger,\n        gdal.GDT_Int32: ogr.OFTInteger,\n        gdal.GDT_Float32: ogr.OFTReal,\n        gdal.GDT_Float64: ogr.OFTReal,\n        gdal.GDT_CInt16: ogr.OFTInteger,\n        gdal.GDT_CInt32: ogr.OFTInteger,\n        gdal.GDT_CFloat32: ogr.OFTReal,\n        gdal.GDT_CFloat64: ogr.OFTReal,\n    }\n\n    ds = gdal.Open(img)\n    prj = ds.GetProjection()\n    srcband = ds.GetRasterBand(1)\n    dst_layername = \"Shape\"\n    drv = ogr.GetDriverByName(\"ESRI Shapefile\")\n    dst_ds = drv.CreateDataSource(shp_path)\n    srs = osr.SpatialReference(wkt=prj)\n\n    dst_layer = dst_ds.CreateLayer(dst_layername, srs=srs)\n    raster_field = ogr.FieldDefn(\"id\", type_mapping[srcband.DataType])\n    dst_layer.CreateField(raster_field)\n    gdal.Polygonize(srcband, srcband, dst_layer, 0, [], callback=None)\n    del img, ds, srcband, dst_ds, dst_layer\n</code></pre>"},{"location":"slicing/#lidar.slicing.regionGroup","title":"<code>regionGroup(img_array, min_size, no_data)</code>","text":"<p>IdentifIies regions based on region growing method</p> <p>Parameters:</p> Name Type Description Default <code>img_array</code> <code>array</code> <p>The numpy array containing the image.</p> required <code>min_size</code> <code>int</code> <p>The minimum number of pixels to be considered as a depression.</p> required <code>no_data</code> <code>float</code> <p>The no_data value of the image.</p> required <p>Returns:</p> Name Type Description <code>tuple</code> <p>The labelled objects and total number of labels.</p> Source code in <code>lidar/slicing.py</code> <pre><code>def regionGroup(img_array, min_size, no_data):\n    \"\"\"IdentifIies regions based on region growing method\n\n    Args:\n        img_array (np.array): The numpy array containing the image.\n        min_size (int): The minimum number of pixels to be considered as a depression.\n        no_data (float): The no_data value of the image.\n\n    Returns:\n        tuple: The labelled objects and total number of labels.\n    \"\"\"\n    img_array[img_array == no_data] = 0\n    label_objects, nb_labels = ndimage.label(img_array)\n    sizes = np.bincount(label_objects.ravel())\n    mask_sizes = sizes &gt; min_size\n    mask_sizes[0] = 0\n    image_cleaned = mask_sizes[label_objects]\n    label_objects, nb_labels = ndimage.label(image_cleaned)\n    # nb_labels is the total number of objects. 0 represents background object.\n    return label_objects, nb_labels\n</code></pre>"},{"location":"slicing/#lidar.slicing.set_image_paras","title":"<code>set_image_paras(no_data, min_size, min_depth, interval, resolution)</code>","text":"<p>Sets the input image parameters for level-set method.</p> <p>Parameters:</p> Name Type Description Default <code>no_data</code> <code>float</code> <p>The no_data value of the input DEM.</p> required <code>min_size</code> <code>int</code> <p>The minimum number of pixels to be considered as a depression.</p> required <code>min_depth</code> <code>float</code> <p>The minimum depth to be considered as a depression.</p> required <code>interval</code> <code>float</code> <p>The slicing interval.</p> required <code>resolution</code> <code>float</code> <p>The spatial resolution of the DEM.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <p>A dictionary containing image parameters.</p> Source code in <code>lidar/slicing.py</code> <pre><code>def set_image_paras(no_data, min_size, min_depth, interval, resolution):\n    \"\"\"Sets the input image parameters for level-set method.\n\n    Args:\n        no_data (float): The no_data value of the input DEM.\n        min_size (int): The minimum number of pixels to be considered as a depression.\n        min_depth (float): The minimum depth to be considered as a depression.\n        interval (float): The slicing interval.\n        resolution (float): The spatial resolution of the DEM.\n\n    Returns:\n        dict: A dictionary containing image parameters.\n    \"\"\"\n    image_paras = {}\n    image_paras[\"no_data\"] = no_data\n    image_paras[\"min_size\"] = min_size\n    image_paras[\"min_depth\"] = min_depth\n    image_paras[\"interval\"] = interval\n    image_paras[\"resolution\"] = resolution\n    return image_paras\n</code></pre>"},{"location":"slicing/#lidar.slicing.updateLevel","title":"<code>updateLevel(dep_list, obj_uid)</code>","text":"<p>Updates the inner neighbors of each depression.</p> <p>Parameters:</p> Name Type Description Default <code>dep_list</code> <code>list</code> <p>A list containing depression info.</p> required <code>obj_uid</code> <code>int</code> <p>The unique id of an object.</p> required <p>Returns:</p> Name Type Description <code>list</code> <p>A list containing depression info.</p> Source code in <code>lidar/slicing.py</code> <pre><code>def updateLevel(dep_list, obj_uid):\n    \"\"\"Updates the inner neighbors of each depression.\n\n    Args:\n        dep_list (list): A list containing depression info.\n        obj_uid (int): The unique id of an object.\n\n    Returns:\n        list: A list containing depression info.\n    \"\"\"\n    for dep in reversed(dep_list):\n        if len(dep.inNbrId) == 0:\n            dep.level = 1\n        else:\n            max_children_level = 0\n            for id in dep.inNbrId:\n                if dep_list[id - 1 - obj_uid].level &gt; max_children_level:\n                    max_children_level = dep_list[id - 1 - obj_uid].level\n            dep.level = max_children_level + 1\n    return dep_list\n</code></pre>"},{"location":"slicing/#lidar.slicing.writeObject","title":"<code>writeObject(img_array, obj_array, bbox)</code>","text":"<p>Writes depression objects to the original image.</p> <p>Parameters:</p> Name Type Description Default <code>img_array</code> <code>array</code> <p>The output image array.</p> required <code>obj_array</code> <code>array</code> <p>The numpy array containing depression objects.</p> required <code>bbox</code> <code>list</code> <p>The bounding box of the depression object.</p> required <p>Returns:</p> Type Description <p>np.array: The numpy array containing the depression objects.</p> Source code in <code>lidar/slicing.py</code> <pre><code>def writeObject(img_array, obj_array, bbox):\n    \"\"\"Writes depression objects to the original image.\n\n    Args:\n        img_array (np.array): The output image array.\n        obj_array (np.array): The numpy array containing depression objects.\n        bbox (list): The bounding box of the depression object.\n\n    Returns:\n        np.array: The numpy array containing the depression objects.\n    \"\"\"\n    min_row, min_col, max_row, max_col = bbox\n    roi = img_array[min_row:max_row, min_col:max_col]\n    roi[obj_array &gt; 0] = obj_array[obj_array &gt; 0]\n    return img_array\n</code></pre>"},{"location":"slicing/#lidar.slicing.writeRaster","title":"<code>writeRaster(arr, out_path, template)</code>","text":"<p>Saves an numpy array as a GeoTIFF.</p> <p>Parameters:</p> Name Type Description Default <code>arr</code> <code>array</code> <p>The numpy array containing the image.</p> required <code>out_path</code> <code>str</code> <p>The file path to the output GeoTIFF.</p> required <code>template</code> <code>str</code> <p>The file path to the template image containing projection info.</p> required <p>Returns:</p> Type Description <p>np.array: The numpy array containing the image.</p> Source code in <code>lidar/slicing.py</code> <pre><code>def writeRaster(arr, out_path, template):\n    \"\"\"Saves an numpy array as a GeoTIFF.\n\n    Args:\n        arr (np.array): The numpy array containing the image.\n        out_path (str): The file path to the output GeoTIFF.\n        template (str): The file path to the template image containing projection info.\n\n    Returns:\n        np.array: The numpy array containing the image.\n    \"\"\"\n    no_data = 0\n    # First of all, gather some information from the template file\n    data = gdal.Open(template)\n    [cols, rows] = arr.shape\n    trans = data.GetGeoTransform()\n    proj = data.GetProjection()\n    # nodatav = 0 #data.GetNoDataValue()\n    # Create the file, using the information from the template file\n    outdriver = gdal.GetDriverByName(\"GTiff\")\n    # http://www.gdal.org/gdal_8h.html\n    # GDT_Byte = 1, GDT_UInt16 = 2, GDT_UInt32 = 4, GDT_Int32 = 5, GDT_Float32 = 6,\n    outdata = outdriver.Create(str(out_path), rows, cols, 1, gdal.GDT_UInt32)\n    # Write the array to the file, which is the original array in this example\n    outdata.GetRasterBand(1).WriteArray(arr)\n    # Set a no data value if required\n    outdata.GetRasterBand(1).SetNoDataValue(no_data)\n    # Georeference the image\n    outdata.SetGeoTransform(trans)\n    # Write projection information\n    outdata.SetProjection(proj)\n    return arr\n</code></pre>"},{"location":"slicing/#lidar.slicing.write_dep_csv","title":"<code>write_dep_csv(dep_list, csv_file)</code>","text":"<p>Saves the depression list to a CSV file.</p> <p>Parameters:</p> Name Type Description Default <code>dep_list</code> <code>list</code> <p>A list containing depression info.</p> required <code>csv_file</code> <code>str</code> <p>File path to the output CSV file.</p> required Source code in <code>lidar/slicing.py</code> <pre><code>def write_dep_csv(dep_list, csv_file):\n    \"\"\"Saves the depression list to a CSV file.\n\n\n    Args:\n        dep_list (list): A list containing depression info.\n        csv_file (str): File path to the output CSV file.\n    \"\"\"\n    csv = open(csv_file, \"w\")\n    header = (\n        \"id\"\n        + \",\"\n        + \"level\"\n        + \",\"\n        + \"count\"\n        + \",\"\n        + \"area\"\n        + \",\"\n        + \"volume\"\n        + \",\"\n        + \"avg_depth\"\n        + \",\"\n        + \"max_depth\"\n        + \",\"\n        + \"min_elev\"\n        + \",\"\n        + \"max_elev\"\n        + \",\"\n        + \"children_id\"\n        + \",\"\n        + \"region_id\"\n        + \",\"\n        + \"perimeter\"\n        + \",\"\n        + \"major_axis\"\n        + \",\"\n        + \"minor_axis\"\n        + \",\"\n        + \"elongatedness\"\n        + \",\"\n        + \"eccentricity\"\n        + \",\"\n        + \"orientation\"\n        + \",\"\n        + \"area_bbox_ratio\"\n    )\n    csv.write(header + \"\\n\")\n    for dep in dep_list:\n        # id, level, size, volume, meanDepth, maxDepth, minElev, bndElev, inNbrId, nbrId = 0\n        line = (\n            \"{},{},{},{:.2f},{:.2f},{:.2f},{:.2f},{:.2f},{:.2f},{},{},{:.2f},{:.2f},{:.2f},{:.2f},{:.2f},{:.2f},\"\n            \"{:.2f}\".format(\n                dep.id,\n                dep.level,\n                dep.count,\n                dep.size,\n                dep.volume,\n                dep.meanDepth,\n                dep.maxDepth,\n                dep.minElev,\n                dep.bndElev,\n                str(dep.inNbrId).replace(\",\", \":\"),\n                dep.regionId,\n                dep.perimeter,\n                dep.major_axis,\n                dep.minor_axis,\n                dep.elongatedness,\n                dep.eccentricity,\n                dep.orientation,\n                dep.area_bbox_ratio,\n            )\n        )\n        csv.write(line + \"\\n\")\n    csv.close()\n</code></pre>"},{"location":"usage/","title":"Usage","text":"<p>The images below show real-world examples of the level set method for delineating nested depressions in the Cottonwood Lake Study Area (CLSA), North Dakota. More test datasets (e.g., the Pipestem watershed in the Prairie Pothole Region of North Dakota) can be downloaded from http://gishub.org/2019-JAWRA-Data</p> <p>The following example was conducted on a 64-bit Linux machine with a quad-core Intel i7-7700 CPU and 16 GB RAM. The average running time of the algorithm for this DEM was 0.75 seconds.</p> <p></p> <p></p> <p></p>"},{"location":"notebooks/inundation/","title":"Inundation Dynamics Simulation","text":"In\u00a0[\u00a0]: Copied! <pre>import os\nimport arcpy\n</pre> import os import arcpy In\u00a0[\u00a0]: Copied! <pre>arcpy.env.workspace = os.path.dirname(arcpy.env.workspace)\nprint(arcpy.env.workspace)\n</pre> arcpy.env.workspace = os.path.dirname(arcpy.env.workspace) print(arcpy.env.workspace) In\u00a0[\u00a0]: Copied! <pre># Path to the custom toolbox\ntoolbox_path = r\"lidar\\lidar\\toolbox\\ArcGIS Pro Hydrology Analyst.tbx\"  # Change to your toolbox path\n\n# Import the toolbox\narcpy.ImportToolbox(toolbox_path, \"HydroTools\")\n</pre> # Path to the custom toolbox toolbox_path = r\"lidar\\lidar\\toolbox\\ArcGIS Pro Hydrology Analyst.tbx\"  # Change to your toolbox path  # Import the toolbox arcpy.ImportToolbox(toolbox_path, \"HydroTools\") In\u00a0[\u00a0]: Copied! <pre>input_dem = os.path.join(arcpy.env.workspace, r\"lidar\\examples\\lidar-dem\\dem_full.tif\")\nout_dir = os.path.join(os.path.expanduser(\"~\\Downloads\"), \"output\")\n</pre> input_dem = os.path.join(arcpy.env.workspace, r\"lidar\\examples\\lidar-dem\\dem_full.tif\") out_dir = os.path.join(os.path.expanduser(\"~\\Downloads\"), \"output\") In\u00a0[\u00a0]: Copied! <pre>if not os.path.exists(out_dir):\n    os.makedirs(out_dir)\n</pre> if not os.path.exists(out_dir):     os.makedirs(out_dir) In\u00a0[\u00a0]: Copied! <pre>print(input_dem)\n</pre> print(input_dem) In\u00a0[\u00a0]: Copied! <pre>print(out_dir)\n</pre> print(out_dir) In\u00a0[\u00a0]: Copied! <pre>arcpy.env.workspace = out_dir\n</pre> arcpy.env.workspace = out_dir In\u00a0[\u00a0]: Copied! <pre>arcpy.HydroTools.ExtrackSink(\n    Input_DEM=input_dem,\n    Minimum_Sink_Size=1000,\n    Minimum_Sink_Depth__from_water_surface_to_spill_point_=1,\n    Buffer_Distance=0,\n    Output_Sink_Polygon=\"sink.shp\",\n)\n</pre> arcpy.HydroTools.ExtrackSink(     Input_DEM=input_dem,     Minimum_Sink_Size=1000,     Minimum_Sink_Depth__from_water_surface_to_spill_point_=1,     Buffer_Distance=0,     Output_Sink_Polygon=\"sink.shp\", ) In\u00a0[\u00a0]: Copied! <pre>arcpy.HydroTools.DelineateCatchment(\n    Input_Partially_Filled_DEM=\"dem_partially_filled.tif\",\n    Input_Sink_Polygon=\"sink.shp\",\n    Output_Catchment_Polygon=\"catchment.shp\",\n)\n</pre> arcpy.HydroTools.DelineateCatchment(     Input_Partially_Filled_DEM=\"dem_partially_filled.tif\",     Input_Sink_Polygon=\"sink.shp\",     Output_Catchment_Polygon=\"catchment.shp\", ) In\u00a0[\u00a0]: Copied! <pre>arcpy.HydroTools.DelineateFlowPath(\n    Input_Fully_Filled_DEM=\"dem_fully_filled.tif\",\n    Input_Sink_Polygon=\"sink.shp\",\n    Rainfall_Intensity__cm_h_=\"5\",\n    Output_Flow_Path=\"flowpath.shp\",\n)\n</pre> arcpy.HydroTools.DelineateFlowPath(     Input_Fully_Filled_DEM=\"dem_fully_filled.tif\",     Input_Sink_Polygon=\"sink.shp\",     Rainfall_Intensity__cm_h_=\"5\",     Output_Flow_Path=\"flowpath.shp\", ) In\u00a0[\u00a0]: Copied! <pre>arcpy.HydroTools.DelineateDepressionHierarchy(\n    Input_DEM_Sink=\"sink.tif\",\n    Minimum_Depression_Size=\"1000\",\n    Minimum_Depression_Depth=\"0.5\",\n    Slicing_Interval=\"0.2\",\n    Output_Depression_Level_Image=\"level.tif\",\n)\n</pre> arcpy.HydroTools.DelineateDepressionHierarchy(     Input_DEM_Sink=\"sink.tif\",     Minimum_Depression_Size=\"1000\",     Minimum_Depression_Depth=\"0.5\",     Slicing_Interval=\"0.2\",     Output_Depression_Level_Image=\"level.tif\", ) In\u00a0[\u00a0]: Copied! <pre>arcpy.HydroTools.CatchmentHierarchy(\n    Input_Partially_Filled_DEM=\"dem_partially_filled.tif\",\n    Input_Depression_Hierarchy_Shapefiles=\"shp\",\n    Output_Catchment_Hierarchy=\"catchment_hir.tif\",\n)\n</pre> arcpy.HydroTools.CatchmentHierarchy(     Input_Partially_Filled_DEM=\"dem_partially_filled.tif\",     Input_Depression_Hierarchy_Shapefiles=\"shp\",     Output_Catchment_Hierarchy=\"catchment_hir.tif\", ) In\u00a0[\u00a0]: Copied! <pre>os.makedirs(os.path.join(arcpy.env.workspace, \"simulation\"), exist_ok=True)\n</pre> os.makedirs(os.path.join(arcpy.env.workspace, \"simulation\"), exist_ok=True) In\u00a0[\u00a0]: Copied! <pre>arcpy.HydroTools.SimulateInundation(\n    Input_Sink_Image=\"sink.tif\",\n    Input_Catchment_Hierarchy_Image=\"catchment_hir.tif\",\n    Minimum_Depression_Size=\"1000\",\n    Minimum_Depression_Depth=\"0.2\",\n    Slicing_Interval=\"0.2\",\n    Rainfall_Intensity__cm_h_=\"5\",\n    Rainfall_Duration__h_=\"50\",\n    Simulation_Time_Step__h_=\"1\",\n    Output_Inundation_Image_Folder=\"simulation\",\n)\n</pre> arcpy.HydroTools.SimulateInundation(     Input_Sink_Image=\"sink.tif\",     Input_Catchment_Hierarchy_Image=\"catchment_hir.tif\",     Minimum_Depression_Size=\"1000\",     Minimum_Depression_Depth=\"0.2\",     Slicing_Interval=\"0.2\",     Rainfall_Intensity__cm_h_=\"5\",     Rainfall_Duration__h_=\"50\",     Simulation_Time_Step__h_=\"1\",     Output_Inundation_Image_Folder=\"simulation\", ) In\u00a0[\u00a0]: Copied! <pre>arcpy.HydroTools.PlayAnimation(\n    Input_DEM=\"dem_partially_filled.tif\",\n    Loops=\"3\",\n    Input_Inundation_Image_Folder=\"simulation\",\n)\n</pre> arcpy.HydroTools.PlayAnimation(     Input_DEM=\"dem_partially_filled.tif\",     Loops=\"3\",     Input_Inundation_Image_Folder=\"simulation\", )"},{"location":"notebooks/inundation/#inundation-dynamics-simulation","title":"Inundation Dynamics Simulation\u00b6","text":""},{"location":"notebooks/inundation/#create-an-arcgis-pro-project","title":"Create an ArcGIS Pro project\u00b6","text":"<p>Open ArcGIS Pro and create a new project titled <code>inundation</code>.</p>"},{"location":"notebooks/inundation/#clone-the-arcgispro-py3-env","title":"Clone the arcgispro-py3 env\u00b6","text":"<p>Clone the <code>arcgispro-py</code> env to create a new env named <code>arcgispro-py3-clone</code>.</p> <p></p>"},{"location":"notebooks/inundation/#install-scikit-image","title":"Install scikit-image\u00b6","text":"<p>Activate the <code>arcgispro-py3-clone</code> env and install the <code>scikit-image</code> package into the env.</p> <p></p>"},{"location":"notebooks/inundation/#import-libraries","title":"Import libraries\u00b6","text":""},{"location":"notebooks/inundation/#set-workspace","title":"Set workspace\u00b6","text":"<p>Set to working space to the project folder instead of a GeoDatabase.</p>"},{"location":"notebooks/inundation/#download-the-lidar-toolbox","title":"Download the lidar toolbox\u00b6","text":"<p>Click this link and download it to the inundation project folder. Unzip the downloaded file and rename the folder from <code>lidar-master</code> to <code>lidar.</code></p> <p>You will find the ArcGIS toolbox under <code>inundation\\lidar\\lidar\\toolbox\\ArcGIS Pro Hydrology Analyst.tbx</code></p>"},{"location":"notebooks/inundation/#import-the-lidar-toolbox","title":"Import the lidar toolbox\u00b6","text":""},{"location":"notebooks/inundation/#set-input-data-and-output-folder","title":"Set input data and output folder\u00b6","text":""},{"location":"notebooks/inundation/#extract-sinks","title":"Extract sinks\u00b6","text":""},{"location":"notebooks/inundation/#delineate-catchments","title":"Delineate catchments\u00b6","text":""},{"location":"notebooks/inundation/#delineate-flowpaths","title":"Delineate flowpaths\u00b6","text":""},{"location":"notebooks/inundation/#delineate-depression-hierarchy","title":"Delineate depression hierarchy\u00b6","text":""},{"location":"notebooks/inundation/#delinate-catchment-hierarchy","title":"Delinate catchment hierarchy\u00b6","text":""},{"location":"notebooks/inundation/#simulate-inundation","title":"Simulate inundation\u00b6","text":""},{"location":"notebooks/inundation/#play-the-animation","title":"Play the animation\u00b6","text":""},{"location":"notebooks/lidar/","title":"A tutorial for the lidar Python package","text":"<p>This section demonstrates two ways to get data into Binder so that you can test the lidar Python package on the cloud using your own data.</p> <ul> <li>Getting data from direct URLs</li> <li>Getting data from Google Drive</li> </ul> <p>Import the following Python libraries and start getting data from direct URLs.</p> In\u00a0[1]: Copied! <pre>import os\nimport zipfile\nimport tarfile\nimport shutil\nimport urllib.request\n</pre> import os import zipfile import tarfile import shutil import urllib.request <p>Create a folder named lidar under the user home folder and set it as the working directory.</p> In\u00a0[2]: Copied! <pre>work_dir = os.path.join(os.path.expanduser(\"~\"), \"lidar\")\nif not os.path.exists(work_dir):\n    os.mkdir(work_dir)\n# os.chdir(work_dir)\nprint(\"Working directory: {}\".format(work_dir))\n</pre> work_dir = os.path.join(os.path.expanduser(\"~\"), \"lidar\") if not os.path.exists(work_dir):     os.mkdir(work_dir) # os.chdir(work_dir) print(\"Working directory: {}\".format(work_dir)) <pre>Working directory: /home/qiusheng/lidar\n</pre> <p>Replace the following URL with your own direct URL hosting the data you would like to use.</p> In\u00a0[3]: Copied! <pre>url = \"https://github.com/opengeos/lidar/raw/master/examples/lidar-dem.zip\"\n</pre> url = \"https://github.com/opengeos/lidar/raw/master/examples/lidar-dem.zip\" <p>Download data the from the above URL and unzip the file if needed.</p> In\u00a0[4]: Copied! <pre># download the file\nzip_name = os.path.basename(url)\nzip_path = os.path.join(work_dir, zip_name)\n\nprint(\"Downloading {} ...\".format(zip_name))\nurllib.request.urlretrieve(url, zip_path)\nprint(\"Downloading done.\".format(zip_name))\n\n# if it is a zip file\nif \".zip\" in zip_name:\n    print(\"Unzipping {} ...\".format(zip_name))\n    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n        zip_ref.extractall(work_dir)\n    print(\"Unzipping done.\")\n\n# if it is a tar file\nif \".tar\" in zip_name:\n    print(\"Unzipping {} ...\".format(zip_name))\n    with tarfile.open(zip_path, \"r\") as tar_ref:\n        tar_ref.extractall(work_dir)\n    print(\"Unzipping done.\")\n\nprint(\"Data directory: {}\".format(os.path.splitext(zip_path)[0]))\n</pre> # download the file zip_name = os.path.basename(url) zip_path = os.path.join(work_dir, zip_name)  print(\"Downloading {} ...\".format(zip_name)) urllib.request.urlretrieve(url, zip_path) print(\"Downloading done.\".format(zip_name))  # if it is a zip file if \".zip\" in zip_name:     print(\"Unzipping {} ...\".format(zip_name))     with zipfile.ZipFile(zip_path, \"r\") as zip_ref:         zip_ref.extractall(work_dir)     print(\"Unzipping done.\")  # if it is a tar file if \".tar\" in zip_name:     print(\"Unzipping {} ...\".format(zip_name))     with tarfile.open(zip_path, \"r\") as tar_ref:         tar_ref.extractall(work_dir)     print(\"Unzipping done.\")  print(\"Data directory: {}\".format(os.path.splitext(zip_path)[0])) <pre>Downloading lidar-dem.zip ...\nDownloading done.\nUnzipping lidar-dem.zip ...\nUnzipping done.\nData directory: /home/qiusheng/lidar/lidar-dem\n</pre> <p>You have successfully downloaded data to Binder. Therefore, you can skip to Using lidar and start testing lidar with your own data.</p> <p>Replace the following URL with your own shareable URL from Google Drive.</p> In\u00a0[5]: Copied! <pre>gfile_url = \"https://drive.google.com/file/d/1c6v-ep5-klb2J32Nuu1rSyqAc8kEtmdh\"\n</pre> gfile_url = \"https://drive.google.com/file/d/1c6v-ep5-klb2J32Nuu1rSyqAc8kEtmdh\" <p>Extract the file id from the above URL.</p> In\u00a0[6]: Copied! <pre>file_id = gfile_url.split(\"/\")[5]  #'1c6v-ep5-klb2J32Nuu1rSyqAc8kEtmdh'\nprint(\"Google Drive file id: {}\".format(file_id))\n</pre> file_id = gfile_url.split(\"/\")[5]  #'1c6v-ep5-klb2J32Nuu1rSyqAc8kEtmdh' print(\"Google Drive file id: {}\".format(file_id)) <pre>Google Drive file id: 1c6v-ep5-klb2J32Nuu1rSyqAc8kEtmdh\n</pre> <p>Download the shared file from Google Drive.</p> In\u00a0[7]: Copied! <pre>from google_drive_downloader import GoogleDriveDownloader as gdd\n\ndest_path = \"./lidar-dem.zip\"  # choose a name for the downloaded file\ngdd.download_file_from_google_drive(file_id, dest_path, unzip=True)\n</pre> from google_drive_downloader import GoogleDriveDownloader as gdd  dest_path = \"./lidar-dem.zip\"  # choose a name for the downloaded file gdd.download_file_from_google_drive(file_id, dest_path, unzip=True) <p>You have successfully downloaded data from Google Drive to Binder. You can now continue to Using lidar and start testing lidar with your own data.</p> <p>Here you can specify where your data are located. In this example, we will use dem.tif, which has been downloaded to the lidar-dem folder.</p> <p>Import the lidar package.</p> In\u00a0[8]: Copied! <pre>import lidar\n</pre> import lidar <p>List data under the data folder.</p> In\u00a0[9]: Copied! <pre>data_dir = \"./lidar-dem/\"\nprint(os.listdir(data_dir))\n</pre> data_dir = \"./lidar-dem/\" print(os.listdir(data_dir)) <pre>['sink.tif', 'dem.tif', 'dsm.tif']\n</pre> <p>Create a temporary folder to save results.</p> In\u00a0[10]: Copied! <pre>out_dir = os.path.join(os.getcwd(), \"temp\")\n\nif not os.path.exists(out_dir):\n    os.mkdir(out_dir)\n</pre> out_dir = os.path.join(os.getcwd(), \"temp\")  if not os.path.exists(out_dir):     os.mkdir(out_dir) <p>In this simple example, we smooth dem.tif using a median filter. Then we extract sinks (i.e., depressions) from the DEM. Finally, we delineate nested depression hierarchy using the level-set algorithm.</p> <p>Set parameters for the level-set algorithm.</p> In\u00a0[11]: Copied! <pre>min_size = 1000  # minimum number of pixels as a depression\nmin_depth = 0.3  # minimum depth as a depression\ninterval = 0.3  # slicing interval for the level-set method\nbool_shp = False  # output shapefiles for each individual level\n</pre> min_size = 1000  # minimum number of pixels as a depression min_depth = 0.3  # minimum depth as a depression interval = 0.3  # slicing interval for the level-set method bool_shp = False  # output shapefiles for each individual level <p>Smooth the original DEM using a median filter.</p> In\u00a0[12]: Copied! <pre># extracting sinks based on user-defined minimum depression size\nin_dem = os.path.join(data_dir, \"dem.tif\")\nout_dem = os.path.join(out_dir, \"median.tif\")\nin_dem = lidar.MedianFilter(in_dem, kernel_size=3, out_file=out_dem)\n</pre> # extracting sinks based on user-defined minimum depression size in_dem = os.path.join(data_dir, \"dem.tif\") out_dem = os.path.join(out_dir, \"median.tif\") in_dem = lidar.MedianFilter(in_dem, kernel_size=3, out_file=out_dem) <pre>Median filtering ...\nRun time: 0.0190 seconds\nSaving dem ...\n</pre> <p>Extract DEM sinks using a depression-filling algorithm.</p> In\u00a0[13]: Copied! <pre>sink = lidar.ExtractSinks(in_dem, min_size, out_dir)\n</pre> sink = lidar.ExtractSinks(in_dem, min_size, out_dir) <pre>Loading data ...\nmin = 379.70, max = 410.72, no_data = -3.402823e+38, cell_size = 1.0\nDepression filling ...\nSaving filled dem ...\nRegion grouping ...\nComputing properties ...\nSaving sink dem ...\nSaving refined dem ...\nConverting raster to vector ...\nTotal run time:\t\t\t 0.1093 s\n\n</pre> <p>Identify depression nested hierarchy using the level-set algorithm.</p> In\u00a0[14]: Copied! <pre>dep_id, dep_level = lidar.DelineateDepressions(\n    sink, min_size, min_depth, interval, out_dir, bool_shp\n)\n</pre> dep_id, dep_level = lidar.DelineateDepressions(     sink, min_size, min_depth, interval, out_dir, bool_shp ) <pre>Reading data ...\nrows, cols: (400, 400)\nPixel resolution: 1.0\nRead data time: 0.0024 seconds\nData preparation time: 0.0100 seconds\nTotal number of regions: 1\nProcessing Region # 1 ...\n=========== Run time statistics =========== \n(rows, cols):\t\t\t (400, 400)\nPixel resolution:\t\t 1.0 m\nNumber of regions:\t\t 1\nData preparation time:\t\t 0.0100 s\nIdentify level time:\t\t 0.3347 s\nWrite image time:\t\t 0.0164 s\nPolygonize time:\t\t 0.0098 s\nTotal run time:\t\t\t 0.3719 s\n</pre> <p>Print the list of output files.</p> In\u00a0[15]: Copied! <pre>print(\"Results are saved in: {}\".format(out_dir))\nprint(os.listdir(out_dir))\n</pre> print(\"Results are saved in: {}\".format(out_dir)) print(os.listdir(out_dir)) <pre>Results are saved in: /media/hdd/Dropbox/git/lidar/examples/temp\n['depressions.dbf', 'depressions.prj', 'regions_info.csv', 'regions.shp', 'region.tif', 'depression_level.tif', 'depressions.shx', 'depression_id.tif', 'depressions_info.csv', 'depth.tif', 'depressions.shp', 'median.tif', 'dem_diff.tif', 'regions.shx', 'sink.tif', 'dem_filled.tif', 'dem.tif', 'regions.dbf', 'regions.prj']\n</pre> <p>Import the libraries.</p> In\u00a0[16]: Copied! <pre># comment out the third line (%matplotlib inline) if you run the tutorial in other IDEs other than Jupyter Notebook\nimport matplotlib.pyplot as plt\nimport imageio\n\n%matplotlib inline\n</pre> # comment out the third line (%matplotlib inline) if you run the tutorial in other IDEs other than Jupyter Notebook import matplotlib.pyplot as plt import imageio  %matplotlib inline <p>Display one single image.</p> In\u00a0[17]: Copied! <pre>raster = imageio.imread(os.path.join(data_dir, \"dem.tif\"))\nplt.imshow(raster)\nplt.show()\n</pre> raster = imageio.imread(os.path.join(data_dir, \"dem.tif\")) plt.imshow(raster) plt.show() <p>Read images as numpy arrays.</p> In\u00a0[18]: Copied! <pre>smoothed = imageio.imread(os.path.join(out_dir, \"median.tif\"))\nsink = imageio.imread(os.path.join(out_dir, \"sink.tif\"))\ndep_id = imageio.imread(os.path.join(out_dir, \"depression_id.tif\"))\ndep_level = imageio.imread(os.path.join(out_dir, \"depression_level.tif\"))\n</pre> smoothed = imageio.imread(os.path.join(out_dir, \"median.tif\")) sink = imageio.imread(os.path.join(out_dir, \"sink.tif\")) dep_id = imageio.imread(os.path.join(out_dir, \"depression_id.tif\")) dep_level = imageio.imread(os.path.join(out_dir, \"depression_level.tif\")) <p>Display multiple images in one plot.</p> In\u00a0[19]: Copied! <pre>fig = plt.figure(figsize=(16, 16))\n\nax1 = fig.add_subplot(2, 2, 1)\nax1.set_title(\"Smoothed DEM\")\nplt.imshow(smoothed)\n\nax2 = fig.add_subplot(2, 2, 2)\nax2.set_title(\"DEM Sinks\")\nplt.imshow(sink)\n\nax3 = fig.add_subplot(2, 2, 3)\nax3.set_title(\"Depression Unique ID\")\nplt.imshow(dep_id)\n\nax4 = fig.add_subplot(2, 2, 4)\nax4.set_title(\"Depression Level\")\nplt.imshow(dep_level)\n\nplt.show()\n</pre> fig = plt.figure(figsize=(16, 16))  ax1 = fig.add_subplot(2, 2, 1) ax1.set_title(\"Smoothed DEM\") plt.imshow(smoothed)  ax2 = fig.add_subplot(2, 2, 2) ax2.set_title(\"DEM Sinks\") plt.imshow(sink)  ax3 = fig.add_subplot(2, 2, 3) ax3.set_title(\"Depression Unique ID\") plt.imshow(dep_id)  ax4 = fig.add_subplot(2, 2, 4) ax4.set_title(\"Depression Level\") plt.imshow(dep_level)  plt.show()"},{"location":"notebooks/lidar/#a-tutorial-for-the-lidar-python-package","title":"A tutorial for the lidar Python package\u00b6","text":"<p>This notebook demonstrates the usage of the lidar Python package for terrain and hydrological analysis. It is  useful for analyzing high-resolution topographic data, such as digital elevation models (DEMs) derived from Light Detection and Ranging (LiDAR) data.</p> <ul> <li>GitHub repo: https://github.com/opengeos/lidar</li> <li>Documentation: https://lidar.gishub.org</li> <li>PyPI: https://pypi.org/project/lidar</li> <li>Binder: https://gishub.org/lidar-cloud</li> <li>Free software: MIT license</li> </ul> <p>This tutorial can be accessed in three ways:</p> <ul> <li>HTML version: https://gishub.org/lidar-html</li> <li>Viewable Notebook: https://gishub.org/lidar-notebook</li> <li>Interactive Notebook: https://gishub.org/lidar-cloud</li> </ul> <p>Launch this tutorial as an interactive Jupyter Notebook on the cloud - MyBinder.org.</p> <p></p>"},{"location":"notebooks/lidar/#table-of-content","title":"Table of Content\u00b6","text":"<ul> <li>Installation</li> <li>Getting data</li> <li>Using lidar</li> <li>Displaying results</li> <li>lidar GUI</li> <li>Citing lidar</li> <li>Credits</li> <li>Contact</li> </ul>"},{"location":"notebooks/lidar/#installation","title":"Installation\u00b6","text":"<p>The lidar Python package supports a variety of platforms, including Microsoft Windows, macOS, and Linux operating systems. Note that you will need to have Python 3.x installed. Python 2.x is not supported. The lidar Python package can be installed using the following command:</p> <p><code>pip install lidar</code></p> <p>If you have installed lidar Python package before and want to upgrade to the latest version, you can use the following command:</p> <p><code>pip install lidar -U</code></p> <p>If you encounter any installation issues, please check Dependencies on the lidar GitHub page and Report Bugs.</p>"},{"location":"notebooks/lidar/#getting-data","title":"Getting data\u00b6","text":""},{"location":"notebooks/lidar/#getting-data-from-direct-urls","title":"Getting data from direct URLs\u00b6","text":"<p>If you have data hosted on your own HTTP server or GitHub, you should be able to get direct URLs. With a direct URL, users can automatically download the data when the URL is clicked. For example http://wetlands.io/file/data/lidar-dem.zip</p>"},{"location":"notebooks/lidar/#getting-data-from-google-drive","title":"Getting data from Google Drive\u00b6","text":"<p>Alternatively, you can upload data to Google Drive and then share files publicly from Google Drive. Once the file is shared publicly, you should be able to get a shareable URL. For example, https://drive.google.com/file/d/1c6v-ep5-klb2J32Nuu1rSyqAc8kEtmdh.</p> <p>To download files from Google Drive to Binder, you can use the Python package called google-drive-downloader, which can be installed using the following command:</p> <p><code>pip install googledrivedownloader requests</code></p>"},{"location":"notebooks/lidar/#using-lidar","title":"Using lidar\u00b6","text":""},{"location":"notebooks/lidar/#displaying-results","title":"Displaying results\u00b6","text":"<p>This section demonstrates how to display images on Jupyter Notebook. Three Python packages are used here, including matplotlib, imageio, and tifffile. These three packages can be installed using the following command:</p> <p><code>pip install matplotlib imageio tifffile</code></p>"},{"location":"notebooks/lidar/#lidar-gui","title":"lidar GUI\u00b6","text":"<p>lidar also provides a Graphical User Interface (GUI), which can be invoked using the following Python script. Note that the GUI might not work in Jupyter notebooks deployed on the cloud (e.g., MyBinder.org), but it should work on Jupyter notebooks on local computers.</p> <pre>import lidar\nlidar.gui()\n</pre> <p></p>"},{"location":"notebooks/lidar/#citing-lidar","title":"Citing lidar\u00b6","text":"<p>If you use the lidar Python package for your research and publications, please consider citing the following papers on the contour tree and level-set algorithms, which are key components of this lidar Python package.</p> <ul> <li><p>Wu, Q., Lane, C.R., Wang, L., Vanderhoof, M.K., Christensen, J.R., &amp; Liu, H. (2018). Efficient delineation of nested depression hierarchy in digital elevation models for hydrological analyses using level-set method. Journal of the American Water Resources Association. 1-15. https://doi.org/10.1111/1752-1688.12689</p> </li> <li><p>Wu, Q., Liu, H., Wang, S., Yu, B., Beck, R., &amp; Hinkel, K. (2015). A localized contour tree method for deriving geometric and topologic properties of complex surface depressions based on high resolution topographical data. International Journal of Geographical Information Science. 29:12, 2041-2060. http://dx.doi.org/10.1080/13658816.2015.1038719</p> </li> </ul>"},{"location":"notebooks/lidar/#credits","title":"Credits\u00b6","text":"<p>This interactive notebook is made possible by MyBinder.org. Big thanks to MyBinder.org for developing the amazing binder platform, which is extremely valuable for reproducible research!</p> <p>This tutorial made use a number of open-source Python packages, including  Cookiecutter, richdem, numpy, scikit-image matplotlib, imageio, tifffile, pygdal, PySimpleGUI, and google-drive-downloader. Thanks to all developers of these wonderful Python packages!</p>"},{"location":"notebooks/lidar/#contact","title":"Contact\u00b6","text":"<p>If you have any questions regarding this tutorial or the lidar Python package, you can contact me (Dr. Qiusheng Wu) at wqs@binghamton.edu or https://wetlands.io/#contact</p>"},{"location":"notebooks/lidar_colab/","title":"Lidar colab","text":"In\u00a0[1]: Copied! <pre>import subprocess\n\ntry:\n    import lidar\nexcept ImportError:\n    print(\"Installing lidar ...\")\n    subprocess.check_call([\"python\", \"-m\", \"pip\", \"install\", \"lidar\"])\n</pre> import subprocess  try:     import lidar except ImportError:     print(\"Installing lidar ...\")     subprocess.check_call([\"python\", \"-m\", \"pip\", \"install\", \"lidar\"]) In\u00a0[2]: Copied! <pre>import os\nimport pkg_resources\nfrom lidar import *\n\n# identify the sample data directory of the package\npackage_name = \"lidar\"\ndata_dir = pkg_resources.resource_filename(package_name, \"data/\")\n\n# use the sample dem. Change it to your own dem if needed\nin_dem = os.path.join(data_dir, \"dem.tif\")\n# set the output directory\nout_dir = os.getcwd()\n\n# parameters for identifying sinks and delineating nested depressions\nmin_size = 1000  # minimum number of pixels as a depression\nmin_depth = 0.5  # minimum depth as a depression\ninterval = 0.3  # slicing interval for the level-set method\nbool_shp = True  # output shapefiles for each individual level\n\n# extracting sinks based on user-defined minimum depression size\nout_dem = os.path.join(out_dir, \"median.tif\")\nin_dem = MedianFilter(in_dem, kernel_size=3, out_file=out_dem)\nsink_path = ExtractSinks(in_dem, min_size, out_dir)\ndep_id_path, dep_level_path = DelineateDepressions(\n    sink_path, min_size, min_depth, interval, out_dir, bool_shp\n)\nprint(\"Results are saved in: {}\".format(out_dir))\n</pre> import os import pkg_resources from lidar import *  # identify the sample data directory of the package package_name = \"lidar\" data_dir = pkg_resources.resource_filename(package_name, \"data/\")  # use the sample dem. Change it to your own dem if needed in_dem = os.path.join(data_dir, \"dem.tif\") # set the output directory out_dir = os.getcwd()  # parameters for identifying sinks and delineating nested depressions min_size = 1000  # minimum number of pixels as a depression min_depth = 0.5  # minimum depth as a depression interval = 0.3  # slicing interval for the level-set method bool_shp = True  # output shapefiles for each individual level  # extracting sinks based on user-defined minimum depression size out_dem = os.path.join(out_dir, \"median.tif\") in_dem = MedianFilter(in_dem, kernel_size=3, out_file=out_dem) sink_path = ExtractSinks(in_dem, min_size, out_dir) dep_id_path, dep_level_path = DelineateDepressions(     sink_path, min_size, min_depth, interval, out_dir, bool_shp ) print(\"Results are saved in: {}\".format(out_dir)) <pre>Median filtering ...\nRun time: 0.0599 seconds\nSaving dem ...\nLoading data ...\nmin = 379.70, max = 410.72, no_data = -3.402823e+38, cell_size = 1.0\nDepression filling ...\nSaving filled dem ...\nRegion grouping ...\nComputing properties ...\nSaving sink dem ...\nSaving refined dem ...\nConverting raster to vector ...\nTotal run time:\t\t\t 0.0972 s\n\nReading data ...\nrows, cols: (400, 400)\nPixel resolution: 1.0\nRead data time: 0.0029 seconds\nData preparation time: 0.0092 seconds\nTotal number of regions: 1\nProcessing Region # 1 ...\n=========== Run time statistics =========== \n(rows, cols):\t\t\t (400, 400)\nPixel resolution:\t\t 1.0 m\nNumber of regions:\t\t 1\nData preparation time:\t\t 0.0092 s\nIdentify level time:\t\t 0.2358 s\nWrite image time:\t\t 0.0026 s\nPolygonize time:\t\t 0.0098 s\nExtract level time:\t\t 0.0570 s\nTotal run time:\t\t\t 0.3150 s\nResults are saved in: /home/qiusheng/temp\n</pre>"},{"location":"notebooks/lidar_dsm/","title":"Lidar dsm","text":"In\u00a0[\u00a0]: Copied! <pre>import os\nimport lidar\n</pre> import os import lidar In\u00a0[\u00a0]: Copied! <pre>url = \"https://open.gishub.org/data/lidar/madison.laz\"\n</pre> url = \"https://open.gishub.org/data/lidar/madison.laz\" In\u00a0[\u00a0]: Copied! <pre>lidar.download_file(url)\n</pre> lidar.download_file(url) In\u00a0[\u00a0]: Copied! <pre>filename = os.path.abspath(os.path.basename(url))\noutput = os.path.splitext(filename)[0] + \".tif\"\n</pre> filename = os.path.abspath(os.path.basename(url)) output = os.path.splitext(filename)[0] + \".tif\" In\u00a0[\u00a0]: Copied! <pre>lidar.lidar_to_dsm(filename, output, resolution=1.0, minz=0, maxz=450)\n</pre> lidar.lidar_to_dsm(filename, output, resolution=1.0, minz=0, maxz=450) In\u00a0[\u00a0]: Copied! <pre>lidar.add_crs(output, epsg=2255)\n</pre> lidar.add_crs(output, epsg=2255)"},{"location":"notebooks/lidar_dsm/#creating-a-digital-surface-model-dsm-from-lidar-data","title":"Creating a Digital Surface Model (DSM) from LiDAR data\u00b6","text":""}]}